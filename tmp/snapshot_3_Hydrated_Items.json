[
  {
    "id": "https://openai.com/index/ai-literacy-resources-for-teens-and-parents",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/ai-literacy-resources-for-teens-and-parents",
    "title": "AI literacy resources for teens and parents",
    "publishedAt": "Thu, 18 Dec 2025 11:00:00 GMT",
    "fetchedAt": "2026-01-25T19:07:59.675Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div id=\"main\" tabindex=\"-1\"><span aria-live=\"polite\" aria-atomic=\"true\">OpenAI</span><article><div><p>A teen’s guide to using ChatGPT thoughtfully—plus tips for parents to support healthy, responsible use.</p></div><div><p><span>We’re sharing two new AI literacy resources to help families use ChatGPT thoughtfully, safely, and confidently. First is a family-friendly guide that explains—in plain language—how AI models are trained, why AI can sometimes get things wrong, and the importance of double checking the information received. It also includes practical tips for responsible use, like how to write better prompts, why you might get different answers to the same question, and how to manage your data and settings.</span></p><p><span>We’re also publishing a set of tips for parents, with conversation starters and practical guidance to help parents talk with their teens about what AI can (and can’t) do, build critical thinking, set healthy boundaries, and navigate emotional or sensitive topics.&nbsp;</span></p><p><span>Both resources were developed with expert input, including members of our </span><a href=\"https://openai.com/index/expert-council-on-well-being-and-ai/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>Expert Council on Well-Being and AI</span></u>⁠</a><span> and </span><a href=\"https://connectsafely.org/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>ConnectSafely</span></u>⁠<span>(opens in a new window)</span></a><span>, groups with deep expertise in online safety, human-computer interaction, teen development, and mental health. We’ll continue expanding our AI literacy work over time with additional guidance for different ages and stages, and we’ll keep updating these resources as we learn more.</span></p></div><section id=\"citations\" data-testid=\"citations\"><ul><li><a href=\"https://openai.com/news/?tags=user-safety\" target=\"_blank\" rel=\"noopener noreferrer\">User Safety &amp; Control</a></li><li><a href=\"https://openai.com/news/?tags=2025\" target=\"_blank\" rel=\"noopener noreferrer\">2025</a></li></ul></section></article></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/3L8hiynG5WUknKEDQVEuzu/2e6b4e418c522ae4e5a99d2dffd2e905/Parent_Education_Guide_Blog_Art_Card__Open_Graph.png?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/index/gpt-5-2-codex",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/gpt-5-2-codex",
    "title": "Introducing GPT-5.2-Codex",
    "publishedAt": "Thu, 18 Dec 2025 00:00:00 GMT",
    "fetchedAt": "2026-01-25T19:08:00.204Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div><p><span>Today we’re releasing GPT‑5.2-Codex, the most advanced agentic coding model yet for complex, real-world software engineering. GPT‑5.2-Codex is a version of </span><a href=\"https://openai.com/index/introducing-gpt-5-2/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>GPT‑5.2</span></u>⁠</a><span> further optimized for agentic coding in Codex, including improvements on long-horizon work through context compaction, stronger performance on large code changes like refactors and migrations, improved performance in Windows environments, and significantly stronger cybersecurity capabilities.</span></p><p><span>As our models continue to advance along the intelligence frontier, we’ve observed that these improvements also translate to capability jumps in specialized domains such as </span><a href=\"https://openai.com/index/strengthening-cyber-resilience/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>cybersecurity</span></u>⁠</a><span>. For example, just last week, a security researcher using GPT‑5.1-Codex-Max with Codex CLI found and responsibly </span><a href=\"https://react.dev/blog/2025/12/11/denial-of-service-and-source-code-exposure-in-react-server-components\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>disclosed</span></u>⁠<span>(opens in a new window)</span></a><span> a vulnerability in React that could lead to source code exposure.</span></p><p><span>GPT‑5.2-Codex has stronger cybersecurity capabilities than any model we’ve released so far. These advances can help strengthen cybersecurity at scale, but they also raise new dual-use risks that require careful deployment. While GPT‑5.2-Codex does not reach a ‘High’ level of cyber capability under our Preparedness Framework, we’re designing our </span><a href=\"https://openai.com/index/strengthening-cyber-resilience/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>deployment approach</span></u>⁠</a><span> with future capability growth in mind.</span></p><p><span>We're releasing GPT‑5.2-Codex today in all Codex surfaces for paid ChatGPT users, and working towards safely enabling access to GPT‑5.2-Codex for API users in the coming weeks. In parallel, we’re piloting invite-only trusted access to upcoming capabilities and more permissive models for vetted professionals and organizations focused on defensive cybersecurity work. We believe that this approach to deployment will balance accessibility with safety.</span></p><div id=\"pushing-the-frontier-on-real-world-software-engineering\"><p></p><h2><span>Pushing the frontier on real-world software engineering</span></h2><p></p></div><p><span>GPT‑5.2-Codex builds on </span><a href=\"https://openai.com/index/introducing-gpt-5-2/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>GPT‑5.2’s strengths</span></u>⁠</a><span> in professional knowledge work and </span><a href=\"https://openai.com/index/gpt-5-1-codex-max/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>GPT‑5.1-Codex-Max</span></u>⁠</a><span>’s frontier agentic coding and terminal-using capabilities. GPT‑5.2-Codex is now better at long-context understanding, reliable tool calling, improved factuality, and native compaction, making it a more dependable partner for long running coding tasks, while remaining token-efficient in its reasoning.</span></p><p><span>GPT‑5.2-Codex achieves state-of-the-art performance on SWE-Bench Pro and Terminal-Bench 2.0, benchmarks designed to test agentic performance on a wide variety of tasks in realistic terminal environments. It is also much more effective and reliable at agentic coding in native Windows environments, building on capabilities introduced in GPT‑5.1-Codex-Max.</span></p><p><span>With these improvements, Codex is more capable at working in large repositories over extended sessions with full context intact. It can more reliably complete complex tasks like large refactors, code migrations, and feature builds — continuing to iterate without losing track, even when plans change or attempts fail.</span></p><p><span>Stronger vision performance enables GPT‑5.2-Codex to more accurately interpret screenshots, technical diagrams, charts, and UI surfaces shared during coding sessions.</span></p><p><span>Codex can take design mocks and quickly translate them to functional prototypes, and you can pair with Codex to take these prototypes to production.</span></p><div data-multi-columns=\"true\"><!--$--><div><!--$--><div><p></p><h5>Design mock</h5><p></p></div><!--/$--><!--$--><div><p><img alt=\"Design mock used to generate a web prototype with Codex-5.2\" data-nosnippet=\"true\" loading=\"lazy\" width=\"1536\" height=\"1024\" decoding=\"async\" data-nimg=\"1\" sizes=\"(min-width: 1728px) 1728px, 100vw\" srcset=\"https://images.ctfassets.net/kftzwdyauwt9/3zqTyemGGUiGdqzwcSHfqT/7dcff34a7b6f51ce1ed20be8a4ffcbf4/image__5_.png?w=640&amp;q=90&amp;fm=webp 640w, https://images.ctfassets.net/kftzwdyauwt9/3zqTyemGGUiGdqzwcSHfqT/7dcff34a7b6f51ce1ed20be8a4ffcbf4/image__5_.png?w=750&amp;q=90&amp;fm=webp 750w, https://images.ctfassets.net/kftzwdyauwt9/3zqTyemGGUiGdqzwcSHfqT/7dcff34a7b6f51ce1ed20be8a4ffcbf4/image__5_.png?w=828&amp;q=90&amp;fm=webp 828w, https://images.ctfassets.net/kftzwdyauwt9/3zqTyemGGUiGdqzwcSHfqT/7dcff34a7b6f51ce1ed20be8a4ffcbf4/image__5_.png?w=1080&amp;q=90&amp;fm=webp 1080w, https://images.ctfassets.net/kftzwdyauwt9/3zqTyemGGUiGdqzwcSHfqT/7dcff34a7b6f51ce1ed20be8a4ffcbf4/image__5_.png?w=1200&amp;q=90&amp;fm=webp 1200w, https://images.ctfassets.net/kftzwdyauwt9/3zqTyemGGUiGdqzwcSHfqT/7dcff34a7b6f51ce1ed20be8a4ffcbf4/image__5_.png?w=1920&amp;q=90&amp;fm=webp 1920w, https://images.ctfassets.net/kftzwdyauwt9/3zqTyemGGUiGdqzwcSHfqT/7dcff34a7b6f51ce1ed20be8a4ffcbf4/image__5_.png?w=2048&amp;q=90&amp;fm=webp 2048w, https://images.ctfassets.net/kftzwdyauwt9/3zqTyemGGUiGdqzwcSHfqT/7dcff34a7b6f51ce1ed20be8a4ffcbf4/image__5_.png?w=3840&amp;q=90&amp;fm=webp 3840w\" src=\"https://images.ctfassets.net/kftzwdyauwt9/3zqTyemGGUiGdqzwcSHfqT/7dcff34a7b6f51ce1ed20be8a4ffcbf4/image__5_.png?w=3840&amp;q=90&amp;fm=webp\" style=\"max-width: 100%; height: auto; border-radius: 1rem; margin: 2rem 0px;\"></p></div><!--/$--></div><!--/$--><!--$--><div><p></p><h5>Prototype generated by GPT-5.2-Codex</h5><p></p></div><!--/$--></div><div id=\"advancing-the-cyber-frontier\"><p></p><h2><span>Advancing the cyber frontier</span></h2><p></p></div><p><span>When charting performance on one of our core cybersecurity evaluations over time, we see a sharp jump in capability starting with GPT‑5-Codex, another large jump with GPT‑5.1-Codex-Max and now a third jump with GPT‑5.2-Codex. We expect that upcoming AI models will continue on this trajectory. In preparation, we are planning and evaluating as though each new model could reach ‘High’ levels of cybersecurity capability, as measured by our </span><a href=\"https://cdn.openai.com/pdf/18a02b5d-6b67-4cec-ab64-68cdfbddebcd/preparedness-framework-v2.pdf\" target=\"_blank\" referrerpolicy=\"no-referrer-when-downgrade\" rel=\"noopener noreferrer\"><span>Preparedness Framework⁠</span>⁠<span>(opens in a new window)</span></a><span>. While GPT‑5.2-Codex has not yet reached ‘High’ level of cyber capability, we are preparing for future models that cross that threshold. Due to the increased cyber capabilities, we have added additional </span><span>safeguards in the model</span><span> and in the product, which are outlined in the </span><a href=\"https://openai.com/index/gpt-5-2-codex-system-card\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>system card</span></u>⁠</a><span>.</span></p><div id=\"real-world-cyber-capabilities\"><p></p><h2><span>Real-world cyber capabilities</span></h2><p></p></div><p><span>Modern society runs on software, and its reliability depends on strong cybersecurity—keeping critical systems in banking, healthcare, communications, and essential services online, protecting sensitive data, and ensuring people can trust the software they rely on every day. Vulnerabilities can exist long before anyone knows about them, and finding, validating, and fixing them often depends on a community of engineers and independent security researchers equipped with the right tools.</span></p><p><span>On December 11, 2025, the React team published three security vulnerabilities affecting apps built with React Server Components. What made this disclosure notable was not only the vulnerabilities themselves, but how they were uncovered.</span></p><p><span>Andrew MacPherson, a principal security engineer at Privy (a Stripe company), was using GPT‑5.1-Codex-Max with Codex CLI and other coding agents to reproduce and study a different critical React vulnerability disclosed the week prior, known as </span><a href=\"https://react.dev/blog/2025/12/03/critical-security-vulnerability-in-react-server-components\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>React2Shell</span></u>⁠<span>(opens in a new window)</span></a><span> (</span><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2025-55182\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>CVE-2025-55182</span></u>⁠<span>(opens in a new window)</span></a><span>). His goal was to evaluate how well the model could assist with real-world vulnerability research.</span></p><p><span>He initially attempted several zero-shot analyses, prompting the model to examine the patch and identify the vulnerability it addressed. When that did not yield results, he shifted to a higher-volume, iterative prompting approach. When those approaches did not succeed, he guided Codex through standard defensive security workflows—setting up a local test environment, reasoning through potential attack surfaces, and using fuzzing to probe the system with malformed inputs. While attempting to reproduce the original React2Shell issue, Codex surfaced unexpected behaviors that warranted deeper investigation. Over the course of a single week, this process led to the discovery of previously unknown vulnerabilities, which were responsibly disclosed to the React team.</span></p><p><span>This demonstrates how advanced AI systems can materially accelerate defensive security work in widely used, real-world software. At the same time, capabilities that help defenders move faster can also be misused by bad actors.</span></p><p><span>As agentic systems become more capable in cybersecurity-relevant tasks, we are making it a core priority to ensure these advances are deployed responsibly—pairing every gain in capability with stronger safeguards, tighter access controls, and ongoing collaboration with the security community.</span></p><div id=\"empowering-cyberdefense-through-trusted-access\"><p></p><h2><span>Empowering cyberdefense through trusted access</span></h2><p></p></div><p><span>Security teams can run into restrictions when attempting to emulate threat actors, analyze malware to support remediation, or stress test critical infrastructure. We are developing a trusted access pilot to remove that friction for qualifying users and organizations and enable trusted defenders to use frontier AI cyber capabilities to accelerate cyberdefense.</span></p><p><span>Initially the pilot program will be invite-only for vetted security professionals with a track record of responsible vulnerability disclosure and organizations with a clear professional cybersecurity use case. Qualifying participants will get access to our most capable models for defensive use-cases to enable legitimate dual-use work.</span></p><p><span>If you’re a security professional or part of an organization doing ethical security work like vulnerability research or authorized red-teaming, we invite you to express interest in joining and share feedback on what you’d like to see from the program </span><a href=\"https://docs.google.com/forms/d/e/1FAIpQLSea_ptovrS3xZeZ9FoZFkKtEJFWGxNrZb1c52GW4BVjB2KVNA/viewform\" target=\"_blank\" rel=\"noopener noreferrer\"><span>here</span>⁠<span>(opens in a new window)</span></a><span>. </span></p><div id=\"conclusion\"><p></p><h2><span>Conclusion</span></h2><p></p></div><p><span>GPT‑5.2-Codex represents a step forward in how advanced AI can support real-world software engineering and specialized domains like cybersecurity—helping developers and defenders tackle complex, long-horizon work, and strengthening the tools available for responsible security research.</span></p><p><span>By rolling GPT‑5.2-Codex out gradually, pairing deployment with safeguards, and working closely with the security community, we’re aiming to maximize defensive impact while reducing the risk of misuse. What we learn from this release will directly inform how we expand access over time as the software and cyber frontiers continue to advance.</span></p></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/6LIpGEEENB5lAfUNbRi0ey/8f42edb6e74d7d0b6f2541d409ba8553/OAI_GPT-5.2-Codex_ArtCard_16x9..png?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/index/gpt-5-2-codex-system-card",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/gpt-5-2-codex-system-card",
    "title": "Addendum to GPT-5.2 System Card: GPT-5.2-Codex",
    "publishedAt": "Thu, 18 Dec 2025 00:00:00 GMT",
    "fetchedAt": "2026-01-25T19:07:59.002Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><article><div><div id=\"introduction\"><p></p><h2><span>Introduction</span></h2><p></p></div><p><span>GPT‑5.2-Codex is our most advanced agentic coding model yet for complex, real-world software engineering. A version of </span><a href=\"https://openai.com/index/introducing-gpt-5-2/\" target=\"_blank\" rel=\"noopener noreferrer\"><span>GPT‑5.2</span>⁠</a><span> optimized for agentic coding in Codex, it includes further improvements on long-horizon work through context compaction, stronger performance on project-scale tasks like refactors and migrations, and improved performance in Windows environments—and significantly stronger cybersecurity capabilities.</span></p><p><span>This system card outlines the comprehensive safety measures implemented for GPT‑5.2-Codex. It details both model-level mitigations, such as specialized safety training for harmful tasks and prompt injections, and product-level mitigations like agent sandboxing and configurable network access.</span></p><p><span>GPT‑5.2-Codex was evaluated under our Preparedness Framework. It is very capable in the cybersecurity domain but does not reach High capability on cybersecurity. We expect current trends of rapidly increasing capability to continue, and for models to cross the High cybersecurity threshold in the near future. Like other recent models, it is being treated as High capability on biology, and is being deployed with the corresponding suite of safeguards we use for other models in the GPT‑5 family. It does not reach High capability on AI self-improvement.</span></p></div><section id=\"citations\" data-testid=\"citations\"><ul><li><a href=\"https://openai.com/research/index/?tags=2025\" target=\"_blank\" rel=\"noopener noreferrer\">2025</a></li><li><a href=\"https://openai.com/research/index/?tags=system-cards\" target=\"_blank\" rel=\"noopener noreferrer\">System Cards</a></li></ul></section></article></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/5yWE86ZHPrDyMI6q1qEI1U/ede21fab984d3fb9e5638320f6a4e74d/GPT-5.2-Codex-systemcard_16x9.png?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/index/new-chatgpt-images-is-here",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/new-chatgpt-images-is-here",
    "title": "The new ChatGPT Images is here",
    "publishedAt": "Tue, 16 Dec 2025 00:00:00 GMT",
    "fetchedAt": "2026-01-25T19:07:59.579Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div><p><b><span>Project Leadership</span></b></p><p><span>Gabriel Goh — Research Lead</span></p><p><span>Adele Li — Product Lead</span></p><p><span>Bill Peebles — Sora Lead&nbsp;</span></p><p><span>Aditya Ramesh — World Simulation Lead</span></p><p><span>Mark Chen — Chief Research Officer</span></p><p><span>Prafulla Dhariwal — Multimodal Lead</span></p><p><b><span>Core Team&nbsp;</span></b></p><p><span>Alex Fang, Alex Yu, Ben Wang, Bing Liang, Boyuan Chen, Charlie Nash, David Medina, Dibya Bhattacharjee, Jianfeng Wang, Kenji Hata, Kiwhan Song, Mengchao Zhong, Mike Starr, Yuguang Yang</span></p><p><b><span>Research Contributors</span></b></p><p><span>Bram Wallace, Dmytro Okhonko, Haitang Hu, Kshitij Gupta, Li Jing, Lu Liu, Peter Zhokhov, Qiming Yuan, Senthil Purushwalkam, Yizhen Zhang</span></p><p><b><span>Core Inference</span></b></p><p><span>Adam Tart, Alyssa Huang, Andrew Braunstein, Jane Park, Karen Li, Tomer Kaftan</span></p><p><b><span>Research Collaborators</span></b></p><p><span>Aditya Ramesh, Alex Nichol, Andrew Kondrich, Andrew Liu, Benedikt Winter, Bill Peebles, Connor Holmes, Cyril Zhang, Daniel Geng, Eric Mintun, James Betker, Jamie Kiros, Manuka Stratta, Martin Li, Raoul de Liedekerke, Ricky Wang, Ruslan Vasilev, Vladimir Chalyshev, Welton Wang, Wyatt Thompson, Yaming Lin</span></p><p><b><span>Inference Collaborators</span></b></p><p><span>Jiayu Bai, Kevin King, Stanley Hsieh, Weiyi Zheng</span></p><p><b><span>Data &amp; Evaluation</span></b></p><p><span>Alexandra Barr, Aparna Dutta, Arshi Bhatnagar, Chao Yu, Charlotte Cole, Dragos Oprica, Emma Tang, Gowrishankar Sunder, Henry Baer, Ian Sohl, </span><span>James Park Lennon</span><span>, Jason Xu, Peilin Yang, Somay Jain, Szi-chieh Yu, Wesam Manassra, Xiaolei Zhu, Yilei Qian</span></p><p><b><span>Applied</span></b></p><p><span>Affonso Reis, Alan Gou, Alexandra Vodopianova, Amandeep Grewal, Andi Liu, Andrew Sima, Angus Fletcher, Antonia Woodford, Arun Eswara, Benny Wong, Bharat Rangan, Boyang Niu, Bridget Collins, Bryan Brandow, Callie Riggins Zetino, Chris Wendel, Ethan Chang, Gilman Tolle, Greg Hochmuth, Ibrahim Okuyucu, Jesse Chand, Jesse Hendrickson, Jiayu Bai, Jimmy Lin, Johan Cervantes, Kan Wu, Liam Esparraguera, Maja Wichrowska, Matthew Ferrari, Murat Yesildal, Nikunj Handa, Nithanth Kudige, Ola Okelola, Osman Khwaja, Peter Argany, Peter Bakkum, Peter Vidani, Richard Zadorozny, Rohan Sahai, Savelii Bondini, Sean Chang, Vickie Duong, Victoria Huang, Xiaolin Hao, Xueqing Li</span></p><p><b><span>Safety, Safety Systems, Integrity, Policy &amp; Trust</span></b></p><p><span>Abby Fanlo Susk, Adam Wells, Aleah Houze, Annie Cheng, Artyi Xu, Carolina Paz, David Abelman, Femi Alamu, Jay Wang, Jeremiah Currier, Jesika Haria, Mariya Guryeva, Max Burkhardt, Paige Walker, Pedro Aguilar, Rutsu Koshimizu, Sam Toizer, Savannah Heon, Tom Rubin, Tonia Osadebe, Willow Primack, Zoe Stoll</span></p><p><b><span>Product Operations, Program Management and Governance</span></b></p><p><span>Antonio Di Francesco, Filippo Raso, Grace Wu, Josh Metherd, Ruth Costigan</span></p><p><b><span>Legal</span></b></p><p><span>Ally Bennett, Tony Song, Tyce Walters</span></p><p><b><span>Communications, Marketing, Community, Design &amp; Creative</span></b></p><p><span>Akash Iyer, Alex Baker-Whitcomb, Angie Luo, Anne Oburgh, Antonia Richmond, Annie Tsang, Ashley Tyra, Bailey Richardson, Brandon McGraw, Cary Hudson, Dana Palmie, Evan Corrigan, Gaby Raila, Indgila Samad Ali, James Anderson, Jeremy Schwartz, Jordan Liss, Juan Garza, Julie Steele, Kara Zichittella, Karn Piluntanadilok, Kendal Peirce, Kim Baschet, Leah Anise, Livvy Pierce, Maria Clara M. Fleury Osorio, Minnia Feng, Nick Ciffone, Nick Forland, Niko Felix, Paige Ford, Rachel Puckett, Rishabh Aggarwal, Rusty Rupprecht, Souki Mansoor, Tasia Potasinski, Taya Christianson, Vasundhara Mudgil, Whitney Ferris, Yara Khakbaz, Zach Brock, Zoë Silverman</span></p><p><b><span>Special Thanks</span></b></p><p><span>Amy Yang, Arvin Wu, Avital Oliver, Brandon McKinzie, Chak Li, Chris Lu, David Duxin, Dian Ang Yap, Gabriel Petersson, Guillaume Leclerc, Hazel Byrne, Henry Aspegren, Jennifer Luckenbill, Ji Lin, Joseph Mo, Julius Hochmuth, Liunian (Harold) Li, Long Ouyang, Mariano López, Michael Zhang, Ravi Teja Mullapudi, Suvansh Sanjeev, Varun Shetty, Wenda Zhou</span></p><p><b><span>Exec</span></b></p><p><span>Fidji Simo, Hannah Wong, Jakub Pachocki, Jason Kwon, Johannes Heidecke, Kate Rouch, Lauren Itow, Mark Chen, Mia Glaese, Nick Ryder, Nick Turley, Prafulla Dhariwal, Sam Altman, Sulman Choudhry</span></p></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/2clJpB589bJQ2f7FtkSaox/0cb8d78adf9626e2d4c4bab3e940a2e5/Image_Gen_Blog_Art_Card_1960x1080.png?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://deepmind.google/blog/alphaearth-foundations-helps-map-our-planet-in-unprecedented-detail/",
    "sourceType": "rss",
    "sourceName": "DeepMind Blog",
    "url": "https://deepmind.google/blog/alphaearth-foundations-helps-map-our-planet-in-unprecedented-detail/",
    "title": "AlphaEarth Foundations helps map our planet in unprecedented detail",
    "publishedAt": "Fri, 24 Oct 2025 19:06:32 +0000",
    "fetchedAt": "2026-01-25T19:07:58.372Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div id=\"page-content\">\n      \n  <div>\n          <p><span>\n              July 30, 2025\n            </span>\n            <span>\n              Science\n            </span>\n          </p>\n          \n            \n          \n          \n            \n          \n          \n          \n\n\n\n\n        </div>\n  \n    \n\n\n\n\n  <div>\n  <p data-block-key=\"xcv27\">New AI model integrates petabytes of Earth observation data to generate a unified data representation that revolutionizes global mapping and monitoring</p><p data-block-key=\"4f5tl\">Every day, satellites capture information-rich images and measurements, providing scientists and experts with a nearly real-time view of our planet. While this data has been incredibly impactful, its complexity, multimodality and refresh rate creates a new challenge: connecting disparate datasets and making use of them all effectively.</p><p data-block-key=\"ci6ff\">Today, we’re introducing AlphaEarth Foundations, an artificial intelligence (AI) model that functions like a virtual satellite. It accurately and efficiently characterizes the planet’s entire terrestrial land and coastal waters by integrating huge amounts of Earth observation data into a unified digital representation, or \"<a href=\"https://developers.google.com/machine-learning/crash-course/embeddings/embedding-space?utm_source=deepmind.google&amp;utm_medium=referral&amp;utm_campaign=gdm&amp;utm_content=\" rel=\"noopener noreferrer\" target=\"_blank\">embedding,</a>\" that computer systems can easily process. This allows the model to provide scientists with a more complete and consistent picture of our planet's evolution, helping them make more informed decisions on critical issues like food security, deforestation, urban expansion, and water resources.</p><p data-block-key=\"ftcv8\">To accelerate research and unlock use cases, we are now releasing a collection of AlphaEarth Foundations’ annual embeddings as the <a href=\"https://developers.google.com/earth-engine/datasets/catalog/GOOGLE_SATELLITE_EMBEDDING_V1_ANNUAL?utm_source=deepmind.google&amp;utm_medium=referral&amp;utm_campaign=gdm&amp;utm_content=#description\" rel=\"noopener noreferrer\" target=\"_blank\">Satellite Embedding dataset</a> in <a href=\"https://earthengine.google.com/?utm_source=deepmind.google&amp;utm_medium=referral&amp;utm_campaign=gdm&amp;utm_content=\" rel=\"noopener noreferrer\" target=\"_blank\">Google Earth Engine</a>. Over the past year, we’ve been working with more than 50 organizations to test this dataset on their real-world applications.</p><p data-block-key=\"elk8d\">Our partners are already seeing significant benefits, using the data to better classify unmapped ecosystems, understand agricultural and environmental changes, and greatly increase the accuracy and speed of their mapping work. In this blog, we are excited to highlight some of their feedback and showcase the tangible impact of this new technology.</p>\n</div>\n\n\n  \n    \n\n\n\n\n  \n    \n\n\n\n  \n\n\n  \n    \n\n\n\n\n  <div>\n  <h2 data-block-key=\"xcv27\">How AlphaEarth Foundations works</h2><p data-block-key=\"2devn\">AlphaEarth Foundations provides a powerful new lens for understanding our planet by solving two major challenges: data overload and inconsistent information.</p><p data-block-key=\"davgs\">First, it combines volumes of information from dozens of different public sources— optical satellite images, radar, 3D laser mapping, climate simulations, and more. It weaves all this information together to analyse the world's land and coastal waters in sharp, 10x10 meter squares, allowing it to track changes over time with remarkable precision.</p><p data-block-key=\"cb8fe\">Second, it makes this data practical to use. The system's key innovation is its ability to create a highly compact summary for each square. These summaries require 16 times less storage space than those produced by other AI systems that we tested and dramatically reduces the cost of planetary-scale analysis.</p><p data-block-key=\"76ocg\">This breakthrough enables scientists to do something that was impossible until now: create detailed, consistent maps of our world, on-demand. Whether they are monitoring crop health, tracking deforestation, or observing new construction, they no longer have to rely on a single satellite passing overhead. They now have a new kind of foundation for geospatial data.</p>\n</div>\n\n\n  \n    \n\n\n\n\n  <div>\n      \n        \n        \n        \n          <figure>\n            \n              \n\n\n  \n  \n\n\n            \n            \n\n\n\n  <figcaption>\n    \n      <p data-block-key=\"zncfq\">Diagram showing how AlphaEarth Foundations works, taking non-uniformly sampled frames from a video sequence to index any position in time. This helps the model create a continuous view of the location, while explaining numerous measurements.</p>\n    \n  </figcaption>\n\n\n          </figure>\n        \n      \n    </div>\n\n\n  \n    \n\n\n\n\n  <div>\n      \n      \n        \n\n<p data-block-key=\"xcv27\">To ensure AlphaEarth Foundations was ready for real-world use, we rigorously tested its performance. When compared against both traditional methods and other AI mapping systems, AlphaEarth Foundations was consistently the most accurate. It excelled at a wide range of tasks over different time periods, including identifying land use and estimating surface properties. Crucially, it achieved this in scenarios when label data was scarce. On average, AlphaEarth Foundations had a 24% lower error rate than the models we tested, demonstrating its superior learning efficiency. Learn more in our <a href=\"https://arxiv.org/pdf/2507.22291\" rel=\"noopener noreferrer\" target=\"_blank\">paper</a>.</p>\n      \n    </div>\n\n\n  \n    \n\n\n\n\n  <div>\n      \n        \n        \n        \n          <figure>\n            \n              \n\n\n  \n  \n\n\n            \n            \n\n\n\n  <figcaption>\n    \n      <p data-block-key=\"8rp4t\">Diagram showing a global embedding field broken down into a single embedding, from left to right. Each embedding has 64 components which map to coordinates on a 64-dimensional sphere.</p>\n    \n  </figcaption>\n\n\n          </figure>\n        \n      \n    </div>\n\n\n  \n    \n\n\n\n\n  <div>\n  <h2 data-block-key=\"xcv27\">Generating custom maps with the Satellite Embedding dataset</h2><p data-block-key=\"1dk6g\">Powered by AlphaEarth Foundations, the <a href=\"https://developers.google.com/earth-engine/datasets/catalog/GOOGLE_SATELLITE_EMBEDDING_V1_ANNUAL?utm_source=deepmind.google&amp;utm_medium=referral&amp;utm_campaign=gdm&amp;utm_content=#description\" rel=\"noopener noreferrer\" target=\"_blank\">Satellite Embedding dataset</a> in Google Earth Engine is one of the largest of its kind with over 1.4 trillion embedding footprints per year. This collection of annual embeddings is already being used by organizations around the world, including the United Nations’ <a href=\"https://www.fao.org/home/en\" rel=\"noopener noreferrer\" target=\"_blank\">Food and Agriculture Organization</a>, <a href=\"https://harvardforest.fas.harvard.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Harvard Forest</a>, <a href=\"https://earthobservations.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Group on Earth Observations</a>, <a href=\"https://brasil.mapbiomas.org/en/\" rel=\"noopener noreferrer\" target=\"_blank\">MapBiomas</a>, <a href=\"https://oregonstate.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Oregon State University</a>, the <a href=\"https://sig-gis.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Spatial Informatics Group</a> and <a href=\"https://www.stanford.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Stanford University</a>, to create powerful custom maps that drive real-world insights.</p><p data-block-key=\"4kaju\">For example, <a href=\"http://www.globalecosystemsatlas.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Global Ecosystems Atlas</a>, an initiative aiming to create the first comprehensive resource to map and monitor the world’s ecosystems, is using this dataset to help countries classify unmapped ecosystems into categories like <a href=\"https://global-ecosystems.org/explore/groups/MT2.1\" rel=\"noopener noreferrer\" target=\"_blank\">coastal shrublands</a> and <a href=\"https://global-ecosystems.org/explore/groups/T5.5\" rel=\"noopener noreferrer\" target=\"_blank\">hyper-arid deserts</a>. This first of its kind resource will play a critical role in helping countries better prioritize conservation areas, optimize restoration efforts, and combat the loss of biodiversity.</p>\n</div>\n\n\n  \n    \n\n\n\n\n  <div>\n      \n      \n        \n\n<figure>\n  <blockquote>\n    <p data-block-key=\"723k3\">The Satellite Embedding dataset is revolutionizing our work by helping countries map uncharted ecosystems - this is crucial for pinpointing where to focus their conservation efforts.</p>\n  </blockquote>\n  \n\n<figcaption>\n  \n  <span>\n    <p>Nick Murray</p>\n    \n      <p>Director of the James Cook University Global Ecology Lab and Global Science Lead of Global Ecosystems Atlas</p>\n    \n  </span>\n</figcaption>\n\n  \n</figure>\n\n      \n    </div>\n\n\n  \n    \n\n\n\n\n  <div>\n  <p data-block-key=\"xcv27\">In Brazil, <a href=\"https://brasil.mapbiomas.org/en/\" rel=\"noopener noreferrer\" target=\"_blank\">MapBiomas</a> is testing the dataset to more deeply understand agricultural and environmental changes across the country. This type of map informs conservation strategies and sustainable development initiatives in critical ecosystems like the Amazon rainforest.</p><p data-block-key=\"4v2js\">As Tasso Azevedo, founder of MapBiomas said, \"The Satellite Embedding dataset can transform the way our team works - we now have new options to make maps that are more accurate, precise and fast to produce - something we would have never been able to do before.\"</p><p data-block-key=\"8vebg\">Read more about the Satellite Embedding dataset and see tutorials in the <a href=\"https://medium.com/google-earth/ai-powered-pixels-introducing-googles-satellite-embedding-dataset-31744c1f4650\" rel=\"noopener noreferrer\" target=\"_blank\">Google Earth Engine blog</a> .</p><h2 data-block-key=\"54ivt\">Empowering others with AI</h2><p data-block-key=\"6tucs\">AlphaEarth Foundations represents a significant step forward in understanding the state and dynamics of our changing planet. We’re currently using AlphaEarth Foundations to generate annual embeddings and believe they could be even more useful in the future when combined together with general reasoning LLM agents like Gemini. We are continuing to explore the best ways to apply our model's time-based capabilities as part of <a href=\"http://blog.google/technology/ai/google-earth-ai?utm_source=deepmind.google&amp;utm_medium=referral&amp;utm_campaign=gdm&amp;utm_content=\" rel=\"noopener noreferrer\" target=\"_blank\">Google Earth AI</a>, our collection of geospatial models and datasets to help tackle the planet’s most critical needs.</p><p data-block-key=\"10qs\"><strong>Learn more about AlphaEarth Foundations</strong></p>\n</div>\n\n\n  \n    \n\n\n\n\n  <div>\n  <p data-block-key=\"xcv27\"><strong>Acknowledgements</strong></p><p data-block-key=\"5nb3d\">This work was a collaboration between teams at Google DeepMind and Google Earth Engine.</p><p data-block-key=\"d12sn\">Christopher Brown, Michal Kazmierski, Valerie Pasquarella, William Rucklidge, Masha Samsikova, Olivia Wiles, Chenhui Zhang, Estefania Lahera, Evan Shelhamer, Simon Ilyushchenko, Noel Gorelick, Lihui Lydia Zhang, Sophia Alj, Emily Schechter, Sean Askay, Oliver Guinan, Rebecca Moore, Alexis Boukouvalas, Pushmeet Kohli</p>\n</div>\n\n\n  \n\n    </div></div>",
    "imageUrl": "https://lh3.googleusercontent.com/u-WehoHpTbl255uLNpdOf9qI2vMtx9YXHD5RRh643vCNYUbjHJGCJYfjYfLrIBn8kz74dVPDLIhQ5J2_dpPhgnjiyq0XMeFhrZWNyxHB=w528-h297-n-nu-rw-lo",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://deepmind.google/blog/how-ai-is-helping-advance-the-science-of-bioacoustics-to-save-endangered-species/",
    "sourceType": "rss",
    "sourceName": "DeepMind Blog",
    "url": "https://deepmind.google/blog/how-ai-is-helping-advance-the-science-of-bioacoustics-to-save-endangered-species/",
    "title": "How AI is helping advance the science of bioacoustics to save endangered species",
    "publishedAt": "Fri, 24 Oct 2025 02:30:54 +0000",
    "fetchedAt": "2026-01-25T19:07:59.317Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div id=\"page-content\">\n      \n  <div>\n          <p><span>\n              August 7, 2025\n            </span>\n            <span>\n              Science\n            </span>\n          </p>\n          \n            \n          \n          \n            \n          \n          \n          \n\n\n\n\n        </div>\n  \n    \n\n\n\n\n  <div>\n  <p data-block-key=\"dmg0w\">Our new Perch model helps conservationists analyze audio faster to protect endangered species, from Hawaiian honeycreepers to coral reefs.</p><p data-block-key=\"ahnut\">One of the ways scientists protect the health of our planet’s wild ecosystems is by using microphones (or underwater hydrophones) to collect vast amounts of audio dense with vocalizations from birds, frogs, insects, whales, fish and more. These recordings can tell us a lot about the animals present in a given area, along with other clues about the health of that ecosystem. Making sense of so much data, however, remains a massive undertaking.</p><p data-block-key=\"7nsp1\">Today, we are releasing an update to <a href=\"http://arxiv.org/abs/2508.04665\" rel=\"noopener noreferrer\" target=\"_blank\">Perch</a>, our AI model designed to help conservationists analyze bioacoustic data. This new model has better state-of-the-art off-the-shelf bird species predictions than the previous model. It can better adapt to new environments, particularly underwater ones like coral reefs. It’s trained on a wider range of animals, including mammals, amphibians and anthropogenic noise — nearly twice as much data in all, from public sources like <a href=\"https://xeno-canto.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Xeno-Canto</a> and <a href=\"https://neurips.cc/virtual/2024/poster/97701\" rel=\"noopener noreferrer\" target=\"_blank\">iNaturalist</a>. It can disentangle complex acoustic scenes over thousands or even millions of hours of audio data. And it’s versatile, able to help answer many different kinds of questions, from “how many babies are being born” to “how many individual animals are present in a given area.”</p><p data-block-key=\"52hg1\">In order to help scientists protect our planet’s ecosystems, we’re releasing this new version of Perch as an open model and making it available on <a href=\"https://www.kaggle.com/models/google/bird-vocalization-classifier/tensorFlow2/perch_v2\" rel=\"noopener noreferrer\" target=\"_blank\">Kaggle</a>.</p>\n</div>\n\n\n  \n    \n\n\n\n\n  <div>\n      \n        \n        \n        \n          <figure>\n            \n              \n\n\n  \n  \n\n\n            \n            \n\n\n\n  <figcaption>\n    \n      <p data-block-key=\"ej3zu\">Perch not only recognizes the sound of bird species. Our new model was trained on a wider range of animals including mammals, amphibians and anthropogenic noise.</p>\n    \n  </figcaption>\n\n\n          </figure>\n        \n      \n    </div>\n\n\n  \n    \n\n\n\n\n  <div>\n  <h2 data-block-key=\"dmg0w\">Success Stories: Perch in the Field</h2><p data-block-key=\"7ggf\">Since it was first launched in 2023, the initial version of Perch has already been <a href=\"https://www.kaggle.com/models/google/bird-vocalization-classifier\" rel=\"noopener noreferrer\" target=\"_blank\">downloaded over 250,000 times</a> and its openly available solutions are now well-integrated into tools for working biologists. For example, Perch’s vector search library is now part of Cornell's widely-used <a href=\"https://github.com/birdnet-team/BirdNET-Analyzer\" rel=\"noopener noreferrer\" target=\"_blank\">BirdNet Analyzer</a>.</p><p data-block-key=\"7idpm\">In addition, Perch is helping BirdLife Australia and the Australian Acoustic Observatory build classifiers for a number of unique Australian species. For example, our tools enabled the <a href=\"https://www.theguardian.com/environment/2025/feb/12/plains-wanderers-spotted-in-melbournes-west-for-first-time-in-30-years-with-help-of-ai\" rel=\"noopener noreferrer\" target=\"_blank\">discovery</a> of a new population of the elusive Plains Wanderer.</p>\n</div>\n\n\n  \n    \n\n\n\n\n  <div>\n      \n      \n        \n\n<figure>\n  <blockquote>\n    <p data-block-key=\"ooybp\">This is an incredible discovery – acoustic monitoring like this will help shape the future of many endangered bird species.</p>\n  </blockquote>\n  \n\n<figcaption>\n  \n  <span>\n    <p>Paul Roe</p>\n    \n      <p>Dean Research, James Cook University, Australia</p>\n    \n  </span>\n</figcaption>\n\n  \n</figure>\n\n      \n    </div>\n\n\n  \n    \n\n\n\n\n  <div>\n  <p data-block-key=\"dmg0w\">Recent work has also found that the earlier version of Perch can be used to <a href=\"https://www.sciencedirect.com/science/article/pii/S1574954125003395\" rel=\"noopener noreferrer\" target=\"_blank\">identify individual birds</a> and <a href=\"https://www.sciencedirect.com/science/article/pii/S1470160X24013876\" rel=\"noopener noreferrer\" target=\"_blank\">track bird abundance</a>, potentially reducing the need for catch-and-release studies to monitor populations.</p><p data-block-key=\"13el4\">Finally, biologists from the <a href=\"https://lohelab.org/\" rel=\"noopener noreferrer\" target=\"_blank\">LOHE Bioacoustics Lab</a> at the University of Hawaiʻi have used it to monitor and protect populations of honeycreepers, which are important to <a href=\"https://www.mauiforestbirds.org/cultural-significance\" rel=\"noopener noreferrer\" target=\"_blank\">Hawaiian mythology</a> and face extinction from the threat of avian malaria spread by non-native mosquitoes. Perch helped the LOHE Lab find honeycreeper sounds nearly 50x faster than their usual methods, enabling them to monitor more species of honeycreeper over greater areas. We expect the new model will further accelerate these efforts.</p>\n</div>\n\n\n  \n    \n\n\n\n\n  \n\n\n  \n    \n\n\n\n\n  <div>\n  <h2 data-block-key=\"dmg0w\">Untangling the Planet's Playlist</h2><p data-block-key=\"d7e13\">The Perch model can predict which species are present in a recording, but that's only part of the story: We also provide <a href=\"https://github.com/google-research/perch-hoplite\" rel=\"noopener noreferrer\" target=\"_blank\">tools</a> that allow scientists to quickly build new classifiers starting from a single example and monitor species for which there is scarce training data or for very specific sounds like juvenile calls. Given one example of a sound, vector search with Perch surfaces the most similar sounds in a dataset. A local expert can then mark the search results as relevant or irrelevant to train a classifier.</p><p data-block-key=\"e3o5b\">Together, this combination of vector search and active learning with a strong embedding model is called <a href=\"https://openaccess.thecvf.com/content/ICCV2023/papers/Stretcu_Agile_Modeling_From_Concept_to_Classifier_in_Minutes_ICCV_2023_paper.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">agile modeling</a><strong><em>.</em></strong> Our recent paper–<a href=\"https://arxiv.org/abs/2505.03071\" rel=\"noopener noreferrer\" target=\"_blank\">\"The Search for Squawk: Agile Modeling in Bioacoustics\"</a>–shows that this method works across birds and coral reefs, allowing the creation of high quality classifiers in under an hour.</p><h2 data-block-key=\"61c5u\">Looking ahead: the future of bioacoustics</h2><p data-block-key=\"emd8l\">Together, our models and methods are helping maximize the impact of conservation efforts, leaving more time and resources for meaningful, on-the-ground work. From the forests of Hawaiʻi to the reefs of the ocean, the Perch project showcases the profound impact we can have when we apply our technical expertise to the world's most pressing challenges. Every classifier built and every hour of data analyzed brings us closer to a world where the soundtrack of our planet is one of rich, thriving biodiversity.</p>\n</div>\n\n\n  \n    \n\n\n\n\n  <div>\n      \n      \n        \n\n<p data-block-key=\"dmg0w\"><strong>Learn more</strong></p>\n      \n        \n\n\n\n      \n    </div>\n\n\n  \n    \n\n\n\n\n  <div>\n  <p data-block-key=\"dmg0w\"><strong>Acknowledgements</strong></p><p data-block-key=\"77cbt\">This research was developed by the Perch team: Bart van Merriënboer, Jenny Hamer, Vincent Dumoulin, Lauren Harrell, and Tom Denton, and Otilia Stretcu from Google Research. We also thank our collaborators Amanda Navine and Pat Hart at the University of Hawaiʻi, and Holger Klinck, Stefan Kahl and the BirdNet team at the Cornell Lab of Ornithology. And all our friends and collaborators whom we would have written about in this blog post if only we had another thousand words.</p>\n</div>\n\n\n  \n\n    </div></div>",
    "imageUrl": "https://lh3.googleusercontent.com/JLzNTXJm3J0aWxz8FO25cr4uUrQTf1QoUbt64IQLPROF92VXEVeZIwsNRgoy29vtqMX6dpa01A1iy8qlvA0ngM3n1V7c1ILe9Rk0B3a0Cw=w528-h297-n-nu-rw-lo",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://deepmind.google/blog/introducing-codemender-an-ai-agent-for-code-security/",
    "sourceType": "rss",
    "sourceName": "DeepMind Blog",
    "url": "https://deepmind.google/blog/introducing-codemender-an-ai-agent-for-code-security/",
    "title": "Introducing CodeMender: an AI agent for code security",
    "publishedAt": "Thu, 23 Oct 2025 23:05:51 +0000",
    "fetchedAt": "2026-01-25T19:07:59.170Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div id=\"page-content\">\n      \n  <div>\n          <p><span>\n              October 6, 2025\n            </span>\n            <span>\n              Responsibility &amp; Safety\n            </span>\n          </p>\n          \n            \n          \n          \n            \n          \n          \n          \n\n\n\n\n        </div>\n  \n    \n\n\n\n\n  <div id=\"intro\">\n  <p data-block-key=\"0n63j\">Using advanced AI to fix critical software vulnerabilities</p><p data-block-key=\"3l1s9\">Today, we’re sharing early results from our research on CodeMender, a new AI-powered agent that improves code security automatically.</p><p data-block-key=\"a3vc6\">Software vulnerabilities are notoriously difficult and time-consuming for developers to find and fix, even with traditional, automated methods like fuzzing. Our AI-based efforts like <a href=\"https://googleprojectzero.blogspot.com/2024/10/from-naptime-to-big-sleep.html?utm_source=&amp;utm_medium=&amp;utm_campaign=&amp;utm_content=\" rel=\"noopener noreferrer\" target=\"_blank\">Big Sleep</a> and <a href=\"https://security.googleblog.com/2023/08/ai-powered-fuzzing-breaking-bug-hunting.html?utm_source=&amp;utm_medium=&amp;utm_campaign=&amp;utm_content=\" rel=\"noopener noreferrer\" target=\"_blank\">OSS-Fuzz</a> have demonstrated AI’s ability to find new zero-day vulnerabilities in well-tested software. As we achieve more breakthroughs in AI-powered vulnerability discovery, it will become increasingly difficult for humans alone to keep up.</p><p data-block-key=\"ci3a8\">CodeMender helps solve this problem by taking a comprehensive approach to code security that’s both reactive, instantly patching new vulnerabilities, and proactive, rewriting and securing existing code and eliminating entire classes of vulnerabilities in the process. Over the past six months that we’ve been building CodeMender, we have already upstreamed 72 security fixes to open source projects, including some as large as 4.5 million lines of code.</p><p data-block-key=\"c2me\">By automatically creating and applying high-quality security patches, CodeMender’s AI-powered agent helps developers and maintainers focus on what they do best — building good software.</p><h2 data-block-key=\"1leto\">CodeMender in action</h2><p data-block-key=\"d6ea1\">CodeMender operates by leveraging the thinking capabilities of recent <a href=\"https://blog.google/products/gemini/gemini-2-5-deep-think/?utm_source=&amp;utm_medium=&amp;utm_campaign=&amp;utm_content=\" rel=\"noopener noreferrer\" target=\"_blank\">Gemini Deep Think</a> models to produce an autonomous agent capable of debugging and fixing complex vulnerabilities.</p><p data-block-key=\"ecg1c\">To do this, the CodeMender agent is equipped with robust tools that let it reason about code before making changes, and automatically validate those changes to make sure they’re correct and don’t cause regressions.</p>\n</div>\n\n\n  \n    \n\n\n\n\n  <div id=\"video\">\n      \n        \n        \n        \n          <figure>\n            \n              \n\n\n\n  \n    \n    \n      <figure>\n        \n        \n        \n      </figure>\n    \n  \n\n\n            \n            \n\n\n\n  <figcaption>\n    \n      <p data-block-key=\"15fui\">Animation showing CodeMender’s process for fixing vulnerabilities.</p>\n    \n  </figcaption>\n\n\n          </figure>\n        \n      \n    </div>\n\n\n  \n    \n\n\n\n\n  <div id=\"text\">\n  <p data-block-key=\"0n63j\">While large language models are rapidly improving, mistakes in code security could be costly. CodeMender’s automatic validation process ensures that code changes are correct across many dimensions by only surfacing for human review high-quality patches that, for example, fix the root cause of the issue, are functionally correct, cause no regressions and follow style guidelines.</p><p data-block-key=\"4nfid\">As part of our research, we also developed new techniques and tools that let CodeMender reason about code and validate changes more effectively. This includes:</p><ul><li data-block-key=\"d921o\"><strong>Advanced program analysis:</strong> We developed tools based on advanced program analysis that include static analysis, dynamic analysis, differential testing, fuzzing and SMT solvers. Using these tools to systematically scrutinize code patterns, control flow and data flow, CodeMender can better identify the root causes of security flaws and architectural weaknesses.</li><li data-block-key=\"e9lnc\"><strong>Multi-agent systems:</strong> We developed special-purpose agents that enable CodeMender to tackle specific aspects of an underlying problem. For example, CodeMender uses a large language model-based critique tool that highlights the differences between the original and modified code in order to verify that the proposed changes do not introduce regressions, and self-correct as needed.</li></ul><h2 data-block-key=\"5fvjc\">Fixing vulnerabilities</h2><p data-block-key=\"168ts\">To effectively patch a vulnerability, and prevent it from re-emerging, Code Mender uses a debugger, source code browser, and other tools to pinpoint root causes and devise patches. We have added two examples of CodeMender patching vulnerabilities in the video carousel below.</p><p data-block-key=\"ds6s\"><strong>Example #1: Identifying the root cause of a vulnerability</strong></p><p data-block-key=\"91i3h\">Here’s a snippet of the agent's reasoning about the root cause for a CodeMender-generated patch, after analyzing the results of debugger output and a code search tool.</p><p data-block-key=\"91fa0\">Although the final patch in this example only changed a few lines of code, the root cause of the vulnerability was not immediately clear. In this case, the crash report showed a heap buffer overflow, but the actual problem was elsewhere — an incorrect stack management of Extensible Markup Language (XML) elements during parsing.</p><p data-block-key=\"180p2\"><strong>Example #2: Agent is able to create non-trivial patches</strong></p><p data-block-key=\"fdbfe\">In this example, the CodeMender agent was able to come up with a non-trivial patch that deals with a complex object lifetime issue.</p><p data-block-key=\"cqqnk\">The agent was not only able to figure out the root cause of the vulnerability, but was also able to modify a completely custom system for generating C code within the project.</p>\n</div>\n\n\n  \n    \n\n\n\n\n  \n    \n\n\n\n  \n\n\n  \n    \n\n\n\n\n  <div id=\"text\">\n  <h2 data-block-key=\"0n63j\">Proactively rewriting existing code for better security</h2><p data-block-key=\"3jv9\">We also designed CodeMender to proactively rewrite existing code to use more secure data structures and APIs.</p><p data-block-key=\"fobm7\">For example, we deployed CodeMender to apply <a href=\"https://clang.llvm.org/docs/BoundsSafety.html\" rel=\"noopener noreferrer\" target=\"_blank\">-fbounds-safety</a> annotations to parts of a widely used image compression library called <a href=\"https://github.com/webmproject/libwebp\" rel=\"noopener noreferrer\" target=\"_blank\">libwebp</a>. When <strong>-fbounds-safety</strong> annotations are applied, the compiler adds bounds checks to the code to prevent an attacker from exploiting a buffer overflow or underflow to execute arbitrary code.</p><p data-block-key=\"27s5\">A few years ago, a heap buffer overflow vulnerability in libwebp (<a href=\"https://www.cve.org/CVERecord?id=CVE-2023-4863\" rel=\"noopener noreferrer\" target=\"_blank\">CVE-2023-4863</a>) was used by a threat actor as part of <a href=\"https://citizenlab.ca/2023/09/blastpass-nso-group-iphone-zero-click-zero-day-exploit-captured-in-the-wild/\" rel=\"noopener noreferrer\" target=\"_blank\">a zero-click iOS exploit</a>. With <strong>-fbounds-safety</strong> annotations, this vulnerability, along with most other buffer overflows in the project where we've applied annotations, would’ve been rendered unexploitable forever.</p><p data-block-key=\"7im7j\">In the video carousel below we show examples of the agent’s decision-making process, including the validation steps.</p><p data-block-key=\"4kdr5\"><strong>Example #1: Agent’s reasoning steps</strong></p><p data-block-key=\"c9ge1\">In this example, the CodeMender agent is asked to address the following <strong>-fbounds-safety</strong> error on <strong>bit_depths</strong> pointer:</p>\n</div>\n\n\n  \n    \n\n\n\n\n  \n\n\n  \n    \n\n\n\n\n  <div id=\"text\">\n  <p data-block-key=\"0n63j\"><strong>Example #2: Agent automatically corrects errors and test failures</strong></p><p data-block-key=\"73lpi\">Another of CodeMender’s key features is its ability to automatically correct new errors and any test failures that arise from its own annotations. Here is an example of the agent recovering from a compilation error.</p><p data-block-key=\"ao0vh\"><strong>Example #3: Agent validates the changes</strong></p><p data-block-key=\"deic2\">In this example, the CodeMender agent modifies a function and then uses the LLM judge tool configured for functional equivalence to verify that the functionality remains intact. When the tool detects a failure, the agent self-corrects based on the LLM judge's feedback.</p>\n</div>\n\n\n  \n    \n\n\n\n\n  \n    \n\n\n\n  \n\n\n  \n    \n\n\n\n\n  <div id=\"text\">\n  <h2 data-block-key=\"0n63j\">Making software secure for everyone</h2><p data-block-key=\"8mmhf\">While our early results with CodeMender are promising, we’re taking a cautious approach, focusing on reliability. Currently, all patches generated by CodeMender are reviewed by human researchers before they’re submitted upstream.</p><p data-block-key=\"g5ea\">Using CodeMender, we've already begun submitting patches to various critical open-source libraries, many of which have already been accepted and upstreamed. We’re gradually ramping up this process to ensure quality and systematically address feedback from the open-source community.</p><p data-block-key=\"b02pi\">We’ll also be gradually reaching out to interested maintainers of critical open source projects with CodeMender-generated patches. By iterating on feedback from this process, we hope to release CodeMender as a tool that can be used by all software developers to keep their codebases secure.</p><p data-block-key=\"624at\">We will have a number of techniques and results to share, which we intend to publish as technical papers and reports in the coming months. With CodeMender, we've only just begun to explore AI’s incredible potential to enhance software security for everyone.</p>\n</div>\n\n\n  \n    \n\n\n\n\n  <div id=\"acknowledgements\">\n  <p data-block-key=\"0n63j\"><strong>Acknowledgements</strong></p><p data-block-key=\"d51jd\">Credits (listed in alphabetical order):</p><p data-block-key=\"296dq\">Alex Rebert, Arman Hasanzadeh, Carlo Lemos, Charles Sutton, Dongge Liu, Gogul Balakrishnan, Hiep Chu, James Zern, Koushik Sen, Lihao Liang, Max Shavrick, Oliver Chang and Petros Maniatis.</p>\n</div>\n\n\n  \n    \n\n\n\n\n  \n\n\n  \n\n    </div></div>",
    "imageUrl": "https://lh3.googleusercontent.com/Kk9Xc_8kX3jiPVSIwqyuhQvKCAFUkCZG0F6cR950N8JkqSP8DZaTcAv81ykTc_uQMDg3Yn7DMGLnACQZhLD3O2gLkGSTENgZXJKK93y12XE=w528-h297-n-nu-rw-lo",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://towardsdatascience.com/?p=608240",
    "sourceType": "rss",
    "sourceName": "Towards Data Science",
    "url": "https://towardsdatascience.com/air-for-tomorrow-mapping-the-digital-air-quality-landscape-repositories-data-types-starter-code/",
    "title": "Air for Tomorrow: Mapping the Digital Air-Quality Landscape, from Repositories and Data Types to Starter Code",
    "author": "Prithviraj Pramanik",
    "publishedAt": "Sat, 24 Jan 2026 13:00:00 +0000",
    "fetchedAt": "2026-01-25T19:07:58.882Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div>\n<p> road in Lao PDR. The school is 200 meters away. Traffic roars, smoke from burning garbage drifts across the path, and children walk straight through it. What are they breathing today? Without local data, no one really knows.&nbsp;</p>\n\n\n\n<div><p>Across East Asia and the Pacific,&nbsp;<strong>325</strong>&nbsp;million children [<a href=\"https://www.unicef.org/press-releases/silent-killer-over-100-daily-deaths-children-under-five-linked-air-pollution-east\" target=\"_blank\" rel=\"noopener noreferrer\">1</a>] breathe toxic air every day, sometimes at levels 10 times above safe limits. The damage is often silent: affected lungs, asthma, but it can lead to missed school days in acute cases. The futures are at stake. In the long run, the health systems are strained, and economies have to bear the costs.</p><p>In many cases, air quality data is not even available.</p></div>\n\n\n\n<p><strong>No monitors. No evidence. No protection.</strong>&nbsp;</p>\n\n\n\n<p>In this second part of the blog series [<a href=\"https://towardsdatascience.com/air-for-tomorrow-why-openness-in-air-quality-research-and-implementation-matters-for-global-equity/\" target=\"_blank\" rel=\"noopener noreferrer\">2</a>],&nbsp;we&nbsp;investigate&nbsp;the data repositories where useful air-quality data&nbsp;is available, how to import them,&nbsp;and how to get them up and running in&nbsp;your notebook. We would also demystify data formats such as GeoJSON, Parquet/GeoParquet, NetCDF/HDF5, COG, GRIB, and Zarr so you can pick the right tool for the job. We&nbsp;are&nbsp;building it&nbsp;up so that in the next part, we can go step by step through how&nbsp;we developed&nbsp;an open-source&nbsp;air&nbsp;quality model.&nbsp;</p>\n\n\n\n<p>In the last few years, there has been a significant push to generate and use air-quality data. These data come from&nbsp;different sources, and their quality varies accordingly. A few&nbsp;repositories can help quantify&nbsp;them: regulatory stations for ground truth, community sensors to understand hyperlocal variations, satellites for regional context, and model reanalyses for estimates&nbsp;(Figure 2). The good news: most of this is open. The better news: the code to get started is&nbsp;relatively short.&nbsp;</p>\n\n\n\n<figure><img decoding=\"async\" src=\"https://contributor.insightmediagroup.io/wp-content/uploads/2026/01/image-57.png\" alt=\"\" style=\"max-width: 100%; height: auto; border-radius: 1rem; margin: 2rem 0px;\"><figcaption>Figure 2:&nbsp;Fire hotspot as on 20.04.2024 and the interpolated density map created using multiple data sources. Source: @UNICEF. All rights reserved.</figcaption></figure>\n\n\n\n<h2>Repository&nbsp;quick-starts&nbsp;(with minimal Python)&nbsp;</h2>\n\n\n\n<p>In this section, we move from concepts to practice. Below, we walk through a set of commonly used open-source repositories and show the&nbsp;<strong>smallest possible code</strong>&nbsp;you need to start pulling data from each of them. All examples assume Python ≥3.10 with&nbsp;pip install&nbsp;as needed.&nbsp;</p>\n\n\n\n<p>For each numbered repository, you will find:&nbsp;</p>\n\n\n\n<ul>\n<li>a short description&nbsp;of what the data source is and how it is&nbsp;maintained,&nbsp;</li>\n</ul>\n\n\n\n<ul>\n<li>typical use-cases (when this source is a good fit),&nbsp;</li>\n</ul>\n\n\n\n<ul>\n<li>how to access it (API keys, sign-up notes, or direct URLs), and&nbsp;</li>\n</ul>\n\n\n\n<ul>\n<li>a minimal Python&nbsp;code&nbsp;snippet to extract data.&nbsp;</li>\n</ul>\n\n\n\n<p>Imagine&nbsp;this as a practical guide&nbsp;where you can&nbsp;skim the descriptions, pick the source that matches your problem, and then adapt the code to plug directly into your own analysis or model pipeline.&nbsp;</p>\n\n\n\n<p><strong>Tip:</strong>&nbsp;Keep secrets out of code. Use environment variables for tokens (e.g.,&nbsp;export&nbsp;AIRNOW_API_KEY=…).&nbsp;</p>\n\n\n\n<h3>1)&nbsp;OpenAQ&nbsp;(global ground measurements; open API)&nbsp;</h3>\n\n\n\n<p>OpenAQ [<a href=\"https://explore.openaq.org/\" data-type=\"link\" data-id=\"https://explore.openaq.org/\" target=\"_blank\" rel=\"noopener noreferrer\">3</a>]&nbsp;is an&nbsp;open-source&nbsp;data platform&nbsp;that&nbsp;hosts&nbsp;global data for air quality data, such as&nbsp;PM2.5,&nbsp;PM10, and O3. They provide air quality data by partnering with various&nbsp;governmental partners, community partners,&nbsp;and air quality sensor companies such as&nbsp;Air&nbsp;Gradient,&nbsp;IQAir, among others.</p>\n\n\n\n<p>Great for: quick cross-country pulls, harmonised units/metadata, reproducible pipelines.&nbsp;</p>\n\n\n\n<p>Sign up for an&nbsp;OpenAQ&nbsp;API key at https://explore.openaq.org. After signing up, find your API key in your&nbsp;settings. Use this key to authenticate requests.&nbsp;</p>\n\n\n\n<pre><code>!pip install openaq pandas</code></pre>\n\n\n\n<pre><code>import pandas as pd\nfrom pandas import json_normalize\nfrom openaq import OpenAQ\nimport datetime\nfrom datetime import timedelta\nimport geopandas as gpd\nimport requests\nimport time\nimport json\n\n# follow the quickstart to get the api key https://docs.openaq.org/using-the-api/quick-start\napi_key = '' #enter you API Key before executing\nclient = OpenAQ(api_key=api_key) #use the API key generated earlier\n\n# get the locations of every sensors in the chosen countries codes: https://docs.openaq.org/resources/countries\nlocations = client.locations.list(\ncountries_id=[68,111],\nlimit = 1000\n)\n\ndata_locations = locations.dict()\ndf_sensors_country = json_normalize(data_locations ['results'])\ndf_sensors_exploded = df_sensors_country.explode('sensors')\ndf_sensors_exploded['sensor_id']=df_sensors_exploded['sensors'].apply(lambda x: x['id'])\ndf_sensors_exploded['sensor_type']=df_sensors_exploded['sensors'].apply(lambda x: x['name'])\ndf_sensors_pm25 = df_sensors_exploded[df_sensors_exploded['sensor_type'] == \"pm25 µg/m³\"]\ndf_sensors_pm25\n\n# go through each location and extract the  hourly measurements\ndf_concat_aq_data=pd.DataFrame()\nto_date = datetime.datetime.now()\nfrom_date = to_date - timedelta(days=2) # get the past 2 days data\nsensor_list = df_sensors_pm25.sensor_id\n\nfor sensor_id in sensor_list[0:5]:\n    print(\"-----\")\n    response = client.measurements.list(\n        sensors_id= sensor_id,\n        datetime_from = from_date,\n        datetime_to = to_date,\n        limit = 500 )\n    print(response)\n\n    data_measurements = response.dict()\n    df_hourly_data = json_normalize(data_measurements ['results'])\n    df_hourly_data[\"sensor_id\"] = sensor_id\n    if len(df_hourly_data) &gt; 0:\n        df_concat_aq_data=pd.concat([df_concat_aq_data,df_hourly_data])\n        df_concat_aq_data = df_concat_aq_data[[\"sensor_id\",\"period.datetime_from.utc\",\"period.datetime_to.utc\",\"parameter.name\",\"value\"]]\n\n    df_concat_aq_data</code></pre>\n\n\n\n<h3>2) EPA AQS Data Mart (U.S. regulatory archive; token needed)&nbsp;</h3>\n\n\n\n<div><p>The EPA AQS Data Mart [<a href=\"https://aqs.epa.gov/aqsweb/documents/data_api.html\" data-type=\"link\" data-id=\"https://aqs.epa.gov/aqsweb/documents/data_api.html\" target=\"_blank\" rel=\"noopener noreferrer\">4</a>] is a U.S. regulatory data archive that hosts quality-controlled air-quality measurements from thousands of monitoring stations across the country. It provides long-term records for criteria pollutants such as PM₂․₅, PM₁₀, O₃, NO₂, SO₂, and CO, along with detailed site metadata and QA flags, and is freely accessible via an API once you register and obtain an access token. It provides meteorological data as well.&nbsp;</p><p>Great for: authoritative QA/QC-d U.S. data.&nbsp;</p></div>\n\n\n\n<p>Sign up for an AQS Data Mart account on the US EPA website at:&nbsp;<a href=\"https://aqs.epa.gov/aqsweb/documents/data_api.html\" target=\"_blank\" rel=\"noopener noreferrer\">https://aqs.epa.gov/aqsweb/documents/data_api.html</a><br>Create a .env file in your environment and add your credentials, including AQS email and AQS key.</p>\n\n\n\n<pre><code># pip install requests pandas \n\nimport os, requests, pandas as pd \nAQS_EMAIL = os.getenv(\"AQS_EMAIL\") \nAQS_KEY   = os.getenv(\"AQS_KEY\") \n\nurl = \"https://aqs.epa.gov/data/api/sampleData/byState\" \nparams = {\"email\": AQS_EMAIL, \"key\": AQS_KEY, \"param\": \"88101\", \"b date\":\"20250101\", \"edate\": \"20250107\", \"state\": \"06\"} \nr = requests.get(url, params=params, timeout=60) \n\ndf = pd.json_normalize(r.json()[\"Data\"]) \nprint(df[[\"state_name\",\"county_name\",\"date_local\",\"sample_measurement\",\"units_of_measure\"]].head()) </code></pre>\n\n\n\n<h3>3)&nbsp;AirNow&nbsp;(U.S. real-time indices; API key)&nbsp;</h3>\n\n\n\n<p>AirNow [<a href=\"https://www.airnow.gov/\" data-type=\"link\" data-id=\"https://www.airnow.gov/\" target=\"_blank\" rel=\"noopener noreferrer\">5</a>]&nbsp;is a U.S. government platform that provides near real-time air-quality index (AQI) information based on regulatory monitoring data. It publishes current and forecast AQI values for pollutants such as PM₂․₅&nbsp;and O₃, along with category breakpoints (“Good”,&nbsp;“Moderate”,&nbsp;etc.) that are easy to communicate to the public. Data can be accessed programmatically via the&nbsp;AirNow&nbsp;API once you register and obtain an API key.&nbsp;</p>\n\n\n\n<p>Great for: wildfire and public-facing AQI visuals.&nbsp;</p>\n\n\n\n<p>Register for an AirNow API account via the AirNow API portal:&nbsp;<a href=\"https://docs.airnowapi.org/\" target=\"_blank\" rel=\"noopener noreferrer\">https://docs.airnowapi.org/</a>&nbsp;</p>\n\n\n\n<p>From the Log In page, select&nbsp;“Request an&nbsp;AirNow&nbsp;API Account”&nbsp;and complete the registration form with your email and basic details. After you activate your account, you&nbsp;will find your API key in your&nbsp;AirNow&nbsp;API dashboard; use this key to authenticate all calls to the&nbsp;AirNow&nbsp;web services.&nbsp;</p>\n\n\n\n<pre><code>import os, requests, pandas as pd \n\nAPI_KEY = os.getenv(\"AIRNOW_API_KEY\") \nurl = \"https://www.airnowapi.org/aq/observation/latLong/current/\" \nparams = {\"format\":\"application/json\", \"latitude\": 37.7749, \"longitude\": -122.4194, \"distance\":25, \"API_KEY\": API_KEY} \ndf = pd.DataFrame(requests.get(url, params=params, timeout=30).json()) \n\nprint(df[[\"ParameterName\", \"AQI\" ,\"Category.Name \",\"DateObserved\", \"HourObserved\"]]) </code></pre>\n\n\n\n<h3>4) Copernicus Atmosphere Monitoring Service (CAMS; Atmosphere Data Store)</h3>\n\n\n\n<p>The Copernicus Atmosphere Monitoring Service [<a href=\"https://atmosphere.copernicus.eu/\" data-type=\"link\" data-id=\"https://atmosphere.copernicus.eu/\" target=\"_blank\" rel=\"noopener noreferrer\">6</a>], implemented by ECMWF for the EU’s Copernicus programme, provides global reanalyses and near-real-time forecasts of atmospheric composition. Through the Atmosphere Data Store (ADS), you can access gridded fields for aerosols, reactive gases (O₃, NO₂, etc.), greenhouse gases and related meteorological variables, with multi-year records suitable for both research and operational applications. All CAMS products in the ADS are open and free of charge, subject to accepting the Copernicus licence.&nbsp;</p>\n\n\n\n<p>Great for: global background fields (aerosols &amp; trace gases),&nbsp;forecasts&nbsp;and reanalyses.&nbsp;</p>\n\n\n\n<p><strong>How to register and get API access</strong>&nbsp;</p>\n\n\n\n<ol start=\"1\">\n<li>Go to the Atmosphere Data Store:&nbsp;<a href=\"https://ads.atmosphere.copernicus.eu/?utm_source=chatgpt.com\" target=\"_blank\" rel=\"noopener noreferrer\">https://ads.atmosphere.copernicus.eu</a>.&nbsp;</li>\n</ol>\n\n\n\n<ol start=\"2\">\n<li>Click&nbsp;<strong>Login / Register</strong>&nbsp;in the top-right corner and create a (free) Copernicus/ECMWF account.&nbsp;</li>\n</ol>\n\n\n\n<ol start=\"3\">\n<li>After confirming your email, log in and visit your&nbsp;<strong>profile</strong>&nbsp;page to find your ADS API key (UID + key).&nbsp;</li>\n</ol>\n\n\n\n<ol start=\"4\">\n<li>Follow the ADS “How to use the API” instructions to create a configuration file (typically&nbsp;~/.cdsapirc) with:&nbsp;</li>\n</ol>\n\n\n\n<ol start=\"5\">\n<li>url: https://ads.atmosphere.copernicus.eu/api&nbsp;</li>\n</ol>\n\n\n\n<ol start=\"6\">\n<li>key: &lt;YOUR-UID&gt;:&lt;YOUR-API-KEY&gt;&nbsp;</li>\n</ol>\n\n\n\n<ol start=\"7\">\n<li>On the web page of each CAMS&nbsp;dataset&nbsp;you want to use, go to the&nbsp;<strong>Download data</strong>&nbsp;tab&nbsp;and accept the licence at the bottom once; only then will API requests for that dataset succeed.&nbsp;</li>\n</ol>\n\n\n\n<p>Once this is set up, you can use the standard&nbsp;cdsapi&nbsp;Python client to programmatically download CAMS datasets from the ADS.&nbsp;</p>\n\n\n\n<pre><code># pip install cdsapi xarray cfgrib \n\nimport cdsapi \nc = cdsapi.Client() \n\n# Example: CAMS global reanalysis (EAC4) total column ozone (toy example) \nc.retrieve( \n    \"cams-global-reanalysis-eac4\", \n    {\"variable\":\"total_column_ozone\",\"date\":\"2025-08-01/2025-08-02\",\"time\":[\"00:00\",\"12:00\"], \n     \"format\":\"grib\"}, \"cams_ozone.grib\") </code></pre>\n\n\n\n<h3>5) NASA&nbsp;Earthdata&nbsp;(LAADS DAAC / GES DISC; token/login)&nbsp;</h3>\n\n\n\n<p>NASA&nbsp;Earthdata [<a href=\"https://www.earthdata.nasa.gov/\" data-type=\"link\" data-id=\"https://www.earthdata.nasa.gov/\" target=\"_blank\" rel=\"noopener noreferrer\">7</a>]&nbsp;provides unified sign-on access to a wide range of Earth science data, including satellite aerosol and trace gas products that are crucial for air-quality applications. Two key centres for atmospheric composition are:&nbsp;</p>\n\n\n\n<ul>\n<li><strong>LAADS DAAC</strong>&nbsp;(Level-1&nbsp;and Atmosphere Archive and Distribution System DAAC), which hosts MODIS, VIIRS and other instrument products (e.g., AOD, cloud, fire, radiance).&nbsp;</li>\n</ul>\n\n\n\n<ul>\n<li><strong>GES DISC</strong>&nbsp;(Goddard Earth Sciences Data and Information Services&nbsp;Center), which serves model and satellite products such as MERRA-2 reanalysis, OMI, TROPOMI, and related atmospheric datasets.&nbsp;</li>\n</ul>\n\n\n\n<p>Most of these datasets are free to use but require a&nbsp;<strong>NASA&nbsp;Earthdata&nbsp;Login</strong>; downloads are authenticated either via HTTP basic auth (username/password stored in&nbsp;.netrc) or via a personal access token (PAT) in request headers.&nbsp;</p>\n\n\n\n<p>Great for: MODIS/VIIRS AOD, MAIAC, TROPOMI trace-gas products.&nbsp;&nbsp;</p>\n\n\n\n<p>How to register and get API/download access:&nbsp;</p>\n\n\n\n<ol start=\"1\">\n<li>Create a NASA Earthdata Login account at:&nbsp;<br><a href=\"https://urs.earthdata.nasa.gov/\" target=\"_blank\" rel=\"noopener noreferrer\">https://urs.earthdata.nasa.gov</a>&nbsp;</li>\n</ol>\n\n\n\n<ol start=\"2\">\n<li>Confirm your email and log in to your&nbsp;Earthdata&nbsp;profile.&nbsp;</li>\n</ol>\n\n\n\n<ol start=\"3\">\n<li>Under your profile, generate a&nbsp;<strong>personal access token</strong>&nbsp;(PAT). Save this token securely; you can use it in scripts via an&nbsp;Authorization: Bearer &lt;TOKEN&gt;&nbsp;header or in tools that support&nbsp;Earthdata&nbsp;tokens.&nbsp;</li>\n</ol>\n\n\n\n<ol start=\"4\">\n<li>For classic&nbsp;wget/curl-based downloads, you can alternatively create a&nbsp;~/.netrc&nbsp;file to store your&nbsp;Earthdata&nbsp;username and password, for example:&nbsp;</li>\n</ol>\n\n\n\n<pre><code>machine urs.earthdata.nasa.gov&nbsp;\nlogin &lt;YOUR_USERNAME&gt;&nbsp;\npassword &lt;YOUR_PASSWORD&gt;</code></pre>\n\n\n\n<p>Then set file permissions to user-only (chmod&nbsp;600 ~/.netrc) so command-line tools can authenticate automatically.&nbsp;</p>\n\n\n\n<ol start=\"8\">\n<li>For&nbsp;<strong>LAADS DAAC</strong>&nbsp;products, go to <a href=\"https://ladsweb.modaps.eosdis.nasa.gov/\" target=\"_blank\" rel=\"noopener noreferrer\">https://ladsweb.modaps.eosdis.nasa.gov</a>, log in with your Earthdata credentials, and use the&nbsp;<strong>Search &amp; Download</strong>&nbsp;interface to build download URLs; you can copy the auto-generated&nbsp;wget/curl&nbsp;commands into your scripts.&nbsp;</li>\n</ol>\n\n\n\n<ol start=\"9\">\n<li>For&nbsp;<strong>GES DISC</strong>&nbsp;datasets, start from&nbsp;<a href=\"https://disc.gsfc.nasa.gov/\" target=\"_blank\" rel=\"noopener noreferrer\">https://disc.gsfc.nasa.gov</a>, choose a dataset (e.g., MERRA-2), and use the “Data Access” or “Subset/Get Data” tools. The site can generate script templates (Python,&nbsp;wget, etc.) that already include the correct endpoints for authenticated access.&nbsp;</li>\n</ol>\n\n\n\n<p>Once your&nbsp;Earthdata&nbsp;Login and token are set up, LAADS DAAC and GES DISC behave like standard HTTPS APIs: you can call them from Python (e.g., with&nbsp;requests,&nbsp;xarray&nbsp;+&nbsp;pydap/OPeNDAP, or&nbsp;s3fs&nbsp;for cloud buckets) using your credentials or token for authenticated, scriptable downloads.&nbsp;</p>\n\n\n\n<pre><code>#Downloads via HTTPS with Earthdata login. \n\n# pip install requests \nimport requests \nurl = \"https://ladsweb.modaps.eosdis.nasa.gov/archive/allData/6/MCD19A2/2025/214/MCD19A2.A2025214.h21v09.006.2025xxxxxx.hdf\" \n\n# Requires a valid token cookie; recommend using .netrc or requests.Session() with auth \n# See NASA docs for token-based download; here we only illustrate the pattern: \n# s = requests.Session(); s.auth = (USERNAME, PASSWORD); r = s.get(url) </code></pre>\n\n\n\n<h3>6) STAC catalogues (search satellites programmatically)&nbsp;</h3>\n\n\n\n<p>SpatioTemporal&nbsp;Asset&nbsp;Catalog&nbsp;(STAC) [<a href=\"https://stacspec.org/en\" data-type=\"link\" data-id=\"https://stacspec.org/en\" target=\"_blank\" rel=\"noopener noreferrer\">8</a>] is an open specification for describing geospatial assets,&nbsp;such as satellite scenes, tiles, and derived products,&nbsp;in a consistent, machine-readable way. Instead of manually browsing download portals, you query a STAC API with filters like time, bounding box, cloud cover, platform (e.g., Sentinel-2, Landsat-8, Sentinel-5P), or processing level, and get back JSON items with direct links to COGs,&nbsp;NetCDF, Zarr, or other assets.&nbsp;&nbsp;</p>\n\n\n\n<p>Great for: discover and stream assets (COGs/NetCDF) without bespoke APIs and works well with Sentinel-5P, Landsat, Sentinel-2, more.&nbsp;</p>\n\n\n\n<p><strong>How to register and get API access:&nbsp;<br></strong>STAC itself is just a standard; access depends on the specific STAC API you use:&nbsp;</p>\n\n\n\n<ul>\n<li>Many public STAC catalogues (e.g., demo or research endpoints) are fully open and require no registration—you can hit their&nbsp;/search&nbsp;endpoint directly with HTTP POST/GET.&nbsp;</li>\n</ul>\n\n\n\n<ul>\n<li>Some cloud platforms that expose STAC (for example, commercial or large cloud providers) require you to create a free account and obtain credentials before you can read the underlying assets (e.g., blobs in S3/Blob storage), even though the STAC metadata is open.&nbsp;</li>\n</ul>\n\n\n\n<p>A generic pattern you can describe is:&nbsp;</p>\n\n\n\n<ol start=\"1\">\n<li>Pick a STAC API endpoint for the satellite data you care about (often documented as something&nbsp;along the lines of&nbsp;https://&lt;provider&gt;/stac&nbsp;or&nbsp;…/stac/search).&nbsp;</li>\n</ol>\n\n\n\n<ol start=\"2\">\n<li>If the provider&nbsp;requires&nbsp;sign-up, create an account in their portal and obtain the API key or storage credentials they recommend (this might be a token, SAS URL, or cloud access role).&nbsp;</li>\n</ol>\n\n\n\n<ol start=\"3\">\n<li>Use a STAC client library in Python (for example,&nbsp;pystac-client) to search the catalogue:&nbsp;</li>\n</ol>\n\n\n\n<pre><code># pip install pystac-client \nfrom pystac_client import Client \n\napi = Client.open(\"https://example.com/stac\") \nsearch = api.search( \n    collections=[\"sentinel-2-l2a\"], \n    bbox=[102.4, 17.8, 103.0, 18.2],   # minx, miny, maxx, maxy \n    datetime=\"2024-01-01/2024-01-31\", \n    query={\"eo:cloud_cover\": {\"lt\": 20}}, \n    )\nitems = list(search.get_items()) \nfirst_item = items[0] \nassets = first_item.assets  # e.g., COGs, QA bands, metadata </code></pre>\n\n\n\n<ol start=\"4\">\n<li>For each returned STAC item, follow the asset&nbsp;href&nbsp;links (often HTTPS URLs or cloud URIs like&nbsp;s3://…) and read them with the&nbsp;appropriate library&nbsp;(rasterio/xarray/zarr&nbsp;etc.). If credentials are needed, configure them via environment variables or your cloud SDK as per the provider’s instructions.&nbsp;</li>\n</ol>\n\n\n\n<p>Once set up, STAC catalogues give you a uniform, programmatic way to search and retrieve satellite data across different providers, without rewriting your search logic every time you switch from one archive to another.&nbsp;</p>\n\n\n\n<pre><code># pip install pystac-client planetary-computer rasterio \nfrom pystac_client import Client \nfrom shapely.geometry import box, mapping \nimport geopandas as gpd \n\ncatalog = Client.open(\"https://earth-search.aws.element84.com/v1\") \naoi = mapping(box(-0.3, 5.5, 0.3, 5.9))  # bbox around Accra\nsearch = catalog.search(collections=[\"sentinel-2-l2a\"], intersects=aoi, limit=5) \nitems = list(search.get_items()) \nfor it in items: \n    print(it.id, list(it.assets.keys())[:5])   # e.g., \"B04\", \"B08\", \"SCL\", \"visual\" </code></pre>\n\n\n\n<p>It is preferrable to use&nbsp;STAC where possible&nbsp;as they provide&nbsp;clean metadata, cloud-optimised assets, and easy filtering by time/space.&nbsp;</p>\n\n\n\n<h3>7) Google Earth Engine (GEE; fast prototyping at scale)&nbsp;</h3>\n\n\n\n<p>Google Earth Engine [<a href=\"https://earthengine.google.com/\" data-type=\"link\" data-id=\"https://earthengine.google.com/\" target=\"_blank\" rel=\"noopener noreferrer\">9</a>] is a cloud-based geospatial analysis platform that hosts a large catalogue of satellite, climate, and land-surface datasets (e.g., MODIS, Landsat, Sentinel, reanalyses) and lets you process them at scale without managing your own infrastructure. You write short scripts in JavaScript or Python, and GEE handles the heavy lifting&nbsp;like&nbsp;data access, tiling, reprojection, and parallel computation&nbsp;thus&nbsp;making it ideal for fast prototyping, exploratory analyses, and teaching.&nbsp;</p>\n\n\n\n<div><p>However,&nbsp;<strong>GEE itself is not open source</strong>: it is a proprietary, closed platform where the underlying codebase is not publicly available. This has implications for open, reproducible workflows discussed in the first&nbsp;<em>Air for Tomorrow</em>&nbsp;blog [add link]:&nbsp;</p><p>&nbsp;Great for: testing fusion/downscaling over a city/region using petabyte-scale datasets.&nbsp;</p><p>&nbsp;How to register and get access&nbsp;</p></div>\n\n\n\n<ol start=\"1\">\n<li>Visit the Earth Engine sign-up page:&nbsp;<a href=\"https://earthengine.google.com/\" target=\"_blank\" rel=\"noopener noreferrer\">https://earthengine.google.com</a>.&nbsp;</li>\n</ol>\n\n\n\n<ol start=\"2\">\n<li>Sign in with a Google account and complete the&nbsp;<strong>non-commercial</strong>&nbsp;sign-up form, describing your intended use (research, education, or personal, non-commercial projects).&nbsp;</li>\n</ol>\n\n\n\n<ol start=\"3\">\n<li>Once your account is approved, you can:&nbsp;</li>\n</ol>\n\n\n\n<ul>\n<li>use the browser-based&nbsp;Code Editor&nbsp;to write JavaScript Earth Engine scripts; and&nbsp;</li>\n</ul>\n\n\n\n<ul>\n<li>enable the&nbsp;Earth Engine API&nbsp;in Google Cloud and install the&nbsp;earthengine-api&nbsp;Python package (pip install&nbsp;earthengine-api) to run workflows from Python notebooks.&nbsp;</li>\n</ul>\n\n\n\n<ol start=\"4\">\n<li>When sharing your work, consider exporting key intermediate results (e.g.,&nbsp;GeoTIFF/COG,&nbsp;NetCDF/Zarr) and documenting your processing steps in open-source code so that others can re-create the analysis without depending entirely on GEE.&nbsp;</li>\n</ol>\n\n\n\n<p>When used this way, Earth Engine becomes a powerful “rapid laboratory” for testing ideas, which you can then harden into fully open, portable pipelines for production and long-term stewardship.&nbsp;</p>\n\n\n\n<pre><code># pip install earthengine-api \nimport ee \n\nee.Initialize()  # first run: ee.Authenticate() in a console \ns5p = ee.ImageCollection('COPERNICUS/S5P/OFFL/L3_NO2').select('NO2_column_number_density')\\ \n       .filterDate('2025-08-01', '2025-08-07').mean() \n\nprint(s5p.getInfo()['bands'][0]['id']) \n\n# Exporting and visualization happen within GEE; you can sample to a grid then .getDownloadURL() </code></pre>\n\n\n\n<h3>8)&nbsp;HIMAWARI</h3>\n\n\n\n<div><p>Himawari-8 and Himawari-9 are geostationary meteorological satellites&nbsp;operated&nbsp;by the Japan Meteorological Agency (JMA). Their Advanced Himawari Imager (AHI) provides multi-band visible, near-infrared&nbsp;and infrared imagery over East Asia and the western–central&nbsp;Pacific, with full-disk scans every 10 minutes and even faster refresh over target regions. This high-cadence view is extremely useful for tracking smoke plumes, dust, volcanic eruptions, convective&nbsp;storms&nbsp;and the diurnal evolution of clouds—exactly the kinds of processes that modulate near-surface air quality.&nbsp;</p><p>&nbsp;Great for: tracking diurnal haze/smoke plumes and fire events, generating high-frequency AOD to fill polar-orbit gaps, and rapid situational awareness for cities across SE/E Asia (via JAXA P-Tree L3 products).&nbsp;</p></div>\n\n\n\n<p><strong>How to access and register</strong>&nbsp;</p>\n\n\n\n<p><em><strong>Option&nbsp;A</strong> – Open archive via NOAA on AWS (no sign-up&nbsp;required)</em>&nbsp;</p>\n\n\n\n<ol start=\"1\">\n<li>Browse the dataset description at the AWS Registry of Open Data:&nbsp;<a href=\"https://registry.opendata.aws/noaa-himawari/?utm_source=chatgpt.com\" target=\"_blank\" rel=\"noopener noreferrer\">https://registry.opendata.aws/noaa-himawari/</a>&nbsp;</li>\n</ol>\n\n\n\n<ol start=\"2\">\n<li>Himawari-8 and Himawari-9 imagery are hosted in public S3 buckets (s3://noaa-himawari8/&nbsp;and&nbsp;s3://noaa-himawari9/). Because the buckets are world-readable, you can list or download files anonymously, for example:&nbsp;</li>\n</ol>\n\n\n\n<p><code>aws&nbsp;s3&nbsp;ls&nbsp;--no-sign-request s3://noaa-himawari9/&nbsp;</code></p>\n\n\n\n<p>or access individual objects via HTTPS (e.g.,&nbsp;https://noaa-himawari9.s3.amazonaws.com/…).&nbsp;</p>\n\n\n\n<ol start=\"3\">\n<li>For Python workflows, you can use libraries like&nbsp;s3fs,&nbsp;fsspec,&nbsp;xarray, or&nbsp;rasterio&nbsp;to stream data directly from these buckets without prior registration, keeping in mind the attribution guidance from JMA/NOAA when you publish results.&nbsp;</li>\n</ol>\n\n\n\n<p><em><strong>Option&nbsp;B</strong> – JAXA Himawari Monitor / P-Tree (research &amp; education account)</em>&nbsp;</p>\n\n\n\n<ol start=\"1\">\n<li>Go to the JAXA Himawari Monitor / P-Tree portal:&nbsp;<br><a href=\"https://www.eorc.jaxa.jp/ptree/?utm_source=chatgpt.com\" target=\"_blank\" rel=\"noopener noreferrer\">https://www.eorc.jaxa.jp/ptree/</a>&nbsp;</li>\n</ol>\n\n\n\n<ol start=\"2\">\n<li>Click&nbsp;<strong>User Registration / Account request</strong>&nbsp;and read the “Precautions” and “Terms of Use”. Data access is restricted to non-profit purposes such as research and education; commercial users are directed to the Japan Meteorological Business Support&nbsp;Center.&nbsp;</li>\n</ol>\n\n\n\n<ol start=\"3\">\n<li>Submit your email address in the account request form. You’ll&nbsp;receive a temporary acceptance email, then a link to complete your user information. After manual review, JAXA enables your access and&nbsp;notifies you&nbsp;once you can download Himawari Standard Data and geophysical parameter products.&nbsp;</li>\n</ol>\n\n\n\n<ol start=\"4\">\n<li>Once approved, you can log in to download near-real-time and archived Himawari data via the P-Tree FTP/HTTP services, following JAXA’s guidance on non-redistribution and citation.&nbsp;</li>\n</ol>\n\n\n\n<p>In practice, a common pattern is to use the NOAA/AWS buckets for open, scriptable access to raw imagery, and the JAXA P-Tree products when you need value-added parameters (e.g., cloud or aerosol properties) and are working within non-profit research or educational projects.&nbsp;</p>\n\n\n\n<pre><code># open the downloaded file\n!pip install xarray netCDF4\n!pip install rasterio polars_h3\n!pip install geopandas pykrige\n!pip install polars==1.25.2\n!pip install dask[complete] rioxarray h3==3.7.7\n!pip install h3ronpy==0.21.1\n!pip install geowrangler</code></pre>\n\n\n\n<pre><code># Himawari using – JAXA Himawari Monitor / P-Tree\n# create your account here and use the username and password sent by email - https://www.eorc.jaxa.jp/ptree/registration_top.html\n\nuser = '' # enter the username \npassword = '' # enter the password </code></pre>\n\n\n\n<pre><code>from ftplib import FTP\nfrom pathlib import Path\nimport rasterio\nfrom rasterio.transform import from_origin\nimport xarray as xr\nimport os\nimport matplotlib.pyplot as plt\n\n\ndef get_himawari_ftp_past_2_days(user, password):\n\n    # FTP connection details\n    ftp = FTP('ftp.ptree.jaxa.jp')\n    ftp.login(user=user, passwd=password)\n\n    # check the directory content : /pub/himawari/L2/ARP/031/\n    # details of AOD directoty here: https://www.eorc.jaxa.jp/ptree/documents/README_HimawariGeo_en.txt\n\n    overall_path= \"/pub/himawari/L3/ARP/031/\"\n    directories = overall_path.strip(\"/\").split(\"/\")\n\n    for directory in directories:\n      ftp.cwd(directory)\n\n    # List files in the target directory\n    date_month_files = ftp.nlst()\n\n    # order files desc\n    date_month_files.sort(reverse=False)\n    print(\"Files in target directory:\", date_month_files)\n\n    # get a list of all the month / days within the \"/pub/himawari/L3/ARP/031/\" path within the past 2 months\n    limited_months_list = date_month_files[-2:]\n\n    i=0\n    # for each month in the limited_months_list, list all the days within in\n    for month in limited_months_list:\n      ftp.cwd(month)\n      date_day_files = ftp.nlst()\n      date_day_files.sort(reverse=False)\n\n\n      # combine each element of the date_day_file list with the month : month +\"/\" + date_day_file\n      list_combined_days_month_inter = [month + \"/\" + date_day_file for date_day_file in date_day_files]\n      if i ==0:\n        list_combined_days_month= list_combined_days_month_inter\n        i=i+1\n      else:\n        list_combined_days_month= list_combined_days_month + list_combined_days_month_inter\n      ftp.cwd(\"..\")\n\n    # remove all elements containing daily or monthly from list_combined_days_month\n    list_combined_days_month = [item for item in list_combined_days_month if 'daily' not in item and 'monthly' not in item]\n\n    # get the list of days we want to download : in our case last 2 days - for NRT\n    limited_list_combined_days_month=list_combined_days_month[-2:]\n\n\n    for month_day_date in limited_list_combined_days_month:\n      #navigate to the relevant directory\n      ftp.cwd(month_day_date)\n      print(f\"directory: {month_day_date}\")\n\n      # get the list of the hourly files within each directory\n      date_hour_files = ftp.nlst()\n      !mkdir -p ./raw_data/{month_day_date}\n\n      #for each hourly file in the list\n      for date_hour_file in date_hour_files:\n        target_file_path=f\"./raw_data/{month_day_date}/{date_hour_file}\"\n        # Download the target file - only if it does not already exist\n\n        if not os.path.exists(target_file_path):\n            with open(target_file_path, \"wb\") as local_file:\n              ftp.retrbinary(f\"RETR {date_hour_file}\", local_file.write)\n              print(f\"Downloaded {date_hour_file} successfully!\")\n        else:\n            print(f\"File already exists: {date_hour_file}\")\n\n\n\n      print(\"--------------\")\n      # go back 2 steps in the ftp tree\n      ftp.cwd(\"..\")\n      ftp.cwd(\"..\")</code></pre>\n\n\n\n<pre><code>def transform_to_tif():\n    # get list of files in raw_data folder\n    month_file_list = os.listdir(\"./raw_data\")\n    month_file_list\n\n    #order month_file_list\n    month_file_list.sort(reverse=False)\n\n    nb_errors=0\n    # get list of each day folder for the past 2 months only\n\n    for month_file in month_file_list[-2:]:\n        print(f\"-----------------------------------------\")\n        print(f\"Month considered: {month_file}\")\n        date_file_list=os.listdir(f\"./raw_data/{month_file}\")\n        date_file_list.sort(reverse=False)\n\n        # get list of files for each day folder\n\n        for date_file in date_file_list[-2:]:\n            print(f\"---------------------------\")\n            print(f\"Day considered: {date_file}\")\n            hour_file_list=os.listdir(f\"./raw_data/{month_file}/{date_file}\")\n            hour_file_list.sort(reverse=False)\n\n            #process each hourly file into a tif file and transform it into an h3 processed dataframe\n            for hour_file in hour_file_list:\n                file_path = f\"./raw_data/{month_file}/{date_file}/{hour_file}\"\n                hour_file_tif=hour_file.replace(\".nc\",\".tif\")\n                output_tif = f\"./tif/{month_file}/{date_file}/{hour_file_tif}\"\n                if os.path.exists(output_tif):\n                   print(f\"File already exists: {output_tif}\")\n                else:\n\n                   try:\n                      dataset = xr.open_dataset(file_path, engine='netcdf4')\n                   except:\n                      #go to next hour_file\n                      print(f\"error opening {hour_file} file - skipping \")\n                      nb_errors=nb_errors+1\n                      continue\n\n                   # Access a specific variable\n                   variable_name = list(dataset.data_vars.keys())[1] # Merged AOT product\n                   data = dataset[variable_name]\n\n                   # Plot data (if it's 2D and compatible)\n                   plt.figure()\n                   data.plot()\n                   plt.title(f'{date_file}')\n                   plt.show()\n\n                   # Extract metadata (replace with actual coordinates from your data if available)\n                   lon = dataset['longitude'] if 'longitude' in dataset.coords else None\n                   lat = dataset['latitude'] if 'latitude' in dataset.coords else None\n\n                   # Handle missing lat/lon (example assumes evenly spaced grid)\n                   if lon is None or lat is None:\n                        lon_start, lon_step = -180, 0.05 # Example values\n                        lat_start, lat_step = 90, -0.05 # Example values\n                        lon = xr.DataArray(lon_start + lon_step * range(data.shape[-1]), dims=['x'])\n                        lat = xr.DataArray(lat_start + lat_step * range(data.shape[-2]), dims=['y'])\n\n                   # Define the affine transform for georeferencing\n                   transform = from_origin(lon.min().item(), lat.max().item(), abs(lon[1] - lon[0]).item(), abs(lat[0] - lat[1]).item())\n\n                   # Save to GeoTIFF\n                   !mkdir -p ./tif/{month_file}/{date_file}\n\n                   with rasterio.open(\n                   output_tif,\n                   'w',\n                   driver='GTiff',\n                   height=data.shape[-2],\n                   width=data.shape[-1],\n                   count=1, # Number of bands\n                   dtype=data.dtype.name,\n                   crs='EPSG:4326', # Coordinate Reference System (e.g., WGS84)\n                   transform=transform\n                   ) as dst:\n\n                        dst.write(data.values, 1) # Write the data to band 1\n                   print(f\"Saved {output_tif} successfully!\")\n                   print(f\"{nb_errors} error(s) \")</code></pre>\n\n\n\n<pre><code>get_himawari_ftp_past_2_days(user, password)\ntransform_to_tif()</code></pre>\n\n\n\n<h3>9) NASA — FIRMS&nbsp;[Special Highlight]&nbsp;</h3>\n\n\n\n<div><p>NASA’s Fire Information for Resource Management System (FIRMS) [<a href=\"https://firms.modaps.eosdis.nasa.gov/\" data-type=\"link\" data-id=\"https://firms.modaps.eosdis.nasa.gov/\" target=\"_blank\" rel=\"noopener noreferrer\">10]</a> provides near-real-time information on active fires and thermal anomalies detected by instruments such as MODIS and VIIRS. It offers global coverage with&nbsp;low latency (on the order of minutes to hours), supplying attributes such as fire radiative power, confidence, and acquisition time. FIRMS is widely used for wildfire monitoring, agricultural burning, forest management, and as a proxy input for air-quality and smoke dispersion modelling.&nbsp;</p><p>&nbsp;Great for: pinpointing fire hotspots that drive AQ spikes, tracking plume sources and fire-line progression,&nbsp;monitoring&nbsp;crop-residue/forest burns, and triggering rapid response. Easy access via CSV/GeoJSON/Shapefile, map tiles/API, with 24–72 h rolling feeds and full archives for seasonal analysis.&nbsp;</p></div>\n\n\n\n<p><strong>How to register and get API access</strong>&nbsp;</p>\n\n\n\n<ol start=\"1\">\n<li>Create a free NASA Earthdata Login account at:&nbsp;<br><a href=\"https://urs.earthdata.nasa.gov/\" target=\"_blank\" rel=\"noopener noreferrer\">https://urs.earthdata.nasa.gov</a>&nbsp;</li>\n</ol>\n\n\n\n<ol start=\"2\">\n<li>Confirm your email and sign in with your new credentials.&nbsp;</li>\n</ol>\n\n\n\n<ol start=\"3\">\n<li>Go to the FIRMS site you plan to use, for example:&nbsp;</li>\n</ol>\n\n\n\n<ul>\n<li>Global FIRMS:&nbsp;<a href=\"https://firms.modaps.eosdis.nasa.gov/\" target=\"_blank\" rel=\"noopener noreferrer\">https://firms.modaps.eosdis.nasa.gov</a>&nbsp;</li>\n</ul>\n\n\n\n<ul>\n<li>FIRMS US/Canada:&nbsp;<a href=\"https://firms.modaps.eosdis.nasa.gov/usfs/\" target=\"_blank\" rel=\"noopener noreferrer\">https://firms.modaps.eosdis.nasa.gov/usfs/</a>&nbsp;</li>\n</ul>\n\n\n\n<ol start=\"4\">\n<li>Click&nbsp;<strong>Login</strong>&nbsp;(top right) and authenticate with your&nbsp;Earthdata&nbsp;username and password. Once logged in, you can:&nbsp;</li>\n</ol>\n\n\n\n<ul>\n<li>customise map views and download options from the web interface, and&nbsp;</li>\n</ul>\n\n\n\n<ul>\n<li>generate or use FIRMS Web Services/API URLs that honour your authenticated session.&nbsp;</li>\n</ul>\n\n\n\n<ol start=\"5\">\n<li>For scripted access, you can call the FIRMS download or web service endpoints (e.g., GeoJSON, CSV) using standard HTTP tools (e.g., curl,&nbsp;requests&nbsp;in Python). If an endpoint requires authentication, supply your&nbsp;Earthdata&nbsp;credentials via a&nbsp;.netrc&nbsp;file or session cookies, as you would for other&nbsp;Earthdata&nbsp;services.&nbsp;</li>\n</ol>\n\n\n\n<p>In practice, FIRMS is a convenient way to pull recent fire locations into an air-quality workflow: you can fetch daily or hourly fire detections for a region, convert them to a&nbsp;GeoDataFrame, and then intersect with wind fields, population grids, or sensor networks to understand potential smoke impacts.&nbsp;</p>\n\n\n\n<pre><code>#FIRMS  \n!pip install geopandas rtree shapely </code></pre>\n\n\n\n<pre><code>import pandas as pd \nimport geopandas as gpd \nfrom shapely.geometry import Point \nimport numpy as np \nimport matplotlib.pyplot as plt \nimport rtree \n\n# get boundaries of Thailand \nboundaries_country = gpd.read_file(f'https://github.com/wmgeolab/geoBoundaries/raw/fcccfab7523d4d5e55dfc7f63c166df918119fd1/releaseData/gbOpen/THA/ADM0/geoBoundaries-THA-ADM0.geojson') \nboundaries_country.plot() \n\n# Real time data source: https://firms.modaps.eosdis.nasa.gov/active_fire/ \n# Past 7 days links: \nmodis_7d_url= \"https://firms.modaps.eosdis.nasa.gov/data/active_fire/modis-c6.1/csv/MODIS_C6_1_SouthEast_Asia_7d.csv\" \nsuomi_7d_url= \"https://firms.modaps.eosdis.nasa.gov/data/active_fire/suomi-npp-viirs-c2/csv/SUOMI_VIIRS_C2_SouthEast_Asia_7d.csv\" \nj1_7d_url= \"https://firms.modaps.eosdis.nasa.gov/data/active_fire/noaa-20-viirs-c2/csv/J1_VIIRS_C2_SouthEast_Asia_7d.csv\" \nj2_7d_url=\"https://firms.modaps.eosdis.nasa.gov/data/active_fire/noaa-21-viirs-c2/csv/J2_VIIRS_C2_SouthEast_Asia_7d.csv\" \nurls = [modis_7d_url, suomi_7d_url, j1_7d_url, j2_7d_url] \n\n# Create an empty GeoDataFrame to store the combined data \ngdf = gpd.GeoDataFrame() \n\nfor url in urls: \n    df = pd.read_csv(url) \n\n    # Create a geometry column from latitude and longitude \n    geometry = [Point(xy) for xy in zip(df['longitude'], df['latitude'])] \n    gdf_temp = gpd.GeoDataFrame(df, crs=\"EPSG:4326\", geometry=geometry)\n     \n    # Concatenate the temporary GeoDataFrame to the main GeoDataFrame \n    gdf = pd.concat([gdf, gdf_temp], ignore_index=True) \n\n# Filter to keep only fires within the country boundaries \ngdf = gpd.sjoin(gdf, boundaries_country, how=\"inner\", predicate=\"within\") \n\n# Display fires on map  \nfrp = gdf[\"frp\"].astype(float) \nfig, ax = plt.subplots(figsize=(9,9)) \nboundaries_country.plot(ax=ax, facecolor=\"none\", edgecolor=\"0.3\", linewidth=0.8) \ngdf.plot(ax=ax, markersize=frp, color=\"crimson\", alpha=0.55) \nax.set_title(\"Fires within country boundaries (bubble size = Fire Radiative Power )\") \nax.set_axis_off() \nplt.show() </code></pre>\n\n\n\n<h2>Data types you&nbsp;will meet (and how to read them right)&nbsp;</h2>\n\n\n\n<p>Air-quality work rarely lives in a single, tidy CSV. So, it helps to know what the file types you will meet. You will move between multidimensional model outputs (NetCDF/GRIB/Zarr), satellite rasters (COG/GeoTIFF), point measurements (CSV /Parquet /GeoParquet), and web-friendly formats (JSON/GeoJSON), often in the same notebook.&nbsp;</p>\n\n\n\n<p>This section is a quick field guide to those formats and how to open them without getting stuck.&nbsp;</p>\n\n\n\n<p>There is no need to memorise any of this, so feel free to&nbsp;skim the list once, then come back when you hit an unfamiliar file extension in the wild.&nbsp;</p>\n\n\n\n<ol start=\"1\">\n<li><strong>NetCDF4&nbsp;/ HDF5 (self-describing scientific arrays):&nbsp;</strong>Widely used for reanalyses, satellite products, and models. Rich metadata, multi-dimensional (time, level,&nbsp;lat,&nbsp;lon)&nbsp;Usual extensions:&nbsp;.nc, .nc4, .h5, .hdf5&nbsp;</li>\n</ol>\n\n\n\n<p><em>Read:</em>&nbsp;</p>\n\n\n\n<pre><code># pip install xarray netCDF4 \n\nimport xarray as xr \nds = xr.open_dataset(\"modis_aod_2025.nc\") \nds = ds.sel(time=slice(\"2025-08-01\",\"2025-08-07\")) \nprint(ds) </code></pre>\n\n\n\n<ol start=\"2\">\n<li><strong>Cloud-Optimised&nbsp;GeoTIFF&nbsp;(COG):&nbsp;</strong>Raster format tuned for HTTP range requests (stream just what you need). Common for satellite imagery and gridded products. Usual extensions:&nbsp;.tif, .tiff&nbsp;</li>\n</ol>\n\n\n\n<p>&nbsp;<em>Read:</em>&nbsp;</p>\n\n\n\n<pre><code># pip install rasterio \n\nimport rasterio \nwith rasterio.open(\"https://example-bucket/no2_mean_2025.tif\") as src: \n    window = rasterio.windows.from_bounds(*(-0.3,5.5,0.3,5.9), src.transform) \n    arr = src.read(1, window=window)</code></pre>\n\n\n\n<ol start=\"3\">\n<li><strong>JSON (nested) &amp;&nbsp;GeoJSON&nbsp;(features + geometry):&nbsp;</strong>Great for APIs and lightweight geospatial. GeoJSON&nbsp;uses WGS84 (EPSG:4326) by default. Usual extensions:&nbsp;json,&nbsp;.jsonl, .ndjson,&nbsp;.geojsonl,&nbsp;.ndgeojson&nbsp;</li>\n</ol>\n\n\n\n<p><em>Read:</em>&nbsp;</p>\n\n\n\n<pre><code># pip install geopandas \n\nimport geopandas as gpd \ngdf = gpd.read_file(\"points.geojson\")  # columns + geometry \ngdf = gdf.set_crs(4326)                # ensure WGS84 </code></pre>\n\n\n\n<ol start=\"4\">\n<li><strong>GRIB2 (meteorology, model outputs):&nbsp;</strong>Compact, tiled; often used by CAMS/ECMWF/NWP. Usual extensions:&nbsp;.grib2,&nbsp;.grb2,&nbsp;.grib, .grb. In practice, data providers often add compression suffixes too,&nbsp;e.g. .grib2.gz&nbsp;or .grb2.bz2.&nbsp;</li>\n</ol>\n\n\n\n<p><em>Read:</em>&nbsp;</p>\n\n\n\n<pre><code># pip install xarray cfgrib \n\nimport xarray as xr \nds = xr.open_dataset(\"cams_ozone.grib\", engine=\"cfgrib\") </code></pre>\n\n\n\n<ol start=\"5\">\n<li><strong>Parquet &amp;&nbsp;GeoParquet&nbsp;(columnar, compressed):&nbsp;</strong>Best for big tables: fast column&nbsp;selection, predicate pushdown, partitioning (e.g., by date/city). GeoParquet&nbsp;adds a standard for geometries. Usual extensions:&nbsp;.parquet,&nbsp;.parquet.gz&nbsp;</li>\n</ol>\n\n\n\n<p><em>&nbsp;Read/Write:</em>&nbsp;</p>\n\n\n\n<pre><code># pip install pandas pyarrow geopandas geoparquet \n\nimport pandas as pd, geopandas as gpd \ndf = pd.read_parquet(\"openaq_accra_2025.parquet\")   # columns only \n\n# Convert a GeoDataFrame -&gt; GeoParquet \ngdf = gpd.read_file(\"points.geojson\") \ngdf.to_parquet(\"points.geoparquet\")  # preserves geometry &amp; CRS </code></pre>\n\n\n\n<ol start=\"6\">\n<li><strong>CSV/TSV (text tables):</strong>&nbsp;Simple, universal. Weak at large scale (slow I/O, no schema), no geometry. Usual extensions: .csv,&nbsp;.tsv&nbsp;(also sometimes .tab, less common)</li>\n</ol>\n\n\n\n<p><em>&nbsp;Read:</em>&nbsp;</p>\n\n\n\n<pre><code># pip install pandas \n\nimport pandas as pd\ndf = pd.read_csv(\"measurements.csv\", parse_dates=[\"datetime\"], dtype={\"site_id\":\"string\"}) </code></pre>\n\n\n\n<ol start=\"7\">\n<li><strong>Zarr&nbsp;(chunked, cloud-native):&nbsp;</strong>Ideal for analysis in the cloud with parallel reads (works great with&nbsp;Dask). Usual extension:&nbsp;.zarr&nbsp;(often a directory / store ending in .zarr; occasionally packaged&nbsp;as .zarr.zip)&nbsp;</li>\n</ol>\n\n\n\n<p>&nbsp;<em>Read:</em>&nbsp;</p>\n\n\n\n<pre><code># pip install xarray zarr s3fs \n\nimport xarray as xr\nds = xr.open_zarr(\"s3://bucket/cams_eac4_2025.zarr\", consolidated=True) </code></pre>\n\n\n\n<p>Note:<strong>&nbsp;Shapefile (legacy vector):&nbsp;</strong>Works, but brittle (many files, 10-char&nbsp;field limit).&nbsp;.&nbsp;This is a legacy formats and it is better to use the alternatives like&nbsp;GeoPackage&nbsp;or&nbsp;GeoParquet&nbsp;&nbsp;</p>\n\n\n\n<p>It is important to choose the right geospatial (or scientific) file format as it is not just a storage decision but it directly impacts how quickly you can read data, tool compatibility, how easily you can share it, and how well it scales from a desktop workflow to cloud-native processing. The following table (Table 1) provides a practical “format-to-task” cheat sheet: for each common need (from quick API dumps to cloud-scale arrays and web mapping), it lists the most suitable format, the extensions you’ll typically encounter, and the core reason that format is a good fit. It can be used as a default starting point when designing pipelines, publishing datasets, or selecting what to download from an external repository.&nbsp;</p>\n\n\n\n<figure><table><tbody><tr><td data-align=\"center\"><strong>Need</strong></td><td data-align=\"center\"><strong>Best Bet</strong></td><td data-align=\"center\"><strong>Usual&nbsp;Extension</strong></td><td data-align=\"center\"><strong>Why</strong>&nbsp;</td></tr><tr><td data-align=\"center\">Human-readable logs or quick API dumps&nbsp;</td><td data-align=\"center\">CSV/JSON&nbsp;</td><td data-align=\"center\">.csv, .json&nbsp;(also .jsonl, .ndjson)&nbsp;</td><td data-align=\"center\">Ubiquitous, easy to inspect&nbsp;</td></tr><tr><td data-align=\"center\">Big tables (millions of rows)&nbsp;</td><td data-align=\"center\">Parquet/&nbsp;GeoParquet&nbsp;</td><td data-align=\"center\">.parquet&nbsp;</td><td data-align=\"center\">Fast scans, column pruning, and partitioning&nbsp;</td></tr><tr><td data-align=\"center\">Large&nbsp;rasters&nbsp; over HTTP&nbsp;</td><td data-align=\"center\">COG&nbsp;</td><td data-align=\"center\">.tif, .tiff&nbsp;</td><td data-align=\"center\">Range requests; no full download&nbsp;</td></tr><tr><td data-align=\"center\">Multi-dimensional scientific data&nbsp;</td><td data-align=\"center\">NetCDF4/HDF5&nbsp;</td><td data-align=\"center\">.nc, .nc4, .h5, .hdf5&nbsp;</td><td data-align=\"center\">Self-describing, units/attrs&nbsp;</td></tr><tr><td data-align=\"center\">Meteorological model outputs&nbsp;</td><td data-align=\"center\">GRIB2&nbsp;</td><td data-align=\"center\">.grib2,&nbsp;.grb2,&nbsp;.grib, .grb&nbsp;</td><td data-align=\"center\">Compact, widely supported by&nbsp;wx&nbsp;tools&nbsp;</td></tr><tr><td data-align=\"center\">Cloud-scale arrays&nbsp;</td><td data-align=\"center\">Zarr&nbsp;</td><td data-align=\"center\">.zarr&nbsp;</td><td data-align=\"center\">Chunked + parallel; cloud-native&nbsp;</td></tr><tr><td data-align=\"center\">Exchangeable vector file&nbsp;</td><td data-align=\"center\">GeoPackage&nbsp;</td><td data-align=\"center\">.gpkg&nbsp;</td><td data-align=\"center\">Single file; robust&nbsp;</td></tr><tr><td data-align=\"center\">Web mapping geometries&nbsp;</td><td data-align=\"center\">GeoJSON&nbsp;</td><td data-align=\"center\">.geojsonl,&nbsp;<br>.ndgeojson&nbsp;</td><td data-align=\"center\">Simple; native to web stacks&nbsp;</td></tr></tbody></table><figcaption><strong>Table 1:&nbsp;Picking the right format for the job</strong>&nbsp;</figcaption></figure>\n\n\n\n<p><strong>Tip:</strong> An interesting talk on STAC and data types (especially GeoParquet):&nbsp;<a href=\"https://github.com/GSA/gtcop-wiki/wiki/June-2025:-GeoParquet,-Iceberg-and-Cloud%E2%80%90Native-Spatial-Data-Infrastructures\" target=\"_blank\" rel=\"noopener noreferrer\">https://github.com/GSA/gtcop-wiki/wiki/June-2025:-GeoParquet,-Iceberg-and-Cloud%E2%80%90Native-Spatial-Data-Infrastructures</a></p>\n\n\n\n<p>Multiple open STAC catalogues are now available, including public endpoints for optical, radar, and atmospheric products (for example, Landsat and Sentinel imagery via providers such as Element 84’s Earth Search or Microsoft’s Planetary Computer). STAC makes it much easier to script “find and download all scenes for this polygon and time range” and to integrate different datasets into the same workflow.&nbsp;</p>\n\n\n\n<h2>Conclusion&nbsp;—&nbsp;from “where” the data lives to “how” you use it&nbsp;</h2>\n\n\n\n<figure><img decoding=\"async\" src=\"https://contributor.insightmediagroup.io/wp-content/uploads/2026/01/Screenshot-2026-01-06-at-12.10.32-1024x453.png\" alt=\"\" style=\"max-width: 100%; height: auto; border-radius: 1rem; margin: 2rem 0px;\"><figcaption>Figure 3: Creating exposure maps from&nbsp;hotspots&nbsp;&nbsp;©&nbsp;UNICEF/UNI724381/Kongchan&nbsp;Phi. All rights reserved.&nbsp;</figcaption></figure>\n\n\n\n<p><strong>Air for Tomorrow</strong>: We started with the question “<em>What are these kids breathing today?</em>”&nbsp;This post&nbsp;provides&nbsp;a practical path and tools to help you answer&nbsp;this question. You now know where open-air quality data resides, including regulatory networks, community sensors, satellite measurements, and reanalysis. You also understand what those files are (GeoJSON, Parquet/GeoParquet, NetCDF/HDF5, COG, GRIB, Zarr) and how to retrieve them with compact, reproducible snippets. The goal is beyond just downloading them; it is to&nbsp;make&nbsp;defensible, fast, and shareable analyses that hold up&nbsp;<strong>tomorrow</strong>.&nbsp;</p>\n\n\n\n<p>You can assemble a credible local picture in hours, not weeks. From fire hotspots (<strong>Figure 2</strong>) to school-route exposure (<strong>Figure 1</strong>), you can create exposure maps (<strong>Figure 3</strong>).</p>\n\n\n\n<p><strong>Up next:</strong>&nbsp;We would&nbsp;showcase&nbsp;an actual Air Quality Model developed by us at the UNICEF Country Office of Lao PDR with the UNICEF EAPRO’s Frontier Data Team. We would go through an open, end-to-end model pipeline. When there are ground-level air quality data streams available, we would cover how feature engineering, bias correction, normalisation, and a model can be developed with an actionable surface that a regional can use tomorrow morning.&nbsp;</p>\n\n\n\n<p>Contributors: Prithviraj Pramanik, AQAI; Hugo Ruiz Verastegui, Anthony Mockler, Judith Hanan, Frontier Data Lab;&nbsp;Risdianto&nbsp;Irawan, UNICEF EAPRO;&nbsp;Soheib&nbsp;Abdalla, Andrew Dunbrack, UNICEF Lao PDR Country Office; Halim Jun, Daniel Alvarez, Shane O’Connor, UNICEF Office of Innovation;&nbsp;</p>\n</div></div>",
    "imageUrl": "https://towardsdatascience.com/wp-content/uploads/2026/01/UNI724381-scaled-1.jpg",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/index/stargate-community",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/stargate-community",
    "title": "Stargate Community",
    "publishedAt": "Tue, 20 Jan 2026 19:00:00 GMT",
    "fetchedAt": "2026-01-25T19:07:59.824Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div id=\"main\" tabindex=\"-1\"><span aria-live=\"polite\" aria-atomic=\"true\">OpenAI</span><article><div><p><span>OpenAI’s mission is to ensure that AGI benefits all of humanity, and in order to do that, we are working to ensure our Stargate campuses benefit the local communities that make them possible. We believe that AI </span><a href=\"https://cdn.openai.com/global-affairs/openai-infra-economics-10.09.24.pdf\" target=\"_blank\" referrerpolicy=\"no-referrer-when-downgrade\" rel=\"noopener noreferrer\"><u><span>infrastructure</span></u>⁠<span>(opens in a new window)</span></a><span> is vital for American competitiveness and economic opportunity, while boosting local economies by creating jobs and bringing in local revenue.</span></p><p><span>When we announced Stargate one year ago in January 2025, we set out to expand our U.S. AI infrastructure to 10GW by 2029—and just one year in, we are already well beyond halfway to that goal in planned capacity, with the first site in Abilene, Texas already training and serving frontier AI systems and multiple Stargate sites under development across Texas, New Mexico, Wisconsin, and Michigan. We are committed to working with communities to ensure that our Stargate campuses are built and run in a way that strengthens communities and demonstrates that we’re being good neighbors.</span></p><p><span>AI is delivering tangible benefits already, from helping hundreds of millions of people with their </span><a href=\"https://openai.com/index/introducing-chatgpt-health/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>health and wellness</span></u></a><span> every week to unlocking new scientific advances. At the same time, we are making the AI models themselves much more capable and power efficient each year. As we’ve done so, demand has increased even more, since intelligence can more affordably be applied to more important problems, and there’s no limit to the problems that people want to solve. That’s why we and the industry see a critical need for such large-scale AI infrastructure.</span></p><p><span>Partnering with local communities starts with understanding local needs. Going forward, every Stargate site will have its own locally tailored </span><b><span>Stargate Community</span></b><span> plan, driven by community input and local concerns. They will all rest on this same core premise: Stargate is a partnership with communities, and we can only achieve our mission by being good neighbors.</span></p><p><span>Across all of our </span><b><span>Stargate Community</span></b><span> plans,</span><b><span> we commit to paying our own way on energy, so that our operations don’t increase your electricity prices</span></b><span>. Every community and region has unique energy needs and grid conditions, and our commitment will be tailored to the region. Depending on the site, this can range from bringing new dedicated power and storage that the project fully funds, to adding and paying for new energy generation and transmission resources. This commitment can be grounded in specific approaches like:</span></p><div><ol><li><span>Funding the incremental generation and grid upgrades our load requires</span></li><li><span>Planning transparently and proactively with local utilities, transmission providers, state utility regulators (public utility/service commissions) and regional grid operators</span></li><li><span>Working with utilities, grid operators, and the industry to develop strategies for operating AI campuses as flexible loads, so when peak conditions or grid stress are forecast, we can reduce or curtail consumption and participate in demand-response and grid-stability programs</span></li></ol></div><p><span>We are already working with partners to deliver this on existing Stargate campuses. For example:</span></p><div><ul><li><span>In </span><a href=\"https://vantage-dc.com/news/openai-oracle-and-vantage-data-centers-announce-stargate-data-center-site-in-wisconsin/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>Wisconsin</span></u>⁠<span>(opens in a new window)</span></a><span>, our partners Oracle and Vantage are working with WEC Energy Group to develop new energy generation and capacity, including solar and battery storage.</span><b><span> </span></b><span>Our developer partners are also underwriting 100% of the power infrastructure investment through a dedicated electricity rate from WEC. The proposed rate is designed to protect other customers from price increases associated with the new investments needed to serve the facility.</span></li><li><span>In </span><a href=\"https://www.related-digital.com/michigan\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>Michigan</span></u>⁠<span>(opens in a new window)</span></a><span>, our partners Oracle and Related Digital are working with DTE Energy to supply the project’s power using existing resources, augmented by a new battery storage investment financed entirely by the project. The structure is designed to help ensure there is</span><b><span> </span></b><span>no impact on DTE’s existing customers’ energy supply or rates. DTE customers can also benefit from the project contributing its share to the fixed costs of maintaining and improving the grid.</span></li><li><span>In </span><a href=\"https://openai.com/index/stargate-sb-energy-partnership/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>Texas</span></u></a><span>, our partners SB Energy plans to fund and build new energy generation and storage to supply the majority of the power needed to run the Stargate campus we’re developing together in Milam County.</span></li></ul></div><p><span>These are early examples, and we’ll continue to find meaningful ways to benefit local communities including:</span></p><div><ul><li><b><span>Minimizing water use and protecting local ecosystems</span></b><span> by prioritizing closed-loop or low-water cooling systems. </span><b><span>AI campuses and deep learning workloads use innovations in cooling water systems design that drastically reduce the water use compared to traditional datacenters</span></b><span>. Water required by our facilities should be a fraction of a community’s overall water use. As Mayor Weldon Hurt of Abilene, Texas </span><a href=\"https://www.reporternews.com/story/news/2025/10/14/water-electricity-concerns-addressed-by-stargate-data-center-leaders-in-abilene-texas/86585222007/?gnt-cfr=1&amp;gca-cat=p&amp;gca-uir=true&amp;gca-epti=undefined&amp;gca-ft=0&amp;gca-ds=sophi\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>noted,</span></u>⁠<span>(opens in a new window)</span></a><span> the water use at the Abilene site in a year will be half as much as Abilene uses in a single day. These designs are used across all of our Stargate AI campuses - including with Oracle in </span><a href=\"https://www.crusoe.ai/resources/blog/an-inside-look-at-the-abilene-ai-data-center\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>Abilene</span></u>⁠<span>(opens in a new window)</span></a><span> and </span><a href=\"https://vantage-dc.com/news/vantage-data-centers-unveils-plans-for-frontier-a-25b-mega-campus-in-texas-to-meet-unprecedented-ai-demand/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>Shackelford County</span></u>⁠<span>(opens in a new window)</span></a><span>, Texas; </span><a href=\"https://www.stackinfra.com/about/news-press/press-releases/stack-infrastructure-delivers-digital-infrastructure-for-data-center-campus-in-new-mexico/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>Doña Ana County, New Mexico</span></u>⁠<span>(opens in a new window)</span></a><span>; </span><a href=\"https://www.related-digital.com/news/openai-oracle-and-related-digital-announce-stargate-data-center-site-in-michigan\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>Saline Township, Michigan</span></u>⁠<span>(opens in a new window)</span></a><span>, </span><a href=\"https://vantage-dc.com/news/openai-oracle-and-vantage-data-centers-announce-stargate-data-center-site-in-wisconsin/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>Port Washington, Wisconsin</span></u>⁠<span>(opens in a new window)</span></a><span> and our latest AI campus with Microsoft in </span><a href=\"https://blogs.microsoft.com/on-the-issues/2025/09/18/made-in-wisconsin-the-worlds-most-powerful-ai-datacenter/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>Mount Pleasant, Wisconsin</span></u><span>.</span>⁠<span>(opens in a new window)</span></a><span> This approach is paired with site-specific environmental and infrastructure investments developed with local partners. For example, in Wisconsin our partners will</span><a href=\"https://vantage-dc.com/news/openai-oracle-and-vantage-data-centers-announce-stargate-data-center-site-in-wisconsin/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span> invest a minimum of $175M in local infrastructure upgrades and water restoration projects</span></u><span>.</span>⁠<span>(opens in a new window)</span></a></li><li><b><span>Investing early in local jobs and workforce pathways</span></b><span> by establishing OpenAI Academies as the backbone of regional workforce development in Stargate communities. These Academies will be customized for each site, </span><a href=\"https://openai.com/index/openai-certificate-courses/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>delivering credentials </span></u></a><span>and clear pathways into high-quality jobs aligned with local employers and the region’s evolving AI economy. We will launch our first Stargate community OpenAI Academy in Abilene, Texas this spring. We are also engaging alongside our partners with labor unions and workforce partners to support the skilled trades and technical workforce needed to build and operate AI infrastructure at this scale.</span></li></ul></div><p><span>Stargate is a physical infrastructure program that requires deep partnership. We’re reliant on and grateful to the communities that make it possible, and we are committed to showing up as long-term partners.</span></p><div><p><img alt=\"Group photo of Stargate community members from various partner companies standing together indoors around a welcome sign for the Milam County Data Center Open House hosted by OpenAI. Everyone is smiling in a casual, workshop-style event space.\" data-nosnippet=\"true\" loading=\"lazy\" width=\"1999\" height=\"1474\" decoding=\"async\" data-nimg=\"1\" sizes=\"(min-width: 1728px) 1728px, 100vw\" srcset=\"https://images.ctfassets.net/kftzwdyauwt9/6yxDKx6E7sKRsEEdK5yivC/bf3f92c8c0f22b7ed714f8725f934a5a/stargate-community.jpg?w=640&amp;q=90&amp;fm=webp 640w, https://images.ctfassets.net/kftzwdyauwt9/6yxDKx6E7sKRsEEdK5yivC/bf3f92c8c0f22b7ed714f8725f934a5a/stargate-community.jpg?w=750&amp;q=90&amp;fm=webp 750w, https://images.ctfassets.net/kftzwdyauwt9/6yxDKx6E7sKRsEEdK5yivC/bf3f92c8c0f22b7ed714f8725f934a5a/stargate-community.jpg?w=828&amp;q=90&amp;fm=webp 828w, https://images.ctfassets.net/kftzwdyauwt9/6yxDKx6E7sKRsEEdK5yivC/bf3f92c8c0f22b7ed714f8725f934a5a/stargate-community.jpg?w=1080&amp;q=90&amp;fm=webp 1080w, https://images.ctfassets.net/kftzwdyauwt9/6yxDKx6E7sKRsEEdK5yivC/bf3f92c8c0f22b7ed714f8725f934a5a/stargate-community.jpg?w=1200&amp;q=90&amp;fm=webp 1200w, https://images.ctfassets.net/kftzwdyauwt9/6yxDKx6E7sKRsEEdK5yivC/bf3f92c8c0f22b7ed714f8725f934a5a/stargate-community.jpg?w=1920&amp;q=90&amp;fm=webp 1920w, https://images.ctfassets.net/kftzwdyauwt9/6yxDKx6E7sKRsEEdK5yivC/bf3f92c8c0f22b7ed714f8725f934a5a/stargate-community.jpg?w=2048&amp;q=90&amp;fm=webp 2048w, https://images.ctfassets.net/kftzwdyauwt9/6yxDKx6E7sKRsEEdK5yivC/bf3f92c8c0f22b7ed714f8725f934a5a/stargate-community.jpg?w=3840&amp;q=90&amp;fm=webp 3840w\" src=\"https://images.ctfassets.net/kftzwdyauwt9/6yxDKx6E7sKRsEEdK5yivC/bf3f92c8c0f22b7ed714f8725f934a5a/stargate-community.jpg?w=3840&amp;q=90&amp;fm=webp\" style=\"max-width: 100%; height: auto; border-radius: 1rem; margin: 2rem 0px;\"></p></div></div><section id=\"citations\" data-testid=\"citations\"><ul><li><a href=\"https://openai.com/news/?tags=partnerships\" target=\"_blank\" rel=\"noopener noreferrer\">Partnerships</a></li><li><a href=\"https://openai.com/news/?tags=community\" target=\"_blank\" rel=\"noopener noreferrer\">Community</a></li><li><a href=\"https://openai.com/news/?tags=2026\" target=\"_blank\" rel=\"noopener noreferrer\">2026</a></li></ul></section></article></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/5kRWor8nmGQC5MVpbPDYlN/7194b7357f2a1b9bf3f261ef49e5c85c/stargate-community-16_9.png?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/index/cisco",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/cisco",
    "title": "Cisco and OpenAI redefine enterprise engineering with AI agents",
    "publishedAt": "Tue, 20 Jan 2026 11:00:00 GMT",
    "fetchedAt": "2026-01-25T19:07:59.937Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div><p><span>For decades, Cisco has built and operated some of the world’s most complex, mission-critical software systems. As generative AI matured from experimentation to real operational capability, Cisco leaned into what it knows best: </span><b><span>scaling advanced technology inside demanding, real-world environments</span></b><span>.</span></p><p><span>That mindset led Cisco to begin working closely with OpenAI around Codex, helping define what enterprise-grade AI for software engineering should look like in practice—and how Codex could be applied to real, large-scale engineering work inside complex production environments.</span></p><p><span>Rather than treat Codex as a standalone developer tool, Cisco began integrating it directly into production engineering workflows, exposing it to massive multi-repository systems, C/C++-heavy codebases, and the security, compliance, and governance requirements of a global enterprise.</span></p><p><span>In the process, Cisco helped shape Codex into something fundamentally different from a developer productivity tool: </span><b><span>an AI engineering teammate capable of operating at enterprise scale</span></b><span>.</span></p><div><blockquote>\"I’ve loved discovering new opportunities to integrate Codex into Cisco's enterprise software lifecycle workflows. Collaborating with the OpenAI team to get Codex enterprise production ready has been rewarding as well.\"</blockquote><p>—Ching Ho, a member of Cisco's engineering leadership</p></div><div id=\"evaluating-agentic-ai-in-complex-codebases\"><p></p><h2><span>Evaluating agentic AI in complex codebases</span></h2><p></p></div><p><span>Cisco already runs a mature engineering organization with multiple AI initiatives in flight. What made Codex compelling wasn’t code completion or surface-level automation, but </span><b><span>agency</span></b><span>. Codex demonstrated the ability to:</span></p><div><ul><li><span>Understand and reason across </span><b><span>large, interconnected repositories</span></b></li><li><span>Work fluently in </span><b><span>complex languages</span></b></li><li><span>Execute real workflows through </span><b><span>CLI-based, autonomous compile-test-fix loops</span></b></li><li><span>Operate within existing </span><b><span>review, security, and governance frameworks</span></b></li></ul></div><p><span>By working directly with OpenAI, Cisco engineers were able to give feedback on how these capabilities behaved in real environments, shaping areas like workflow orchestration, security controls, and support for long-running engineering tasks—all of which are critical for enterprise use.</span></p><div id=\"using-codex-for-critical-engineering-workflows\"><p></p><h2><span>Using Codex for critical engineering workflows</span></h2><p></p></div><p><span>Once Codex was embedded into everyday engineering work, teams began applying it to some of their most challenging and time-consuming workflows:</span></p><p><b><span>Cross-repo build optimization</span></b><span>: Codex analyzed build logs and dependency graphs across more than 15 interconnected repositories, identifying inefficiencies. The result: a ~20% reduction in build times and more than </span><b><span>1,500 engineering hours saved per month</span></b><span> across global environments.</span></p><p><b><span>Defect remediation at scale (CodeWatch)</span></b><span>: Using Codex-CLI, Cisco automated defect repair with iterative, agentic execution on large-scale C/C++ codebases. What once took weeks of manual effort now completes in hours, delivering a </span><b><span>10-15× increase in defect resolution throughput</span></b><span> and freeing engineers to focus on design and validation.</span></p><p><b><span>Framework migrations in days, not weeks</span></b><span>: When Splunk teams needed to migrate multiple UIs from React 18 to 19, Codex handled the bulk of repetitive changes autonomously, compressing weeks of work into days and allowing engineers to concentrate on judgment-heavy decisions.</span></p><div><blockquote>“The biggest gains came when we stopped thinking about Codex as a tool and started treating it as part of the team. We use Codex to generate and follow a plan document, allowing the reviewing team to more easily understand both the process and the code generated.”</blockquote><p>—Ryan Brady, a Principal Engineer in Cisco's Splunk group</p></div><div id=\"shaping-codexs-roadmap-for-the-enterprise\"><p></p><h2><span>Shaping Codex's roadmap for the enterprise</span></h2><p></p></div><p><span>Cisco provided continuous feedback from real production use that helped OpenAI accelerate Codex’s readiness for large enterprises—particularly in areas like compliance, long-running task management, and integration with existing development pipelines.</span></p><p><span>For Cisco, the collaboration established a repeatable model for adopting next-generation AI: </span><b><span>deep technical partnership, real workloads, and leadership alignment from day one</span></b><span>.</span></p><div><blockquote>“Codex has become a meaningful part of how we think about AI-assisted development and operations going forward.”</blockquote><p>—Brad Murphy, a VP leading Cisco’s Splunk Engineering team</p></div><p><span>In the months ahead, Cisco and OpenAI will continue to collaborate closely on Codex and beyond to advance their shared mission of AI-native engineering at enterprise scale.</span></p></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/6biPCt1l6a2vedPJey5inM/67b80b0750688b948c1fd9b9427cccbd/oai_Cisco_SEO.png?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/index/strengthening-the-us-ai-supply-chain",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/strengthening-the-us-ai-supply-chain",
    "title": "Strengthening the U.S. AI supply chain through domestic manufacturing",
    "publishedAt": "Thu, 15 Jan 2026 00:00:00 GMT",
    "fetchedAt": "2026-01-25T19:08:01.707Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div id=\"main\" tabindex=\"-1\"><span aria-live=\"polite\" aria-atomic=\"true\">OpenAI</span><article><div><p>New Request for Proposals to help build and scale the infrastructure behind advanced AI.</p></div><div><p><span>Building the infrastructure required to power advanced AI presents a historic opportunity to strengthen domestic supply chains and </span><a href=\"https://cdn.openai.com/pdf/21b88bb5-10a3-4566-919d-f9a6b9c3e632/%5BOpenAI_OSTP%20RFI%20Oct%2027%202025%5D.pdf\" target=\"_blank\" referrerpolicy=\"no-referrer-when-downgrade\" rel=\"noopener noreferrer\"><u><span>reindustrialize the country</span></u>⁠<span>(opens in a new window)</span></a><span>. If we seize it, we can catalyze U.S. manufacturing, modernize our energy grid, create well-paid jobs, and strengthen American leadership. Infrastructure has long been destiny when it comes to America’s economic success, and that will be especially true in the Intelligence Age.</span></p><p><span>At OpenAI, we’re committed to doing our part. Since launching our Stargate initiative almost one year ago, we’ve announced planned capacity that puts us well over halfway to meeting our 10-gigawatt commitment. These investments are already translating into good jobs and local economic growth in communities across the country. Over the coming years, we’ll build on this progress by strengthening the broader domestic AI supply chain and accelerating investment in U.S. manufacturing capabilities that support American AI leadership.</span></p><p><span>As part of that work, today we’re launching a new </span><a href=\"https://cdn.openai.com/pdf/rfp-for-us-hardware-manufacturing.pdf\" target=\"_blank\" referrerpolicy=\"no-referrer-when-downgrade\" rel=\"noopener noreferrer\"><span>Request for Proposals</span>⁠<span>(opens in a new window)</span></a><span> (RFP) focused on U.S.-based manufacturing across key parts of the AI supply chain, including data center inputs, consumer electronics, and robotics. Our goal is to identify and enable domestic manufacturing capacity that can help shorten timelines, strengthen resilience, and extend technology leadership as AI infrastructure scales.</span></p><p><span>We’re seeking proposals from manufacturers, suppliers, and partners who are building – or are prepared to build – critical components and systems for the AI ecosystem in the United States, including:</span></p><div><ul><li><span>Modules, tooling and equipment, and final assembly for consumer electronics</span></li><li><span>Manufacturing for compute, power, cooling, and supporting data center hardware</span></li><li><span>Critical inputs for advanced robotics (e.g., gearboxes, motors, power electronics)</span></li></ul></div><p><span>When people talk about AI infrastructure, the conversation often stops at chips and data centers. But advanced AI depends on a much broader ecosystem of physical components: the racks, cabling, networking gear, cooling systems, power systems, power electronics, electromechanical modules, and testing and assembly capacity are all required to bring it all online at scale. Our RFP aims to build on momentum that already exists by identifying where targeted partnerships, demand signals, and coordination can help unlock faster growth, larger scale, and more durable U.S. leadership in AI.</span></p><p><span>Responses to the RFP will help inform partnerships, procurement strategies, and infrastructure planning. We see this as part of a broader story of reindustrialization. Across the country, manufacturers are investing in advanced production capabilities to support the AI ecosystem – bringing new facilities online, modernizing supply chains, and expanding skilled workforces. These investments are critical to ensuring that the benefits of AI are created and shared here in the U.S..</span></p><p><span>We will review proposals on a rolling basis and follow up with selected respondents on next steps. The deadline to submit a proposal is June 2026.</span></p></div><section id=\"citations\" data-testid=\"citations\"><ul><li><a href=\"https://openai.com/news/?tags=2026\" target=\"_blank\" rel=\"noopener noreferrer\">2026</a></li></ul></section></article></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/728oLmSXw7mfWWGe9SZ7zs/ea6deb1e3a117c0ec8518968020046a8/AI_Supply.png?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/index/openai-raising-concerns-policy",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/openai-raising-concerns-policy",
    "title": "OpenAI’s Raising Concerns Policy",
    "publishedAt": "Mon, 12 Jan 2026 00:00:00 GMT",
    "fetchedAt": "2026-01-25T19:08:01.416Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div id=\"main\" tabindex=\"-1\"><span aria-live=\"polite\" aria-atomic=\"true\">OpenAI</span><article><div><p>We’re publishing our Raising Concerns Policy, which protects employees’ rights to make protected disclosures.</p></div><div><p><span>We believe rigorous debate about AI is essential to ensuring that AI is safe and benefits the most people possible, which is why OpenAI has a Raising Concerns Policy. This policy protects employees’ rights to raise issues, including about AI safety, applicable laws, or company policies. We’ve recently revised our policy—you can read it </span><a href=\"https://cdn.openai.com/policies/openai-raising-concerns-policy.pdf\" target=\"_blank\" referrerpolicy=\"no-referrer-when-downgrade\" rel=\"noopener noreferrer\"><span>here</span>⁠<span>(opens in a new window)</span></a><span>.</span></p><div id=\"background-on-openais-raising-concerns-policy\"><p></p><h2><span>Background on OpenAI’s Raising Concerns Policy</span></h2><p></p></div><p><span>Our Raising Concerns Policy outlines various ways employees can raise issues and expressly prohibits harassment and retaliation against those who decide to do so. Our policy also makes clear that employees have the right to make reports or disclosures to government agencies, including the U.S. National Labor Relations Board, the U.S. Equal Employment Opportunity Commission, the U.S. Securities and Exchange Commission, and the California Attorney General’s Office.</span></p><p><span>In April 2024, we introduced a new 24/7 Integrity Line, which allows OpenAI employees to anonymously raise concerns if they prefer not to use existing channels, such as through their manager, HR, Compliance or Legal. When potential legal or policy violations are reported, they are handled by our Compliance, Legal, Employee Relations, and Security teams. Certain issues may also be shared with the Audit Committee of the Board of Directors.</span></p><p><span>Like other companies in our industry, OpenAI continues to distinguish between raising concerns and revealing company trade secrets. Given our technology’s implications for U.S. national security, the latter (subject to the right to make protected disclosures) remains prohibited under confidentiality agreements for current and former employees.</span></p></div><section id=\"citations\" data-testid=\"citations\"><ul><li><a href=\"https://openai.com/news/?tags=policies-procedures\" target=\"_blank\" rel=\"noopener noreferrer\">Policies and Procedures</a></li><li><a href=\"https://openai.com/news/?tags=global-affairs\" target=\"_blank\" rel=\"noopener noreferrer\">Global Affairs</a></li><li><a href=\"https://openai.com/news/?tags=2026\" target=\"_blank\" rel=\"noopener noreferrer\">2026</a></li></ul></section></article></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/6KfxPkfzXpR8oZ3uxUA4EH/c1a74850647b84025d04760929d0bc9f/OpenAI_s_Raising_Concerns_Policy_Cover.jpg?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/index/netomi",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/netomi",
    "title": "Netomi’s lessons for scaling agentic systems into the enterprise",
    "publishedAt": "Thu, 08 Jan 2026 13:00:00 GMT",
    "fetchedAt": "2026-01-25T19:08:02.758Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div><p><span>Enterprises expect AI agents to handle messy workflows reliably, honor policies by default, operate under heavy load, and show their work.</span></p><p><a href=\"https://www.netomi.com/\" target=\"_blank\" rel=\"noopener noreferrer\"><span>Netomi</span>⁠<span>(opens in a new window)</span></a><span> builds systems that meet that high bar, serving Fortune 500 customers like United Airlines and DraftKings. Their platform pairs GPT‑4.1 for low-latency, reliable tool use with GPT‑5.2 for deeper, multi-step planning, running both inside a governed execution layer designed to keep model-driven actions predictable under real production conditions.</span></p><p><span>Running agentic systems at this scale has given Netomi a blueprint for what makes these deployments work inside the enterprise.</span></p><div id=\"lesson-1-build-for-real-world-complexity-not-idealized-flows\"><p></p><h2><span>Lesson 1: Build for real-world complexity, not idealized flows</span></h2><p></p></div><p><span>A single enterprise request rarely maps to a single API. Real workflows span booking engines, loyalty databases, CRM systems, policy logic, payments, and knowledge sources. The data is often incomplete, conflicting, or time-sensitive. Systems that depend on brittle flows collapse under this variability.</span></p><p><span>Netomi designed its Agentic OS so OpenAI models sit at the center of a governed orchestration pipeline built for this level of ambiguity. The platform uses GPT‑4.1 for fast, reliable reasoning and tool-calling—critical for real-time workflows—and GPT‑5.2 when multi-step planning or deeper reasoning is required.</span></p><div><blockquote>“Our goal was to orchestrate the many systems a human agent would normally juggle and do it safely at machine speed.”</blockquote><p>—Puneet Mehta, CEO, Netomi</p></div><p><span>To ensure consistent agent behavior across long, complex tasks, Netomi follows the agentic prompting patterns recommended by OpenAI:</span></p><div><ul><li><b><span>Persistence reminders</span></b><span> to help GPT‑5.2 carry reasoning across long, multi-step workflows</span></li><li><b><span>Explicit tool-use expectations</span></b><span>, suppressing hallucinated answers by steering GPT‑4.1 to call tools for authoritative information during transactional operations</span></li><li><b><span>Structured planning</span></b><span>, which leverages GPT‑5.2’s deeper reasoning to outline and execute multi-step tasks</span></li><li><b><span>Agent-driven rich media decisions</span></b><span>, relying on GPT‑5.2 to detect and signal when a tool call should return images, videos, forms, or other rich, multimodal elements</span></li></ul></div><p><span>Together, these patterns help the model reliably map unstructured requests to multi-step workflows and maintain state across discontinuous interactions.</span></p><p><span>Few industries expose the need for multi-step reasoning as clearly as airlines, where one interaction routinely spans multiple systems and policy layers. A single question may require checking fare rules, recalculating loyalty benefits, initiating ticket changes, and coordinating with flight operations.</span></p><p><span>“In airlines, context changes by the minute. AI has to reason about the scene the customer is in—not just execute a siloed task,” said Mehta. “That’s why situational awareness matters way more than just workflows, and why a context-led ensemble architecture is essential.”</span></p><p><span>With GPT‑4.1 and GPT‑5.2, Netomi can keep extending these patterns into richer multi-step automations—using the models not just to answer questions, but to plan tasks, sequence actions, and coordinate the backend systems a major airline depends on.</span></p><div id=\"lesson-2-parallelize-everything-to-meet-enterprise-latency-expectations\"><p></p><h2><span>Lesson 2: Parallelize everything to meet enterprise latency expectations</span></h2><p></p></div><p><span>In high-pressure moments—rebooking during a storm, resolving a billing issue, or handling sudden spikes in demand—users will abandon any system that hesitates. Latency defines trust.</span></p><p><span>Most AI systems fail because they execute tasks sequentially: classify → retrieve → validate → call tools → generate output. Netomi instead designed for concurrency, taking advantage of low-latency streaming and tool-calling stability of GPT‑4.1.</span></p><p><span>GPT‑4.1 provides fast time-to-first-token and predictable tool-calling behavior, which make this architecture viable at scale; while GPT‑5.2 provides deeper multi-step reasoning paths when needed. Netomi’s concurrency framework ensures the </span><i><span>total system</span></i><span>, not just the model, stays under critical latency thresholds.</span></p><p><span>These concurrency demands aren’t unique to airlines. Any system exposed to sudden, extreme traffic surges needs the same architectural discipline. DraftKings, for instance, regularly stress-tests this model, with traffic during major sporting events spiking above 40,000 concurrent customer requests per second.&nbsp;</span></p><p><span>During such events, Netomi has sustained sub-three-second responses with 98% intent classification accuracy, even as workflows touch accounts, payments, knowledge lookups, and regulatory checks.</span></p><p><span>“AI is central and critical to how we support customers in the moments that matter most,” said Paul Liberman, Co-Founder and President of Operations at DraftKings. “Netomi’s platform helps us handle massive spikes in activity with agility and precision.”</span></p><p><span>At scale, Netomi’s concurrency model depends on the fast, predictable tool-calling of GPT‑4.1, which keeps multi-step workflows responsive under extreme load.</span></p><div id=\"lesson-3-make-governance-an-intrinsic-part-of-the-runtime\"><p></p><h2><span>Lesson 3: Make governance an intrinsic part of the runtime</span></h2><p></p></div><p><span>Enterprise AI must be trustworthy by design, with governance woven directly into the runtime—not added as an external layer.</span></p><p><span>When intent confidence drops below threshold, or when a request cannot be classified with high certainty, Netomi’s governance mechanisms kick in to determine how the request is handled, ensuring the system backs off from free-form generation in favor of controlled execution paths.</span></p><p><span>At a technical level, the governance layer handles:</span></p><div><ul><li><b><span>Schema validation</span></b><span>, which validates every tool call against expected arguments and OpenAPI contracts before execution</span></li><li><b><span>Policy enforcement</span></b><span> that applies topic filters, brand restrictions, and compliance checks inline during reasoning and tool use</span></li><li><b><span>PII protection</span></b><span> to detect and mask sensitive data as part of pre-processing and response handling</span></li><li><b><span>Deterministic fallback</span></b><span>, routing back to known-safe behaviors when intent, data, or tool calls are ambiguous</span></li><li><b><span>Runtime observability, </span></b><span>exposing</span><b><span> </span></b><span>token traces, reasoning steps, and tool-chain logs for real-time inspection and debugging</span></li></ul></div><p><span>In highly regulated domains like dental insurance, this kind of governance is non-negotiable. A Netomi customer in the insurance industry processes close to two million provider requests each year across all 50 states, including eligibility checks, benefits lookups, and claim status inquiries where a single incorrect response can create downstream regulatory or service risk.&nbsp;</span></p><p><span>During open enrollment, when scrutiny and volume peaked, the company needed AI that enforced policy as part of the runtime itself. Netomi’s architecture was up to that complex requirement.</span></p><p><span>“We built the system so that if the agent ever reaches uncertainty, it knows exactly how to back off safely,” said Mehta. “The governance is not bolted on—it’s part of the runtime.”</span></p><div id=\"a-blueprint-for-building-agentic-systems-that-work-for-the-enterprise\"><p></p><h2><span>A blueprint for building agentic systems that work for the enterprise</span></h2><p></p></div><p><span>Netomi’s path shows what it takes to earn enterprise trust: build for complexity, parallelize to meet latency demands, and bake governance into every workflow. OpenAI models form the reasoning backbone, while Netomi’s systems engineering ensures that intelligence is operationally safe, auditable, and ready for Fortune 500 environments.</span></p><p><span>These principles helped Netomi scale across some of the world’s most demanding industries—and offer a blueprint for any startup looking to turn agentic AI into production-grade infrastructure.</span></p></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/73MzGWJqwp1YazJCDrUhra/be3d8a969d196f6492e3a912d4ff8361/oai_Netomi_SEO.jpg?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/index/unrolling-the-codex-agent-loop",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/unrolling-the-codex-agent-loop",
    "title": "Unrolling the Codex agent loop",
    "publishedAt": "Fri, 23 Jan 2026 12:00:00 GMT",
    "fetchedAt": "2026-01-25T19:08:02.175Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div><p><a href=\"https://developers.openai.com/codex/cli\" target=\"_blank\" referrerpolicy=\"no-referrer-when-downgrade\" rel=\"noopener noreferrer\"><u><span>Codex CLI</span></u>⁠<span>(opens in a new window)</span></a><span> is our cross-platform local software agent, designed to produce high-quality, reliable software changes while operating safely and efficiently on your machine. We’ve learned a tremendous amount about how to build a world-class software agent </span><a href=\"https://openai.com/index/introducing-o3-and-o4-mini/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>since we first launched the CLI in April</span></u>⁠</a><span>. To unpack those insights, this is the first post in an ongoing series where we’ll explore various aspects of how Codex works, as well as hard-earned lessons. (For an even more granular view on how the Codex CLI is built, check out our open source repository at </span><a href=\"https://github.com/openai/codex\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>https://github.com/openai/codex</span></u>⁠<span>(opens in a new window)</span></a><span>. Many of the finer details of our design decisions are memorialized in GitHub issues and pull requests if you’d like to learn more.)</span></p><p><span>To kick off, we’ll focus on the </span><i><span>agent loop</span></i><span>, which is the core logic in Codex CLI that is responsible for orchestrating the interaction between the user, the model, and the tools the model invokes to perform meaningful software work. We hope this post gives you a good view into the role our agent (or “harness”) plays in making use of an LLM.</span></p><p><span>Before we dive in, a quick note on terminology: at OpenAI, “Codex” encompasses a suite of software agent offerings, including Codex CLI, Codex Cloud, and the Codex VS Code extension. This post focuses on the Codex </span><i><span>harness</span></i><span>, which provides the core agent loop and execution logic that underlies all Codex experiences and is surfaced through the Codex CLI. For ease here, we’ll use the terms “Codex” and “Codex CLI” interchangeably.</span></p><div id=\"the-agent-loop\"><p></p><h2><span>The agent loop</span></h2><p></p></div><p><span>At the heart of every AI agent is something called “the agent loop.” A simplified illustration of the agent loop looks like this:</span></p><p><span>To start, the agent takes </span><i><span>input</span></i><span> from the user to include in the set of textual instructions it prepares for the model known as a </span><i><span>prompt</span></i><span>.</span></p><p><span>The next step is to query the model by sending it our instructions and asking it to generate a response, a process known as </span><i><span>inference</span></i><span>. During inference, the textual prompt is first translated into a sequence of input </span><a href=\"https://platform.openai.com/docs/concepts#tokens\" target=\"_blank\" referrerpolicy=\"no-referrer-when-downgrade\" rel=\"noopener noreferrer\"><u><span>tokens</span></u>⁠<span>(opens in a new window)</span></a><span>—integers that index into the model’s vocabulary. These tokens are then used to sample the model, producing a new sequence of output tokens.</span></p><p><span>The output tokens are translated back into text, which becomes the model’s response. Because tokens are produced incrementally, this translation can happen as the model runs, which is why many LLM-based applications display streaming output. In practice, inference is usually encapsulated behind an API that operates on text, abstracting away the details of tokenization.</span></p><p><span>As the result of the inference step, the model either (1) produces a final response to the user’s original input, or (2) requests a </span><i><span>tool call</span></i><span> that the agent is expected to perform (e.g., “run </span><code><span>ls</span></code><span> and report the output”). In the case of (2), the agent executes the tool call and appends its output to the original prompt. This output is used to generate a new input that’s used to re-query the model; the agent can then take this new information into account and try again.</span></p><p><span>This process repeats until the model stops emitting tool calls and instead produces a message for the user (referred to as an </span><i><span>assistant message</span></i><span> in OpenAI models). In many cases, this message directly answers the user’s original request, but it may also be a follow-up question for the user.</span></p><p><span>Because the agent can execute tool calls that modify the local environment, its “output” is not limited to the assistant message. In many cases, the primary output of a software agent is the code it writes or edits on your machine. Nevertheless, each turn always ends with an assistant message—such as “I added the </span><code><span>architecture.md</span></code><span> you asked for”—which signals a termination state in the agent loop. From the agent’s perspective, its work is complete and control returns to the user.</span></p><p><span>The journey from </span><i><span>user input</span></i><span> to </span><i><span>agent response</span></i><span> shown in the diagram is referred to as one </span><i><span>turn</span></i><span> of a conversation (a </span><i><span>thread </span></i><span>in Codex). Though this </span><i><span>conversation turn</span></i><span> can include many iterations between the </span><b><span>model inference</span></b><span> and </span><b><span>tool calls</span></b><span>). Every time you send a new message to an existing conversation, the conversation history is included as part of the prompt for the new turn, which includes the messages and tool calls from previous turns:</span></p><p><span>This means that as the conversation grows, so does the length of the prompt used to sample the model. This length matters because every model has a </span><i><span>context window</span></i><span>, which is the maximum number of tokens it can use for one inference call. Note this window includes both input </span><i><span>and</span></i><span> output tokens. As you might imagine, an agent could decide to make hundreds of tool calls in a single turn, potentially exhausting the context window. For this reason, </span><i><span>context window management</span></i><span> is one of the agent’s many responsibilities. Now, let’s dive in to see how Codex runs the agent loop.</span></p><div id=\"model-inference\"><p></p><h2><span>Model inference</span></h2><p></p></div><p><span>The Codex CLI sends HTTP requests to the </span><a href=\"https://platform.openai.com/docs/api-reference/responses\" target=\"_blank\" referrerpolicy=\"no-referrer-when-downgrade\" rel=\"noopener noreferrer\"><u><span>Responses API</span></u>⁠<span>(opens in a new window)</span></a><span> to run model inference. We’ll examine how information flows through Codex, which uses the Responses API to drive the agent loop.</span></p><div><ul><li><a href=\"https://github.com/openai/codex/blob/d886a8646cb8d3671c3029d08ae8f13fa6536899/codex-rs/core/src/model_provider_info.rs#L141\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>When using ChatGPT login</span></u>⁠<span>(opens in a new window)</span></a><span> with the Codex CLI, it uses </span><code><span>https://chatgpt.com/backend-api/codex/responses</span></code><span> as the endpoint</span></li><li><a href=\"https://github.com/openai/codex/blob/d886a8646cb8d3671c3029d08ae8f13fa6536899/codex-rs/core/src/model_provider_info.rs#L143\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>When using API-key authentication</span></u>⁠<span>(opens in a new window)</span></a><span> with OpenAI hosted models, it uses </span><code><span>https://api.openai.com/v1/responses</span></code><span> as the endpoint</span></li><li><span>When running Codex CLI with </span><code><span>--oss</span></code><span> to use </span><a href=\"https://openai.com/index/introducing-gpt-oss/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>gpt-oss</span></u>⁠</a><span> with </span><a href=\"https://github.com/openai/codex/pull/8798\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>ollama 0.13.4+</span></u>⁠<span>(opens in a new window)</span></a><span> or </span><a href=\"https://lmstudio.ai/blog/openresponses\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>LM Studio 0.3.39+</span></u>⁠<span>(opens in a new window)</span></a><span>, it defaults to </span><code><span>http://localhost:11434/v1/responses</span></code><span> running locally on your computer</span></li><li><span>Codex CLI can be used with the Responses API hosted by a cloud provider such as Azure</span></li></ul></div><p><span>Let’s explore how Codex creates the prompt for the first inference call in a conversation.</span></p><p><span>As an end user, you don’t specify the prompt used to sample the model verbatim when you query the Responses API. Instead, you specify various input types as part of your query, and the Responses API server decides how to structure this information into a prompt that the model is designed to consume. You can think of the prompt as a “list of items”; this section will explain how your query gets transformed into that list.</span></p><p><span>In the initial prompt, every item in the list is associated with a role. The </span><code><span>role</span></code><span> indicates how much weight the associated content should have and is one of the following values (in decreasing order of priority): </span><code><span>system</span></code><span>, </span><code><span>developer</span></code><span>, </span><code><span>user</span></code><span>, </span><code><span>assistant</span></code><span>.</span></p><div><ul><li><a href=\"https://platform.openai.com/docs/api-reference/responses/create#responses_create-instructions\" target=\"_blank\" referrerpolicy=\"no-referrer-when-downgrade\" rel=\"noopener noreferrer\"><code><u><span>instructions</span></u></code>⁠<span>(opens in a new window)</span></a><span>: system (or developer) message inserted into the model’s context</span></li><li><a href=\"https://platform.openai.com/docs/api-reference/responses/create#responses_create-tools\" target=\"_blank\" referrerpolicy=\"no-referrer-when-downgrade\" rel=\"noopener noreferrer\"><code><u><span>tools</span></u></code>⁠<span>(opens in a new window)</span></a><span>: a list of tools the model may call while generating a response</span></li><li><a href=\"https://platform.openai.com/docs/api-reference/responses/create#responses_create-input\" target=\"_blank\" referrerpolicy=\"no-referrer-when-downgrade\" rel=\"noopener noreferrer\"><code><u><span>input</span></u></code>⁠<span>(opens in a new window)</span></a><span>: a list of text, image, or file inputs to the model</span></li></ul></div><p><span>The </span><code><span>tools</span></code><span> field is a list of tool definitions that conform to a schema defined by the Responses API. For Codex, this includes tools that are provided by the Codex CLI, tools that are provided by the Responses API that should be made available to Codex, as well as tools provided by the user, usually via MCP servers:</span></p><p><span>1. A message with </span><code><span>role=developer</span></code><span> that describes the sandbox that </span><i><span>applies only to the Codex-provided </span></i><code><i><span>shell</span></i></code><i><span> tool</span></i><span> defined in the </span><code><span>tools</span></code><span> section. That is, other tools, such as those provided from MCP servers, are not sandboxed by Codex and are responsible for enforcing their own guardrails.</span></p><p><span>2. (Optional) A message with </span><code><span>role=developer</span></code><span> whose contents are the </span><code><span>developer_instructions</span></code><span> value read from the user’s </span><code><span>config.toml</span></code><span> file.</span></p><p><span>3. (Optional) A message with </span><code><span>role=user</span></code><span> whose contents are the “user instructions,” which are not sourced from a single file but are </span><a href=\"https://github.com/openai/codex/blob/99f47d6e9a3546c14c43af99c7a58fa6bd130548/codex-rs/core/src/project_doc.rs#L37-L42\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>aggregated across multiple sources</span></u>⁠<span>(opens in a new window)</span></a><span>. In general, more specific instructions appear later:</span></p><div><ul><li><span>Contents of </span><code><span>AGENTS.override.md</span></code><span> and </span><code><span>AGENTS.md</span></code><span> in </span><code><span>$CODEX_HOME</span></code></li><li><span>Subject to a limit (32 KiB, by default), look in each folder from the Git/project root of the </span><code><span>cwd</span></code><span> (if it it exists) up to the </span><code><span>cwd</span></code><span> itself: add the contents of any of </span><code><span>AGENTS.override.md</span></code><span>, </span><code><span>AGENTS.md</span></code><span>, or any filename specified by </span><code><span>project_doc_fallback_filenames in config.toml</span></code></li><li><span>If any </span><a href=\"https://developers.openai.com/codex/skills/\" target=\"_blank\" referrerpolicy=\"no-referrer-when-downgrade\" rel=\"noopener noreferrer\"><u><span>skills</span></u>⁠<span>(opens in a new window)</span></a><span> have been configured:</span></li></ul></div><p><span>Once Codex has done all of the above computation to initialize the </span><code><span>input</span></code><span>, it appends the user message to start the conversation.</span></p><p><span>The previous examples focused on the content of each message, but note that each element of </span><code><span>input</span></code><span> is a JSON object with </span><code><span>type</span></code><span>, </span><a href=\"https://www.reddit.com/r/OpenAI/comments/1hgxcgi/what_is_the_purpose_of_the_new_developer_role_in/\" target=\"_blank\" rel=\"noopener noreferrer\"><code><span>role</span></code>⁠<span>(opens in a new window)</span></a><span>, and </span><code><span>content</span></code><span> as follows:</span></p><p><span>Once Codex builds up the full JSON payload to send to the Responses API, it then makes the HTTP POST request with an </span><code><span>Authorization</span></code><span> header depending on how the Responses API endpoint is configured in </span><code><span>~/.codex/config.toml</span></code><span> (additional HTTP headers and query parameters are added if specified).</span></p><p><span>When an OpenAI Responses API server receives the request, it uses the JSON to derive the prompt for the model as follows (to be sure, a custom implementation of the Responses API could make a different choice):</span></p><p><span>As you can see, the order of the first three items in the prompt is determined by the server, not the client. That said, of those three items, only the content of the </span><i><span>system message</span></i><span> is also controlled by the server, as the </span><code><span>tools</span></code><span> and </span><code><span>instructions</span></code><span> are determined by the client. These are followed by the </span><code><span>input</span></code><span> from the JSON payload to complete the prompt.</span></p><p><span>Now that we have our prompt, we are ready to sample the model.</span></p><p><span>This HTTP request to the Responses API initiates the first “turn” of a conversation in Codex. The server replies with a Server-Sent Events (</span><a href=\"https://en.wikipedia.org/wiki/Server-sent_events\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>SSE</span></u>⁠<span>(opens in a new window)</span></a><span>) stream. The </span><code><span>data</span></code><span> of each event is a JSON payload with a </span><code><span>\"type\"</span></code><span> that starts with </span><code><span>\"response\"</span></code><span>, which could be something like this (a full list of events can be found in our </span><a href=\"https://platform.openai.com/docs/api-reference/responses-streaming\" target=\"_blank\" referrerpolicy=\"no-referrer-when-downgrade\" rel=\"noopener noreferrer\"><u><span>API docs</span></u>⁠<span>(opens in a new window)</span></a><span>):</span></p><p><span>Codex </span><a href=\"https://github.com/openai/codex/blob/2a68b74b9bf16b64e285495c1b149d7d6ac8bdf4/codex-rs/codex-api/src/sse/responses.rs#L334-L342\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>consumes the stream of events</span></u>⁠<span>(opens in a new window)</span></a><span> and republishes them as internal event objects that can be used by a client. Events like </span><code><span>response.output_text.delta</span></code><span> are used to support streaming in the UI, whereas other events like </span><code><span>response.output_item.added</span></code><span> are transformed into objects that are appended to the </span><code><span>input</span></code><span> for subsequent Responses API calls.</span></p><p><span>Suppose the first request to the Responses API includes two </span><code><span>response.output_item.done</span></code><span> events: one with </span><code><span>type=reasoning</span></code><span> and one with </span><code><span>type=function_call</span></code><span>. These events must be represented in the </span><code><span>input</span></code><span> field of the JSON when we query the model again with the response to the tool call:&nbsp;</span></p><p><span>The resulting prompt used to sample the model as part of the subsequent query would look like this:</span></p><p><span>In particular, note how the old prompt </span><i><span>is an exact prefix</span></i><span> of the new prompt. This is intentional, as this makes subsequent requests much more efficient because it enables us to take advantage of </span><i><span>prompt caching</span></i><span> (which we’ll discuss in the next section on performance).</span></p><p><span>Looking back at our first diagram of the agent loop, we see that there could be many iterations between inference and tool calling. The prompt may continue to grow until we finally receive an assistant message, indicating the end of the turn:</span></p><p><span>In the Codex CLI, we present the assistant message to the user and focus the composer to indicate to the user that it’s their “turn” to continue the conversation. If the user responds, both the assistant message from the previous turn, as well as the user’s new message, must be appended to the </span><code><span>input</span></code><span> in the Responses API request to start the new turn:</span></p><p><span>Once again, because we are continuing a conversation, the length of the </span><code><span>input</span></code><span> we send to the Responses API keeps increasing:</span></p><p><span>Let’s examine what this ever-growing prompt means for performance.</span></p><p><span>You might be asking yourself, “Wait, isn’t the agent loop </span><i><span>quadratic</span></i><span> in terms of the amount of JSON sent to the Responses API over the course of the conversation?” And you would be right. While the Responses API does support an optional </span><a href=\"https://platform.openai.com/docs/api-reference/responses/create#responses_create-previous_response_id\" target=\"_blank\" referrerpolicy=\"no-referrer-when-downgrade\" rel=\"noopener noreferrer\"><code><u><span>previous_response_id</span></u></code>⁠<span>(opens in a new window)</span></a><span> parameter to mitigate this issue, Codex does not use it today, primarily to keep requests fully stateless and to support Zero Data Retention (ZDR) configurations.</span></p><div><p>Avoiding <code>previous_response_id</code> simplifies things for the provider of the Responses API because it ensures that every request is <i>stateless</i>. This also makes it straightforward to support customers who have opted into <a href=\"https://platform.openai.com/docs/guides/migrate-to-responses#4-decide-when-to-use-statefulness\" target=\"_blank\" referrerpolicy=\"no-referrer-when-downgrade\" rel=\"noopener noreferrer\"><u>Zero Data Retention (ZDR)</u>⁠<span>(opens in a new window)</span></a>, as storing the data required to support <code>previous_response_id</code> would be at odds with ZDR. Note that ZDR customers do not sacrifice the ability to benefit from proprietary reasoning messages from prior turns, as the associated <code>encrypted_content</code> can be decrypted on the server. (OpenAI persists a ZDR customer’s decryption key, but not their data.) See PRs <a href=\"https://github.com/openai/codex/pull/642\" target=\"_blank\" rel=\"noopener noreferrer\"><u>#642</u>⁠<span>(opens in a new window)</span></a> and <a href=\"https://github.com/openai/codex/pull/1641\" target=\"_blank\" rel=\"noopener noreferrer\"><u>#1641</u>⁠<span>(opens in a new window)</span></a> for the related changes to Codex to support ZDR.</p></div><p><span>Generally, the cost of sampling the model dominates the cost of network traffic, making sampling the primary target of our efficiency efforts. This is why prompt caching is so important, as it enables us to reuse computation from a previous inference call. When we get cache hits, </span><i><span>sampling the model is linear rather than quadratic</span></i><span>. Our </span><a href=\"https://platform.openai.com/docs/guides/prompt-caching#structuring-prompts\" target=\"_blank\" referrerpolicy=\"no-referrer-when-downgrade\" rel=\"noopener noreferrer\"><u><span>prompt caching </span></u>⁠<span>(opens in a new window)</span></a><span>documentation explains this in more detail:</span></p><p><i><span>Cache hits are only possible for exact prefix matches within a prompt. To realize caching benefits, place static content like instructions and examples at the beginning of your prompt, and put variable content, such as user-specific information, at the end. This also applies to images and tools, which must be identical between requests.</span></i></p><p><span>With this in mind, let’s consider what types of operations could cause a “cache miss” in Codex:</span></p><div><ul><li><span>Changing the </span><code><span>tools</span></code><span> available to the model in the middle of the conversation.</span></li><li><span>Changing the </span><code><span>model</span></code><span> that is the target of the Responses API request (in practice, this changes the third item in the original prompt, as it contains model-specific instructions).</span></li><li><span>Changing the sandbox configuration, approval mode, or current working directory.</span></li></ul></div><p><span>The Codex team must be diligent when introducing new features in the Codex CLI that could compromise prompt caching. As an example, our initial support for MCP tools introduced a </span><a href=\"https://github.com/openai/codex/pull/2611\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>bug where we failed to enumerate the tools in a consistent order</span></u>⁠<span>(opens in a new window)</span></a><span>, causing cache misses. Note that MCP tools can be particularly tricky because MCP servers can change the list of tools they provide on the fly via a </span><a href=\"https://modelcontextprotocol.io/specification/2025-11-25/server/tools#list-changed-notification\" target=\"_blank\" rel=\"noopener noreferrer\"><code><u><span>notifications/tools/list_changed</span></u></code>⁠<span>(opens in a new window)</span></a><span> notification. Honoring this notification in the middle of a long conversation can cause an expensive cache miss.</span></p><p><span>When possible, we handle configuration changes that happen mid-conversation by appending a </span><i><span>new</span></i><span> message to </span><code><span>input</span></code><span> to reflect the change rather than modifying an earlier message:</span></p><div><ul><li><span>If the sandbox configuration or approval mode changes, we </span><a href=\"https://github.com/openai/codex/blob/99f47d6e9a3546c14c43af99c7a58fa6bd130548/codex-rs/core/src/codex.rs#L1037-L1057\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>insert</span></u>⁠<span>(opens in a new window)</span></a><span> a new </span><code><span>role=developer</span></code><span> message with the same format as the original </span><code><span>&lt;permissions instructions&gt;</span></code><span> item.</span></li><li><span>If the current working directory changes, we </span><a href=\"https://github.com/openai/codex/blob/99f47d6e9a3546c14c43af99c7a58fa6bd130548/codex-rs/core/src/codex.rs#L1017-L1035\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>insert</span></u>⁠<span>(opens in a new window)</span></a><span> a new </span><code><span>role=user</span></code><span> message with the same format as the original </span><code><span>&lt;environment_context&gt;</span></code><span>.</span></li></ul></div><p><span>We go to great lengths to ensure cache hits for performance. There’s another key resource we have to manage: the context window.</span></p><p><span>Our general strategy to avoid running out of context window is to </span><i><span>compact</span></i><span> the conversation once the number of tokens exceeds some threshold. Specifically, we replace the </span><code><span>input</span></code><span> with a new, smaller list of items that is representative of the conversation, enabling the agent to continue with an understanding of what has happened thus far. An early </span><a href=\"https://github.com/openai/codex/pull/1527\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>implementation of compaction</span></u>⁠<span>(opens in a new window)</span></a><span> required the user to manually invoke the </span><code><span>/compact</span></code><span> command, which would query the Responses API using the existing conversation plus custom instructions for </span><a href=\"https://github.com/openai/codex/blob/e2c994e32a31415e87070bef28ed698968d2e549/SUMMARY.md\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>summarization</span></u>⁠<span>(opens in a new window)</span></a><span>. Codex used the resulting assistant message containing the summary </span><a href=\"https://github.com/openai/codex/blob/e2c994e32a31415e87070bef28ed698968d2e549/codex-rs/core/src/codex.rs#L1424\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>as the new </span></u><code><u><span>input</span></u></code>⁠<span>(opens in a new window)</span></a><span> for subsequent conversation turns.</span></p><p><span>Since then, the Responses API has evolved to support a special </span><a href=\"https://platform.openai.com/docs/guides/conversation-state#compaction-advanced\" target=\"_blank\" referrerpolicy=\"no-referrer-when-downgrade\" rel=\"noopener noreferrer\"><code><u><span>/responses/compact</span></u></code><u><span> endpoint</span></u>⁠<span>(opens in a new window)</span></a><span> that performs compaction more efficiently. It returns </span><a href=\"https://platform.openai.com/docs/api-reference/responses/compacted-object\" target=\"_blank\" referrerpolicy=\"no-referrer-when-downgrade\" rel=\"noopener noreferrer\"><u><span>a list of items</span></u>⁠<span>(opens in a new window)</span></a><span> that can be used in place of the previous </span><code><span>input</span></code><span> to continue the conversation while freeing up the context window. This list includes a special </span><code><span>type=compaction</span></code><span> item with an opaque </span><code><span>encrypted_content</span></code><span> item that preserves the model’s latent understanding of the original conversation. Now, Codex automatically uses this endpoint to compact the conversation when the </span><a href=\"https://github.com/openai/codex/blob/99f47d6e9a3546c14c43af99c7a58fa6bd130548/codex-rs/core/src/codex.rs#L2558-L2560\" target=\"_blank\" rel=\"noopener noreferrer\"><code><u><span>auto_compact_limit</span></u></code>⁠<span>(opens in a new window)</span></a><span> is exceeded.</span></p><div id=\"coming-next\"><p></p><h2><span>Coming next</span></h2><p></p></div><p><span>We’ve introduced the Codex agent loop and walked through how Codex crafts and manages its context when querying a model. Along the way, we highlighted practical considerations and best practices that apply to anyone building an agent loop on top of the Responses API.</span></p><p><span>While the agent loop provides the foundation for Codex, it’s only the beginning. In upcoming posts, we’ll dig into the CLI’s architecture, explore how tool use is implemented, and take a closer look at Codex’s sandboxing model.</span></p></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/5SVla4Q1Mj9zfLIRRvNBn4/00511d9c01c2bfe3bbe763b8eae1fd85/oai_Unrolling_the_Codex_agent_loop_SEO.png?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/index/scaling-postgresql",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/scaling-postgresql",
    "title": "Scaling PostgreSQL to power 800 million ChatGPT users",
    "publishedAt": "Thu, 22 Jan 2026 12:00:00 GMT",
    "fetchedAt": "2026-01-25T19:08:00.618Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div><p><span>For years, PostgreSQL has been one of the most critical, under-the-hood data systems powering core products like ChatGPT and OpenAI’s API. As our user base grows rapidly, the demands on our databases have increased exponentially, too. Over the past year, our PostgreSQL load has grown by more than 10x, and it continues to rise quickly.</span></p><p><span>Our efforts to advance our production infrastructure to sustain this growth revealed a new insight: PostgreSQL can be scaled to reliably support much larger read-heavy workloads than many previously thought possible. The system (initially created by a team of scientists at University of California, Berkeley) has enabled us to support massive global traffic with a single primary </span><a href=\"https://learn.microsoft.com/en-us/azure/postgresql/overview\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>Azure PostgreSQL flexible server instance</span></u>⁠<span>(opens in a new window)</span></a><span> and nearly 50 read replicas spread over multiple regions globally. This is the story of how we’ve scaled PostgreSQL at OpenAI to support millions of queries per second for 800 million users through rigorous optimizations and solid engineering; we’ll also cover key takeaways we learned along the way.</span></p><div id=\"cracks-in-our-initial-design\"><p></p><h2><span>Cracks in our initial design</span></h2><p></p></div><p><span>After the launch of ChatGPT, traffic grew at an unprecedented rate. To support it, we rapidly implemented extensive optimizations at both the application and PostgreSQL database layers, scaled up by increasing the instance size, and scaled out by adding more read replicas. This architecture has served us well for a long time. With ongoing improvements, it continues to provide ample runway for future growth.</span></p><p><span>It may sound surprising that a single-primary architecture can meet the demands of OpenAI’s scale; however, making this work in practice isn’t simple. We’ve seen several SEVs caused by Postgres overload, and they often follow the same pattern: an upstream issue causes a sudden spike in database load, such as widespread cache misses from a caching-layer failure, a surge of expensive multi-way joins saturating CPU, or a write storm from a new feature launch. As resource utilization climbs, query latency rises and requests begin to time out. Retries then further amplify the load, triggering a vicious cycle with the potential to degrade the entire ChatGPT and API services.</span></p><p><span>Although PostgreSQL scales well for our read-heavy workloads, we still encounter challenges during periods of high write traffic. This is largely due to PostgreSQL’s multiversion concurrency control (MVCC) implementation, which makes it less efficient for write-heavy workloads. For example, when a query updates a tuple or even a single field, the entire row is copied to create a new version. Under heavy write loads, this results in significant write amplification. It also increases read amplification, since queries must scan through multiple tuple versions (dead tuples) to retrieve the latest one. MVCC introduces additional challenges such as table and index bloat, increased index maintenance overhead, and complex autovacuum tuning. (You can find a deep-dive on these issues in a blog I wrote with Prof. Andy Pavlo at Carnegie Mellon University called </span><a href=\"https://www.cs.cmu.edu/~pavlo/blog/2023/04/the-part-of-postgresql-we-hate-the-most.html\" target=\"_blank\" rel=\"noopener noreferrer\"><i><u><span>The Part of PostgreSQL We Hate the Most</span></u></i>⁠<span>(opens in a new window)</span></a><span>, </span><a href=\"https://en.wikipedia.org/wiki/PostgreSQL#cite_note-37\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>cited</span></u>⁠<span>(opens in a new window)</span></a><span> in the PostgreSQL Wikipedia page.)</span></p><div id=\"scaling-postgresql-to-millions-of-qps\"><p></p><h2><span>Scaling PostgreSQL to millions of QPS</span></h2><p></p></div><p><span>To mitigate these limitations and reduce write pressure, we’ve migrated, and continue to migrate, shardable (i.e. workloads that can be horizontally partitioned), write-heavy workloads to sharded systems such as Azure Cosmos DB, optimizing application logic to minimize unnecessary writes. We also no longer allow adding new tables to the current PostgreSQL deployment. New workloads default to the sharded systems.</span></p><p><span>Even as our infrastructure has evolved, PostgreSQL has remained unsharded, with a single primary instance serving all writes. The primary rationale is that sharding existing application workloads would be highly complex and time-consuming, requiring changes to hundreds of application endpoints and potentially taking months or even years. Since our workloads are primarily read-heavy, and we’ve implemented extensive optimizations, the current architecture still provides ample headroom to support continued traffic growth. While we’re not ruling out sharding PostgreSQL in the future, it’s not a near-term priority given the sufficient runway we have for current and future growth.</span></p><p><span>In the following sections, we’ll dive into the challenges we faced and the extensive optimizations we implemented to address them and prevent future outages, pushing PostgreSQL to its limits and scaling it to millions of queries per second (QPS).</span></p><p><i><span>Challenge: With only one writer, a single-primary setup can’t scale writes. Heavy write spikes can quickly overload the primary and impact services like ChatGPT and our API.</span></i></p><p><span>Solution: We minimize load on the primary as much as possible—both reads and writes—to ensure it has sufficient capacity to handle write spikes. Read traffic is offloaded to replicas wherever possible. However, some read queries must remain on the primary because they’re part of write transactions. For those, we focus on ensuring they’re efficient and avoid slow queries. For write traffic, we’ve migrated shardable, write-heavy workloads to sharded systems such as Azure CosmosDB. Workloads that are harder to shard but still generate high write volume take longer to migrate, and that process is still ongoing. We also aggressively optimized our applications to reduce write load; for example, we’ve fixed application bugs that caused redundant writes and introduced lazy writes, where appropriate, to smooth traffic spikes. In addition, when backfilling table fields, we enforce strict rate limits to prevent excessive write pressure.</span></p><p><i><span>Challenge: We identified several expensive queries in PostgreSQL. In the past, sudden volume spikes in these queries would consume large amounts of CPU, slowing both ChatGPT and API requests.</span></i></p><p><span>Solution: A few expensive queries, such as those joining many tables together, can significantly degrade or even bring down the entire service. We need to continuously optimize PostgreSQL queries to ensure they’re efficient and avoid common Online Transaction Processing (OLTP) anti-patterns. For example, we once identified an extremely costly query that joined 12 tables, where spikes in this query were responsible for past high-severity SEVs. We should avoid complex multi-table joins whenever possible. If joins are necessary, we learned to consider breaking down the query and move complex join logic to the application layer instead. Many of these problematic queries are generated by Object-Relational Mapping frameworks (ORMs), so it’s important to carefully review the SQL they produce and ensure it behaves as expected. It’s also common to find long-running idle queries in PostgreSQL. Configuring timeouts like idle_in_transaction_session_timeout is essential to prevent them from blocking autovacuum.</span></p><p><i><span>Challenge: If a read replica goes down, traffic can still be routed to other replicas. However, relying on a single writer means having a single point of failure—if it goes down, the entire service is affected.</span></i></p><p><span>Solution: Most critical requests only involve read queries. To mitigate the single point of failure in the primary, we offloaded those reads from the writer to replicas, ensuring those requests can continue serving even if the primary goes down. While write operations would still fail, the impact is reduced; it’s no longer a SEV0 since reads remain available.</span></p><p><span>To mitigate primary failures, we run the primary in High-Availability (HA) mode with a hot standby, a continuously synchronized replica that is always ready to take over serving traffic. If the primary goes down or needs to be taken offline for maintenance, we can quickly promote the standby to minimize downtime. The Azure PostgreSQL team has done significant work to ensure these failovers remain safe and reliable even under very high load. To handle read replica failures, we deploy multiple replicas in each region with sufficient capacity headroom, ensuring that a single replica failure doesn’t lead to a regional outage.</span></p><p><i><span>Challenge: We often encounter situations where certain requests consume a disproportionate amount of resources on PostgreSQL instances. This can lead to degraded performance for other workloads running on the same instances. For example, a new feature launch can introduce inefficient queries that heavily consume PostgreSQL CPU, slowing down requests for other critical features.</span></i></p><p><span>Solution: To mitigate the “noisy neighbor” problem, we isolate workloads onto dedicated instances to ensure that sudden spikes in resource-intensive requests don’t impact other traffic. Specifically, we split requests into low-priority and high-priority tiers and route them to separate instances. This way, even if a low-priority workload becomes resource-intensive, it won’t degrade the performance of high-priority requests. We apply the same strategy across different products and services as well, so that activity from one product does not affect the performance or reliability of another.</span></p><p><i><span>Challenge: Each instance has a maximum connection limit (5,000 in Azure PostgreSQL). It’s easy to run out of connections or accumulate too many idle ones. We’ve previously had incidents caused by connection storms that exhausted all available connections.</span></i></p><p><span>Solution: We deployed PgBouncer as a proxy layer to pool database connections. Running it in statement or transaction pooling mode allows us to efficiently reuse connections, greatly reducing the number of active client connections. This also cuts connection setup latency: in our benchmarks, the average connection time dropped from 50 milliseconds (ms) to 5 ms. Inter-region connections and requests can be expensive, so we co-locate the proxy, clients, and replicas in the same region to minimize network overhead and connection use time. Moreover, PgBouncer must be configured carefully. Settings like idle timeouts are critical to prevent connection exhaustion.</span></p><p><i><span>Challenge: A sudden spike in cache misses can trigger a surge of reads on the PostgreSQL database, saturating CPU and slowing user requests.</span></i></p><p><span>Solution: To reduce read pressure on PostgreSQL, we use a caching layer to serve most of the read traffic. However, when cache hit rates drop unexpectedly, the burst of cache misses can push a large volume of requests directly to PostgreSQL. This sudden increase in database reads consumes significant resources, slowing down the service. To prevent overload during cache-miss storms, we implement a cache locking (and leasing) mechanism so that only a single reader that misses on a particular key fetches the data from PostgreSQL. When multiple requests miss on the same cache key, only one request acquires the lock and proceeds to retrieve the data and repopulate the cache. All other requests wait for the cache to be updated rather than all hitting PostgreSQL at once. This significantly reduces redundant database reads and protects the system from cascading load spikes.</span></p><p><i><span>Challenge: The primary streams Write Ahead Log (WAL) data to every read replica. As the number of replicas increases, the primary must ship WAL to more instances, increasing pressure on both network bandwidth and CPU. This causes higher and more unstable replica lag, which makes the system harder to scale reliably.</span></i></p><p><span>Solution: We operate nearly 50 read replicas across multiple geographic regions to minimize latency. However, with the current architecture, the primary must stream WAL to every replica. Although it currently scales well with very large instance types and high-network bandwidth, we can’t keep adding replicas indefinitely without eventually overloading the primary. To address this, we’re collaborating with the Azure PostgreSQL team on </span><a href=\"https://www.postgresql.org/docs/current/warm-standby.html#CASCADING-REPLICATION\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>cascading replication</span></u>⁠<span>(opens in a new window)</span></a><span>, where intermediate replicas relay WAL to downstream replicas. This approach allows us to scale to potentially over a hundred replicas without overwhelming the primary. However, it also introduces additional operational complexity, particularly around failover management. The feature is still in testing; we’ll ensure it’s robust and can fail over safely before rolling it out to production.</span></p><p><i><span>Challenge: A sudden traffic spike on specific endpoints, a surge of expensive queries, or a retry storm can quickly exhaust critical resources such as CPU, I/O, and connections, which causes widespread service degradation.</span></i></p><p><span>Solution: We implemented rate-limiting across multiple layers—application, connection pooler, proxy, and query—to prevent sudden traffic spikes from overwhelming database instances and triggering cascading failures. It’s also crucial to avoid overly short retry intervals, which can trigger retry storms. We also enhanced the ORM layer to support rate limiting and when necessary, fully block specific query digests. This targeted form of load shedding enables rapid recovery from sudden surges of expensive queries.</span></p><p><i><span>Challenge: Even a small schema change, such as altering a column type, can trigger </span></i><a href=\"https://www.crunchydata.com/blog/when-does-alter-table-require-a-rewrite\" target=\"_blank\" rel=\"noopener noreferrer\"><i><u><span>a full table rewrite</span></u></i>⁠<span>(opens in a new window)</span></a><i><span>. We therefore apply schema changes cautiously—limiting them to lightweight operations and avoiding any that rewrite entire tables.</span></i></p><p><span>Solution: Only lightweight schema changes are permitted, such as adding or removing certain columns that do not trigger a full table rewrite. We enforce a strict 5-second timeout on schema changes. Creating and dropping indexes concurrently is allowed. Schema changes are restricted to existing tables. If a new feature requires additional tables, they must be in alternative sharded systems such as Azure CosmosDB rather than PostgreSQL. When backfilling a table field, we apply strict rate limits to prevent write spikes. Although this process can sometimes take over a week, it ensures stability and avoids any production impact.</span></p><div id=\"results-and-the-road-ahead\"><p></p><h2><span>Results and the road ahead</span></h2><p></p></div><p><span>This effort demonstrates that with the right design and optimizations, Azure PostgreSQL can be scaled to handle the largest production workloads. PostgreSQL handles millions of QPS for read-heavy workloads, powering OpenAI’s most critical products like ChatGPT and the API platform. We added nearly 50 read replicas, while keeping replication lag near zero, maintained low-latency reads across geo-distributed regions, and built sufficient capacity headroom to support future growth.</span></p><p><span>This scaling works while still minimizing latency and improving reliability. We consistently deliver low double-digit millisecond p99 client-side latency and five-nines availability in production. And over the past 12 months, we’ve had only one SEV-0 PostgreSQL incident (it occurred during the </span><a href=\"https://newsletter.pragmaticengineer.com/p/chatgpt-images\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>viral launch</span></u>⁠<span>(opens in a new window)</span></a><span> of ChatGPT ImageGen, when write traffic suddenly surged by more than 10x as over 100 million new users signed up within a week.)</span></p><p><span>While we’re happy with how far PostgreSQL has taken us, we continue to push its limits to ensure we have sufficient runway for future growth. We’ve already migrated the shardable write-heavy workloads to our sharded systems like CosmosDB. The remaining write-heavy workloads are more challenging to shard—we’re actively migrating those as well to further offload writes from the PostgreSQL primary. We’re also working with Azure to enable cascading replication so we can safely scale to significantly more read replicas.</span></p><p><span>Looking ahead, we’ll continue to explore additional approaches to further scale, including sharded PostgreSQL or alternative distributed systems, as our infrastructure demands continue to grow.</span></p></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/1jMkEyUx0I5dBOoXhBrDcC/da4be6739c5bc7596245833cd2bf6d4c/oai-scaling-postgresql-to-power-800-million-chatgpt-users-seo-16x9.png?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/index/praktika",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/praktika",
    "title": "Inside Praktika's conversational approach to language learning",
    "publishedAt": "Thu, 22 Jan 2026 05:00:00 GMT",
    "fetchedAt": "2026-01-25T19:08:02.639Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div><p><span>Praktika was born from a deeply personal insight: language unlocks opportunity.&nbsp;</span></p><p><span>Co-founders Adam Turaev, Anton Marin, and Ilya Chernyakov all grew up navigating new countries after their families immigrated in search of better opportunities. English quickly became essential, not just for school, but for work, mobility, and belonging.</span></p><p><span>“Learning English was never just about communication,” Turaev said. “It opened doors to international work and career growth.”&nbsp;</span></p><p><span>But traditional language education fell short. Despite years of study, the founders found that while they could read and write fluently, they struggled to speak confidently when it mattered most: at work, in meetings, and in daily life. The gap between classroom learning and real-world fluency was wider than they’d imagined.</span></p><p><a href=\"https://praktika.ai/\" target=\"_blank\" rel=\"noopener noreferrer\"><span>Praktika</span>⁠<span>(opens in a new window)</span></a><span> was built to close that gap. It’s a language learning app designed to help people build real-world fluency through daily conversations, with personalized AI tutors who guide them through interactive, goal-based lessons. Users include students preparing for exams, professionals working on job-related language skills, and immigrants building new lives in foreign countries.&nbsp;</span></p><div id=\"building-a-multi-agent-tutoring-system-that-adapts-and-improvises\"><p></p><h2><span>Building a multi-agent tutoring system that adapts and improvises&nbsp;</span></h2><p></p></div><p><span>As the product matured, Praktika moved beyond a single-model architecture into a multi-agent system designed to mirror how real tutors adapt lessons in real time.&nbsp;</span></p><p><b><span>Lesson Agent </span></b><span>is the primary conversation agent, interacting with learners as the tutor. Running on GPT‑5.2, it blends tutor personality, lesson context, learner goals, and recent conversations to deliver lessons that feel natural and unscripted. This is the point where the system starts to feel like a real tutor rather than a scripted experience.</span></p><p><span>Running continuously in the background, </span><b><span>Student Progress Agent</span></b><span> tracks the learner’s language performance across interactions. Using GPT‑5.2, this agent monitors fluency, accuracy, vocabulary usage, and recurring mistakes. This data forms a continuous feedback loop that informs both the Lesson Agent’s in-session behavior and the longer-term learning strategy, allowing the experience to evolve naturally over time.</span></p><p><b><span>Learning Planning Agent </span></b><span>focuses on shaping the learner’s long-term progression. Grounded in the learner’s individual learning goal, it uses insights from the Student Progress Agent to determine what to learn next, how to sequence skills, and which activities will be most effective. Powered by GPT‑5 Pro, its role is to continuously adapt the learning plan so progress remains personalized, efficient, and aligned with the learner’s desired outcome.</span></p><p><span>All agents share access to a persistent memory layer that stores learner goals, preferences, and past mistakes. Rather than preloading context, Praktika retrieves memory immediately after the learner speaks, ensuring responses are grounded in the most relevant, up-to-date signal.</span></p><p><span>“The system can switch to a completely different exercise if the learner isn’t feeling it,” says Turaev. “That brings the magic back. It starts to feel much closer to a real human tutor.”</span></p><div id=\"making-ai-conversations-feel-like-a-live-exchange\"><p></p><h2><span>Making AI conversations feel like a live exchange&nbsp;</span></h2><p></p></div><p><span>For conversational learning to feel natural, memory has to work the way it does in real life. Praktika’s memory layer retrieves relevant context only </span><i><span>after</span></i><span> the learner finishes speaking. That allows the tutor to respond to what was just said, not what it anticipated.</span></p><p><span>“If a learner makes a mistake right now, the tutor responds to </span><i><span>that mistake</span></i><span>, not one from yesterday,” says co-founder and CEO Adam Turaev. “That timing difference is subtle, but it’s what makes the interaction feel attentive instead of robotic.”</span></p><p><span>Speech recognition plays a similar role. Language learners hesitate, restart sentences, and pronounce words imperfectly. Praktika uses Transcription API to handle fragmented, accented, and non-native speech more reliably than traditional systems trained on fluent speech. That lets learners focus on communicating without being penalized for their beginner status.</span></p><p><span>Together, memory timing and speech recognition form a single loop: listen carefully, recall the right context, and respond immediately.</span></p><div id=\"turning-model-improvements-into-more-effective-learning-experiences\"><p></p><h2><span>Turning model improvements into more effective learning experiences</span></h2><p></p></div><p><span>Early versions of Praktika’s product paired expressive avatars with rule-based NLP and the first davinci models, but conversations still felt constrained. With the release of </span><b><span>GPT‑3.5</span></b><span>, the team experienced its first major breakthrough.</span></p><p><span>“For the first time, we could merge advanced language understanding with expressive, lifelike avatars,” says Adam Turaev. “The conversations stopped feeling scripted. They became natural, emotional, and real.”&nbsp;</span></p><p><span>As Praktika evaluated newer models, GPT‑4.1 proved to be the strongest fit across its internal evaluations measuring onboarding completion, Day-1 retention, trial-to-paid conversion, and qualitative user feedback.</span></p><p><span>“GPT‑4.1 gave us the best balance of reasoning depth, emotional nuance, and reliability,” says Turaev. “It supported multi-language conversation and complex tutoring logic at the quality we needed, significantly increasing conversation session quality.”</span></p><p><span>Those improvements translated directly into user and business results. After introducing their new long-term memory system, Praktika saw a 24% increase in Day-1 retention and doubled revenue in just a few months.</span></p><p><span>More recently, Praktika began using GPT‑5.2 models to power its architecture. GPT‑5.2 now powers the primary conversation agent, while GPT‑5.2 Pro handles supervisory reasoning and GPT‑5 mini supports continuous progress tracking. Together, these models allow the system to reason in parallel, balancing conversation quality, pedagogy, and efficiency at scale.</span></p><div id=\"exploring-new-ways-to-learn-a-language\"><p></p><h2><span>Exploring new ways to learn a language</span></h2><p></p></div><p><span>Today, Praktika supports millions of learners across nine languages, with more on the way. With its agentic foundation in place, Praktika is now focused on expanding what an AI tutor can understand, remember, and create alongside each learner.</span></p><p><span>“We’re not just teaching languages,” says Turaev. “We’re building AI that helps people feel confident using them in the real world.”</span></p></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/XQ72eFI92VMLB1oZUApnM/f3ad7268337db9b0c2ebc1dfe5d71cd4/oai_Praktika_SEO.png?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/business/guides-and-resources/chatgpt-usage-and-adoption-patterns-at-work",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/business/guides-and-resources/chatgpt-usage-and-adoption-patterns-at-work",
    "title": "Inside GPT-5 for Work: How Businesses Use GPT-5",
    "publishedAt": "Thu, 22 Jan 2026 00:00:00 GMT",
    "fetchedAt": "2026-01-25T19:08:02.938Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div><div id=\"introduction\"><p></p><h2><span>Introduction</span></h2><p></p></div><p><span>Launched just two and a half years ago, ChatGPT is used by workers across every industry, in every job function, and at companies of every size. Today, over a quarter of U.S. workers—and 45% of those with postgraduate degrees—report using ChatGPT for work. </span></p><p><span>Enterprise tech has always followed a familiar pattern: big upfront costs, long rollouts, and slow adoption before the payoff. ChatGPT broke that mold when people ported it from their personal lives into their jobs. They didn’t need months of training or complicated onboarding; they just started using it to get meaningful work done. </span></p><p><span>Already, we see clear signals. Everyone from scientists to marketers to operators is folding ChatGPT into everyday work. From debugging code to brainstorming campaigns, it’s becoming the first step in core workflows.  </span></p><p><span>This report shares new data from our own analysis, combined with peer-reviewed sources, about who’s using ChatGPT at work, how people are putting it to use, and the ways it’s taking root inside organizations.</span></p><div id=\"methodology\"><p></p><h2><span>Methodology</span></h2><p></p></div><p><span>This report combines findings from independent third party industry-wide studies with analysis done by OpenAI on usage of ChatGPT and ChatGPT Enterprise. All analyses done by OpenAI in this report were performed on anonymized or aggregated usage data. OpenAI did not review any user or customer content (including model input or output), and did not analyze any identifiable data. All analysis of usage trends was conducted using automated content classifiers. Where the report references specific ChatGPT prompts, those ChatGPT prompts are fully synthetic examples, and not actual user or customer prompts.</span></p><div id=\"the-rise-of-ai-at-work\"><p></p><h2><span>The rise of AI at work</span></h2><p></p></div><p><span>When ChatGPT was released in November 2022, it mostly targeted a small group of AI researchers and enthusiasts. But within months, it had 100 million weekly active users, and today has over 700 million weekly active users, making it one of the world’s most visited websites.&nbsp;</span></p><p><span>Widespread personal use rapidly spread to the workplace. As the statistics show, consumer adoption is very likely advancing AI at work.&nbsp;</span></p><p><span>This is a path we've often seen before: software that gains traction with consumers makes its way into the workplace, often driven most heavily by younger employees. ChatGPT is following that same pattern, reflected in its rapid growth in weekly active users, high penetration with workers under 30, and frequent-often daily-use.</span></p><p><span>In just a few years, AI in the workplace has gone from niche to mainstream. The numbers tell the story:</span></p><div><div><div><h5>Adoption is skyrocketing...</h5><p>Today, 43% of U.S. knowledge workers use AI (Stanford), up from fewer than 1 in 10 in late 2022.</p></div><div><h5>...and ChatGPT leads the shift.</h5><p>Pew reports 28% of employed adults are using ChatGPT at work, up from only 8% two years ago. </p></div></div><div><div><h5>AI use is becoming habitual...</h5><p>More than half of workplace AI users engage four or more days a week. In the last year, daily usage has doubled (Stanford).</p></div><div><h5>...and the benefits are real.</h5><p>A Federal Reserve Bank of St. Louis study found over half of AI users save 3+ hours per week, and a Harvard study found knowledge workers using AI produced 40% higher quality work.</p></div></div><div><div><h5>Usage correlates with education...</h5><p>More than half of workplace AI users engage four or more days a week. In the last year, daily usage has doubled (Stanford).</p></div><div><h5>...and skews younger.</h5><p>Employees 18-29 are more than twice as likely to use ChatGPT at work as those over 50.&nbsp;</p></div></div></div><div id=\"who-uses-chatgpt-in-the-enterprise\"><p></p><h2><span>Who uses ChatGPT in the enterprise</span></h2><p></p></div><p><span>AI adoption isn’t unfolding evenly across the economy. Workers in some industries have moved quickly to embed ChatGPT into their operations, while others are proceeding more slowly.   By looking at which sectors are embracing the tool fastest, we can see both the near-term opportunities and the areas where adoption may take longer to gain traction.&nbsp;</span></p><div><p><span>Source: ChatGPT Free, Plus, and Pro users in the US with a professional email address; email domains mapped to industry</span></p></div><p><span>Certain industries are adopting ChatGPT at higher-than-expected rates. IT and finance lead the way, which makes sense given the tool’s strengths in coding, analysis, and information-heavy work. Manufacturing adoption points to a broader digital transformation: factories using AI for process automation, predictive maintenance, and supply chain optimization. Early investments in industrial AI may be paving the way for widespread ChatGPT use among engineers, analysts, and operations managers.</span></p><p><span>Other industries lag behind. Retail, construction, transportation, wholesale trade, and agriculture all show significantly lower adoption. In most cases, this tracks with their smaller share of knowledge workers, where the need for AI tools is less immediate.&nbsp;&nbsp;</span></p><p><span>Healthcare is a special case. Despite being one of the largest and most data-intensive sectors, adoption has been slower. Strict privacy and compliance rules and risk-averse organizational cultures may be factors. Still, we’re starting to see growth in targeted areas like clinical documentation and administrative workflows, suggesting healthcare could soon become a hotbed of AI adoption.</span></p><div><p><img alt=\"Abstract, grainy gradient image with no distinct objects. Soft pastel colors blend horizontally, transitioning from pale lavender and light pink at the top to brighter pinks and purples in the middle, and fading into deeper blue and dark gray tones near the bottom, evoking a hazy sunset or atmospheric horizon.\" data-nosnippet=\"true\" loading=\"lazy\" width=\"1208\" height=\"967\" decoding=\"async\" data-nimg=\"1\" sizes=\"(min-width: 1728px) 1728px, 100vw\" srcset=\"https://images.ctfassets.net/kftzwdyauwt9/4jw7O0DGxOqj9YcSfayg0V/60e61393888e00784b65ecfd3c020f52/Gradient_Media.png?w=640&amp;q=90&amp;fm=webp 640w, https://images.ctfassets.net/kftzwdyauwt9/4jw7O0DGxOqj9YcSfayg0V/60e61393888e00784b65ecfd3c020f52/Gradient_Media.png?w=750&amp;q=90&amp;fm=webp 750w, https://images.ctfassets.net/kftzwdyauwt9/4jw7O0DGxOqj9YcSfayg0V/60e61393888e00784b65ecfd3c020f52/Gradient_Media.png?w=828&amp;q=90&amp;fm=webp 828w, https://images.ctfassets.net/kftzwdyauwt9/4jw7O0DGxOqj9YcSfayg0V/60e61393888e00784b65ecfd3c020f52/Gradient_Media.png?w=1080&amp;q=90&amp;fm=webp 1080w, https://images.ctfassets.net/kftzwdyauwt9/4jw7O0DGxOqj9YcSfayg0V/60e61393888e00784b65ecfd3c020f52/Gradient_Media.png?w=1200&amp;q=90&amp;fm=webp 1200w, https://images.ctfassets.net/kftzwdyauwt9/4jw7O0DGxOqj9YcSfayg0V/60e61393888e00784b65ecfd3c020f52/Gradient_Media.png?w=1920&amp;q=90&amp;fm=webp 1920w, https://images.ctfassets.net/kftzwdyauwt9/4jw7O0DGxOqj9YcSfayg0V/60e61393888e00784b65ecfd3c020f52/Gradient_Media.png?w=2048&amp;q=90&amp;fm=webp 2048w, https://images.ctfassets.net/kftzwdyauwt9/4jw7O0DGxOqj9YcSfayg0V/60e61393888e00784b65ecfd3c020f52/Gradient_Media.png?w=3840&amp;q=90&amp;fm=webp 3840w\" src=\"https://images.ctfassets.net/kftzwdyauwt9/4jw7O0DGxOqj9YcSfayg0V/60e61393888e00784b65ecfd3c020f52/Gradient_Media.png?w=3840&amp;q=90&amp;fm=webp\" style=\"max-width: 100%; height: auto; border-radius: 1rem; margin: 2rem 0px;\"></p></div><p><span>Adoption patterns vary across departments, but a few themes stand out. In the first three months, four categories dominate usage: writing, research, programming, and analysis. Together, they account for the majority of messages sent. This variety highlights the flexibility of ChatGPT; teams turn to it to draft communications, gather and synthesize information, write code, and interpret data.</span></p><p><span>Technical teams are among the heaviest users, with analytics, engineering, and IT roles making up a large percentage of early usage. Programming is the top task, especially for engineering roles, but users also request a substantial amount of research and documentation help. This suggests ChatGPT is being used nearly as much for planning as for coding.&nbsp;</span></p><p><span>IT teams lean most heavily on research and troubleshooting, often using ChatGPT as an information resource before moving into automation.</span></p><div><div><h4>Analytics</h4><ol><li><p>1</p>Coding</li><li><p>2</p>Writing</li><li><p>3</p>Research</li></ol></div><div><h4>Engineering</h4><ol><li><p>1</p>Coding</li><li><p>2</p>Research</li><li><p>3</p>Writing</li></ol></div><div><h4>IT</h4><ol><li><p>1</p>Coding</li><li><p>2</p>Research</li><li><p>3</p>Writing</li></ol></div></div><p><span>Example prompt for coding</span></p><p><i><span>Note: the above synthetic prompt is an example written specifically for this report solely for illustrative purposes</span></i></p><p><span>People in go-to-market roles, including marketing, communications, sales, and customer experience, are also major adopters. These functions rely on ChatGPT primarily for writing, research, creative ideation, and media generation.&nbsp;</span></p><p><span>Across functions, the early usage pattern is consistent: AI is augmenting expertise, not replacing it. Engineers are iterating on prompts to debug code and generate unit tests. Analysts are using chain-of-thought prompting to clean and interpret datasets. Customer support teams are drafting thoughtful, brand-aligned responses. The common thread is that ChatGPT is extending the reach of specialized skills and becoming a partner in core workflows.</span></p><p><i><span>Source: Aggregated ChatGPT Enterprise department data collected during onboarding; automated<br>content classifiers</span></i></p><p><span>Interestingly, coding is spreading beyond engineering. Designers may be leaning on programming for front-end prototyping and snippet help-and they use ChatGPT for coding at a much higher rate than finance and sales. Project managers combine writing, media generation, coding, and data analysis—acting as the glue across teams. But product, operations, marketing, finance, and HR all use ChatGPT for coding to some extent.&nbsp;</span></p><p><span>We see this trend validated in a study done by Boston University and BCG, which examined the impact of ChatGPT on the technical competency of BCG consultants. The study found that consultants armed with and trained on ChatGPT score 49, 20, and 18 percentage points higher than those in the control group on the three technical tasks, and performed close to the level of real BCG data scientists on two of the three tasks.</span></p><p><span>Good writing is no longer a specialist function reserved for content teams. With ChatGPT, anyone can turn notes into clean copy and iterate quickly. Meetings, memos, and customer messages become clearer and more inclusive because everyone can express their ideas well, not just trained communicators. AI is becoming the front door for routine communication and coordination, compressing drafting, tone calibration, and versioning into a single pass.</span></p><p><span>Design teams stand out for their use of media generation, relying on it 2–4x more than other groups. The heavy use in these functions for core work tasks highlights an emerging role for ChatGPT beyond text.&nbsp;</span></p><div><ol><li><p>Writing</p></li><li><p>Research</p></li><li><p>Media generation</p></li></ol></div><p><span>All go-to-market teams use ChatGPT most for writing, research and media generation tasks, but in different ways. Here are some sample prompts indicating the type of queries we're seeing:</span></p><p><i><span>Note: the above synthetic prompts are examples written specifically for this report solely for illustrative purposes</span></i></p><div id=\"roles-shape-usage-patterns\"><p></p><h2><span>Roles shape usage patterns</span></h2><p></p></div><p><span>Early data shows a consistent trend: most departments rely on the core tools in ChatGPT, including search, data analysis, file uploads, retrieval, and canvas. Adoption of more advanced features—such as reasoning models, deep research, projects, and custom instructions—are higher among power users, including R&amp;D teams.&nbsp;The result for many employees is that ChatGPT is woven into daily workflows mainly through accessible, low-friction tasks rather than specialized use cases. </span></p><p><span>Technical functions stand out as the exception. Analytics, engineering, IT, and research roles are much heavier users of advanced capabilities. Their work often demands multi-step reasoning, large-scale data synthesis, or complex problem-solving. Engineers prompt for code generation or debugging; analysts use deep research to interpret datasets; and IT professionals query knowledge bases to resolve tickets and troubleshoot systems. Higher-powered tools naturally align with technical tasks that are structured, data-heavy, and decision-driven.</span></p><div><p>Advanced features remain underused, even where they could deliver broad impact. Technical functions stand out as much heavier users of advanced capabilities.</p><p>GPT‑5 helps solve this problem with its real‑time router that automatically decides which advanced features and tools to use based on conversation type, complexity, tool needs, and explicit intent.</p></div><p><span>Different technical teams also lean into distinct features. IT teams are more likely to use retrieval and search, treating ChatGPT as a knowledge companion for quick answers to configuration or policy questions. Engineering teams show stronger use of GPTs, programming tools, and data analysis, reflecting their more code-centric workflows. This divergence underscores that adoption depends not only on technical fluency but also on the type of work and context within each department.</span></p><p><span>Two opportunities emerge from this data. First, advanced features remain underused, even where they could deliver broad impact. Barriers may include discoverability, awareness of use cases, or the setup required to use them. </span></p><p><span>Second, early champions in analytics, IT, legal, and engineering are already pushing into more complex workflows. As enablement programs expand and product improvements lower the barrier to entry, adoption will likely shift from core daily tasks toward deeper reasoning and collaborative workflows that reshape decision-making across the enterprise.&nbsp;</span></p><div><div><h4>R&amp;D</h4><ol><li><p>1</p>Search</li><li><p>2</p>Data analysis</li><li><p>3</p>Image upload</li></ol></div><div><h4>Go-to-market</h4><ol><li><p>1</p>Search</li><li><p>2</p>Data analysis</li><li><p>3</p>Retrievel</li></ol></div><div><h4>Administrative</h4><ol><li><p>1</p>Search</li><li><p>2</p>Data analysis</li><li><p>3</p>File upload</li></ol></div></div><div id=\"chatgpt-as-an-operating-system-for-work\"><p></p><h2><span>ChatGPT as an operating system for work</span></h2><p></p></div><p><span>ChatGPT is already making workers more productive in measurable ways. Internal benchmarks show meaningful increases in productivity, driven by employees who use it to write and communicate faster, research more effectively, and reduce the effort required for repetitive tasks. Most companies are still in the early stages of adoption, but we’re beginning to see organizations embed ChatGPT at the departmental level to make entire processes more efficient.&nbsp;</span></p><p><span>Unlike traditional enterprise software, which spreads through top-down rollouts after long decision cycles and training programs, ChatGPT entered the workplace from the bottom up. Employees and small teams brought it in on their own, experimented with workflows, and demonstrated value before companies formalized procurement. This grassroots pattern has made it the fastest adopted enterprise technology in recent history.&nbsp;</span></p><p><span> That dynamic is now shifting. New capabilities, from autonomous agents to advanced coding support to decision-assist tools, are expanding the role of ChatGPT beyond personal productivity. It’s becoming a platform for entire workflows. Executives use it to shape strategy, engineers to design and debug systems, and customer support agents to evaluate complex solutions. Increasingly, ChatGPT functions as an operating system for daily work: a shared layer where decisions are made, problems are solved, and output scales.</span></p><div><p><b>ChatGPT usage: Broad and deep</b></p><p>The number of people using ChatGPT is increasing, but so is the number of inquiries per user:</p><ul><li><p>Certain power-user segments of ChatGPT Pro subscribers send upwards of 200 messages to ChatGPT per day </p></li><li><p>Usage has evolved from simple Q&amp;A to coding, data analysis, and a range of agentic workflows</p></li></ul></div><div id=\"whats-next-for-work\"><p></p><h2><span>What’s next for work</span></h2><p></p></div><p><span>Work has always evolved alongside technology. Not long ago, much of it centered on finding answers, drafting emails, and repeating solved problems. Increasingly, it’s shifting toward synthesis, creativity, and speed: work that’s improved by natural, intuitive interactions with AI.</span></p><p><span>In the years ahead, AI will embed itself into nearly every workflow. As this happens, employees will spend less time performing tasks and more time supervising and shaping AI output. The crossfunctional reach of ChatGPT means individuals will be able to take on tasks once spread across multiple departments. A product manager, for example, might use it to analyze customer feedback, test and refine a new feature, and draft the legal and marketing content needed to bring it to market.</span></p><p><span>Collaboration is moving from siloed documents and messages into shared, real-time workspaces where teams solve problems together. Features like memory are making the product more contextaware, giving employees a partner that remembers preferences, projects, and workflows unique   to them. And the ability to bring structured and unstructured data directly into ChatGPT is broadening its role as the central interface for enterprise knowledge, and GPT‑5 is accelerating this shift.</span></p><p><span>Crucially, early evidence suggests this shift not only makes workers more productive, but actually makes their work more enjoyable. It does this by shrinking time-consuming and lower-value tasks and enabling them to refocus time on meaningful, core work. In a six-month randomized field experiment across thousands of knowledge workers, access to AI cut weekly email time by 31%. Another study looked at software developers, finding AI coding tools enabled them to spend more time coding, more time on exploratory work, and less time on project-management. Together, these findings suggest that tools like ChatGPT may reduce busywork, freeing up time for more strategic, satisfying, and ultimately higher-value work.</span></p><p><span>The scale of this change echoes past technological revolutions. Electricity reshaped factory work, the internet redefined commerce and communication, and AI is now setting the stage for the next leap. The enterprises that adapt quickly and thoughtfully will capture the earliest and largest gains: faster decision cycles, productivity breakthroughs, and new opportunities across every function.</span></p></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/2rUSG4XSMDGLJMBdfgtVH/97f5474b4822fccb60211817a5cceb65/chatgpt-usage-and-adoption-patterns-at-work-IMAGE.png?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/index/higgsfield",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/higgsfield",
    "title": "How Higgsfield turns simple ideas into cinematic social videos",
    "publishedAt": "Wed, 21 Jan 2026 10:00:00 GMT",
    "fetchedAt": "2026-01-25T19:08:02.409Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div><p><span>Short-form video drives modern commerce, but producing video that actually performs is harder than it looks. Clips that feel effortless on TikTok, Reels, and Shorts are built on invisible rules: hook timing, shot rhythm, camera motion, pacing, and other subtle cues that make content feel “native” to whatever is trending.</span></p><p><a href=\"https://higgsfield.ai/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>Higgsfield</span></u>⁠<span>(opens in a new window)</span></a><span> is a generative media platform that lets teams create short-form, cinematic videos from a product link, an image, or a simple idea. Using OpenAI GPT‑4.1 and GPT‑5 to plan and Sora 2 to create, the system generates roughly 4 million videos per day, turning minimal input into structured, social-first video.</span></p><div><blockquote>“Users rarely describe what a model actually needs. They describe what they want to feel. Our job is to translate that intent into something a video model can execute, using OpenAI models to turn goals into technical instructions.”</blockquote><p>—Alex Mashrabov, Co-founder and CEO, Higgsfield</p></div><div id=\"creators-describe-outcomes-not-camera-instructions\"><p></p><h2><span>Creators describe outcomes, not camera instructions</span></h2><p></p></div><p><span>People don’t think in shot lists. They say things like “make it dramatic” or “this should feel premium.” Video models, by contrast, require structured direction: timing rules, motion constraints, and visual priorities.</span></p><p><span>To bridge that gap, the Higgsfield team built what they call a cinematic logic layer to interpret creative intent and expand it into a concrete video plan before any generation happens.</span></p><p><span>When a user provides a product URL or image, the system uses GPT‑4.1 mini and GPT‑5 to infer narrative arc, pacing, camera logic, and visual emphasis. Rather than exposing users to raw prompts, Higgsfield internalizes cinematic decision-making into the system itself. Once the plan is constructed, Sora 2 renders motion, realism, and continuity based on those structured instructions.</span></p><p><span>That planning-first approach reflects the team behind the product. Higgsfield brings together engineers and experienced filmmakers, including award-winning directors, alongside leadership with deep roots in consumer media. Co-founder and CEO Alex Mashrabov previously led generative AI at Snap, where he invented Snap lenses, shaping how hundreds of millions of people interact with visual effects at scale.</span></p><div id=\"operationalizing-virality-as-a-system-not-a-guess\"><p></p><h2><span>Operationalizing virality as a system, not a guess</span></h2><p></p></div><p><span>For Higgsfield, virality is a set of measurable patterns identified using GPT‑4.1 mini and GPT‑5 to analyze short‑form social videos at scale and distill those findings into repeatable creative structures.</span></p><p><span>Internally, Higgsfield defines virality by engagement-to-reach ratio, with particular focus on share velocity. When shares begin to outpace likes, content shifts from passive consumption to active distribution.</span></p><p><span>Higgsfield encodes recurring, viral structures into a library of video presets. Each preset has a specific narrative structure, pacing style, and camera logic observed in high-performing content. Roughly 10 new presets are created each day, and older ones are cycled out as engagement wanes.</span></p><p><span>These presets power Sora 2 Trends, which lets creators generate trend-accurate videos from a single image or idea. The system applies motion logic and platform pacing automatically, producing outputs aligned to each trend without manual tuning.</span></p><p><span>Compared to Higgsfield’s earlier baseline, videos generated through this system show a 150% increase in share velocity and roughly 3x higher cognitive capture, measured through downstream engagement behavior.</span></p><div id=\"turning-product-pages-into-ads-with-click-to-ad\"><p></p><h2><span>Turning product pages into ads with Click-to-Ad</span></h2><p></p></div><p><span>Built on the same planning-first principles that guide the rest of the platform, Click-to-Ad grew out of the positive reception to Sora 2 Trends. The feature removes the “prompting barrier” by using GPT‑4.1 to interpret product intent and Sora 2 to generate videos.</span></p><p><span>Here’s how it works:</span></p><div><ol><li><span>A user pastes in a link to a product page</span></li><li><span>The system analyzes the page to extract brand intent, identify key visual anchors, and understand what matters about the product</span></li><li><span>Once the product is identified, the system maps it into one of the pre-engineered trending presets</span></li><li><span>Sora 2 generates the final video, applying each preset's complex professional standards for camera motion, rhythmic pacing, and stylistic rules</span></li></ol></div><p><span>The goal is fast, usable output that fits social platforms on the first try, and that shift changes how teams work. Users now tend to get usable video in one or two attempts, rather than iterating through five or six prompts. For marketing teams, that means campaigns can be planned around volume and variation, not trial and error.</span></p><p><span>A typical generation takes 2–5 minutes, depending on the workflow. Because the platform supports concurrent runs, teams can generate dozens of variations in an hour, making it practical to test creative directions as trends shift.</span></p><p><span>Since launching in early November, Click-to-Ad has been adopted by more than 20% of professional creators and enterprise teams on the platform, measured by whether outputs are downloaded, published, or shared as part of live campaigns.</span></p><div id=\"routing-the-right-job-to-the-right-model\"><p></p><h2><span>Routing the right job to the right model</span></h2><p></p></div><p><span>Higgsfield’s system relies on multiple OpenAI models, each selected based on the demands of the task.</span></p><p><span>For deterministic, format-constrained workflows, such as enforcing preset structure or applying known camera-motion schemas, the platform routes requests to GPT‑4.1 mini. These tasks benefit from high steerability, predictable outputs, low variance, and fast inference.</span></p><p><span>More ambiguous workflows require a different approach. When the system needs to infer intent from partial inputs, such as interpreting a product page or reconciling visual and textual signals, Higgsfield routes requests to GPT‑5, where deeper reasoning and multimodal understanding outweigh latency or cost considerations.</span></p><p><span>Routing decisions are guided by internal heuristics that weigh:</span></p><div><ul><li><span>Required reasoning depth versus acceptable latency</span></li><li><span>Output predictability versus creative latitude</span></li><li><span>Explicit versus inferred intent</span></li><li><span>Machine-consumed versus human-facing outputs</span></li></ul></div><p><span>“We don’t think of this as choosing the best model,” says Yerzat Dulat, CTO and co-founder of Higgsfield. “We think in terms of behavioral strengths. Some models are better at precision. Others are better at interpretation. The system routes accordingly.”</span></p><div id=\"pushing-the-boundaries-of-ai-video\"><p></p><h2><span>Pushing the boundaries of AI video</span></h2><p></p></div><p><span>Many of Higgsfield’s workflows would not have been viable six months ago.</span></p><p><span>Earlier image and video models struggled with consistency: characters drifted, products changed shape, and longer sequences broke down. Recent advances in OpenAI image and video models made it possible to maintain visual continuity across shots, enabling more realistic motion and longer narratives.</span></p><p><span>That shift unlocked new formats. Higgsfield recently launched Cinema Studio, a horizontal workspace designed for trailers and short films. Early creators are already producing multi-minute videos that circulate widely online, often indistinguishable from live-action footage.</span></p><p><span>As OpenAI models continue to evolve, Higgsfield’s system expands with them. New capabilities are translated into workflows that feel obvious in hindsight, but weren’t feasible before. As models mature, the work of storytelling shifts away from managing tools and toward making decisions about tone, structure, and meaning.</span></p></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/l4N7eLGr7UTXrD7rVQsUE/c10a14431c48d07d9dfbaf6f02c0bd3f/oai_higgsfield_SEO.png?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/index/edu-for-countries",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/edu-for-countries",
    "title": "Introducing Edu for Countries",
    "publishedAt": "Wed, 21 Jan 2026 01:00:00 GMT",
    "fetchedAt": "2026-01-25T19:08:02.290Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div><p><span>The history of technology suggests that the biggest economic gains come not from invention alone, but from turning new capabilities into scaled, everyday use. But even as AI capabilities have improved, </span><a href=\"https://openai.com/index/ai-for-self-empowerment/\" target=\"_blank\" rel=\"noopener noreferrer\"><span>we see a widening “capability overhang,”</span></a><span> defined as the gap between what AI tools can do and how people are using them.</span></p><p><span>Education systems are a critical route through which this gap is closed. </span><a href=\"https://reports.weforum.org/docs/WEF_Future_of_Jobs_Report_2025.pdf?utm_source=chatgpt.com\" target=\"_blank\" referrerpolicy=\"no-referrer-when-downgrade\" rel=\"noopener noreferrer\"><span>Studies</span>⁠<span>(opens in a new window)</span></a><span> project that by 2030 nearly 40% of the core skills workers rely on today will change, driven largely by AI. By embedding AI tools, training, and research into the core infrastructure of schools and universities, education systems can evolve alongside these shifts and better prepare students to thrive in a world with AI.&nbsp;</span></p><div id=\"openais-education-for-countries\"><p></p><h2><span>OpenAI’s Education for Countries&nbsp;</span></h2><p></p></div><p><span>It is for this purpose that we are launching </span><b><span>OpenAI’s Education for Countries</span></b><span> as a new pillar of our </span><a href=\"https://openai.com/index/how-countries-can-end-the-capability-overhang/\" target=\"_blank\" rel=\"noopener noreferrer\"><span>OpenAI for Countries</span></a><span> initiative. We will work with governments and university consortia to bring AI into education systems to personalize learning, reduce administrative burden, and prepare students for the workforce. Working with Ministries of Education, partners, universities and researchers, the initiative will bring together several core elements:</span></p><div><ul><li><b><span>AI tools for learning: </span></b><span>Access to </span><a href=\"https://chatgpt.com/business/education/\" target=\"_blank\" referrerpolicy=\"no-referrer-when-downgrade\" rel=\"noopener noreferrer\"><span>ChatGPT Edu</span>⁠<span>(opens in a new window)</span></a><span>, </span><a href=\"https://openai.com/index/introducing-gpt-5-2/\" target=\"_blank\" rel=\"noopener noreferrer\"><span>GPT‑5.2</span></a><span>, </span><a href=\"https://openai.com/index/chatgpt-study-mode/\" target=\"_blank\" rel=\"noopener noreferrer\"><span>study mode</span></a><span>, and </span><a href=\"https://openai.com/index/introducing-canvas/\" target=\"_blank\" rel=\"noopener noreferrer\"><span>canvas</span></a><span> can be customized to shape how the world’s most advanced AI models are used to support local learning priorities.</span></li><li><b><span>Learning outcomes research: </span></b><span>Collaboration on large-scale, national research initiatives to understand how AI supports learning and affects teacher productivity, which can inform local policy, workforce development, and future technology design.</span></li><li><b><span>OpenAI Certifications and training: </span></b><span>Tailored training with ministries and education systems, from the </span><a href=\"https://academy.openai.com/\" target=\"_blank\" referrerpolicy=\"no-referrer-when-downgrade\" rel=\"noopener noreferrer\"><span>OpenAI Academy</span>⁠<span>(opens in a new window)</span></a><span> to ChatGPT‑based certifications, giving educators and students the practical AI skills aligned with national workforce priorities.</span></li><li><b><span>Global network of partners: </span></b><span>A growing network of governments, researchers, and education leaders who share insights, highlight successful deployments, and help shape responsible approaches to AI in education.</span></li></ul></div><div id=\"our-growing-work-with-countries-globally\"><p></p><h2><span>Our growing work with countries globally</span></h2><p></p></div><p><span>Our first cohort includes Estonia, Greece, Italy’s Conference of University Rectors (CRUI), Jordan, Kazakhstan, Slovakia, Trinidad &amp; Tobago, and the United Arab Emirates.&nbsp;</span></p><p><span>AI tools like ChatGPT Edu have already been deployed nationwide in Estonia, across public universities and secondary schools, reaching more than 30,000 students, educators, and researchers in its first year. Longitudinal research partnerships are also underway, such as a large-scale study with the University of Tartu and Stanford, to measure how AI affects learning outcomes among 20,000 students over time.</span></p><p><span>As AI is introduced at scale, rollouts typically follow a phased approach, starting by equipping educators with the tools and training they need to lead AI use in classrooms. In higher education, ChatGPT Edu is already available to students. In high schools, student access begins through small pilots developed in close collaboration with local leaders, to ensure safety and alignment with local curricula. These pilots are paired with ongoing work by OpenAI to strengthen protections for young people who use ChatGPT, including age-appropriate model behavior improvements and developing AI literacy content for educators with trusted partners like Common Sense Media.</span></p><div id=\"ensuring-ai-benefits-everyone\"><p></p><h2><span>Ensuring AI benefits everyone</span></h2><p></p></div><p><span>OpenAI’s mission is to ensure that advanced AI benefits everyone. We're building AI to help people solve hard problems because by helping with the hard problems, AI can benefit the most people possible—through more scientific discoveries, better healthcare and education, and improved productivity. This work reflects a simple belief: powerful technologies should expand opportunity for all, not exclude people from it.</span></p><p><span>OpenAI’s Education for Countries builds on this mission, as well as our work to ensure AI expands economic opportunity with </span><a href=\"https://openai.com/index/openai-certificate-courses/\" target=\"_blank\" rel=\"noopener noreferrer\"><span>OpenAI Certifications</span></a><span>, which help individuals build foundational AI skills and give clear signals to employers about their ability to use AI effectively at work.</span></p><p><span>The program also represents a step forward in OpenAI’s ongoing commitment to supporting learning with AI—complementing programs like </span><a href=\"https://openai.com/index/introducing-nextgenai/\" target=\"_blank\" rel=\"noopener noreferrer\"><span>NextGenAI</span></a><span> to accelerate research on AI and learning across universities, products to enhance how AI is used in education like </span><a href=\"https://openai.com/index/introducing-chatgpt-edu/\" target=\"_blank\" rel=\"noopener noreferrer\"><span>ChatGPT Edu</span></a><span> and </span><a href=\"https://openai.com/index/chatgpt-study-mode/\" target=\"_blank\" rel=\"noopener noreferrer\"><span>study mode</span></a><span>, and partnerships to support teacher-led AI adoption like with the </span><a href=\"https://openai.com/global-affairs/aft/\" target=\"_blank\" rel=\"noopener noreferrer\"><span>American Federation of Teachers</span></a><span> in the United States.</span></p><p><span>Our next cohort will be announced later in 2026. To learn more about how to join, contact our team.</span></p></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/6BiN06SaVBBRF4b5aUv6Q7/29ea79a72b62c68318ae53715bc21c7d/SEO_Image.png?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/index/horizon-1000",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/horizon-1000",
    "title": "Horizon 1000: Advancing AI for primary healthcare",
    "publishedAt": "Tue, 20 Jan 2026 21:00:00 GMT",
    "fetchedAt": "2026-01-25T19:08:02.504Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div id=\"main\" tabindex=\"-1\"><span aria-live=\"polite\" aria-atomic=\"true\">OpenAI</span><article><div><p>Together, with the Gates Foundation, we’re committing $50 million in funding and technology to help strengthen primary healthcare for 1,000 African clinics and their communities.</p></div><div><p><span>AI capabilities have advanced much faster than their broad, real-world deployment, leaving a growing gap between what’s possible and what people experience. These systems have become so capable that they’ve made new kinds of things possible—some we couldn’t have imagined not long ago, and some we’re still discovering. This is especially clear in healthcare, where the challenge is now </span><a href=\"https://openai.com/index/ai-clinical-copilot-penda-health/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>turning powerful models into tools</span></u>⁠</a><span> that work in everyday care.</span></p><p><span>Today, we’re announcing </span><b><span>Horizon 1000</span></b><span>, a pilot initiative with the Gates Foundation to support leaders in African countries, beginning in Rwanda, as they advance these AI capabilities for health. Together, the Gates Foundation and OpenAI are committing $50 million in funding, technology, and technical support to support their work, with the ambitious goal of reaching 1,000 primary healthcare clinics and their surrounding communities by 2028.</span></p><div><blockquote>“AI is going to be a scientific marvel no matter what, but for it to be a societal marvel, we’ve got to figure out ways that we use this incredible technology to improve people’s lives.”</blockquote><p>Sam Altman, CEO of OpenAI</p></div><p><span>Primary health care is the foundation of strong, resilient health systems, yet remains inaccessible for half the world’s population. Sub-Saharan Africa alone faces a health workforce shortfall of approximately 5.6 million workers—placing extraordinary strain on existing clinicians and underscoring the scale of unmet demand for care. Quality of care is also highly variable, and is a major driver of preventable deaths.</span></p><p><span>At the same time, many countries across Sub-Saharan Africa have been at the forefront of re-imagining how care can be delivered at scale. Governments and health leaders across the region are actively exploring how digital tools and AI can help extend the reach of their existing health workforce, improve quality, and bring more consistent care to communities.&nbsp;</span></p><p><span>Horizon 1000 aims to meet this moment by supporting African leadership and medical experts with resources and technical expertise so they can move from innovation to deployment. In practice, AI tools can help frontline health workers navigate complex guidelines and reduce administrative burden, so clinicians can spend more time on care. We also know people want more agency over their health, and many are already turning to AI to help navigate their own care.&nbsp;</span></p><p><span>We look forward to learning openly along the way and measuring success by what meaningfully improves care for patients and the health workforce who serve them.</span></p></div><section id=\"citations\" data-testid=\"citations\"><ul><li><a href=\"https://openai.com/news/?tags=2026\" target=\"_blank\" rel=\"noopener noreferrer\">2026</a></li></ul></section></article></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/5hjhwvqeMsjzikwYjjavQY/5007a11494456d471f8c480956b3b707/OpenAI_Gatesfoundation__1_.png?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/index/servicenow-powers-actionable-enterprise-ai-with-openai",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/servicenow-powers-actionable-enterprise-ai-with-openai",
    "title": "ServiceNow powers actionable enterprise AI with OpenAI",
    "publishedAt": "Tue, 20 Jan 2026 05:45:00 GMT",
    "fetchedAt": "2026-01-25T19:08:04.955Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div><p><b><span>Key takeaways:&nbsp;</span></b></p><div><ul><li><span>Multi-year agreement expands ServiceNow customer access to OpenAI frontier models.&nbsp;</span></li><li><span>OpenAI models will be a preferred intelligence capability for enterprises that run more than 80 billion workflows each year in ServiceNow.&nbsp;</span></li><li><span>OpenAI will support direct speech-to-speech and native voice technology in ServiceNow.&nbsp;</span></li></ul></div><p><span>ServiceNow, the AI control tower for business reinvention, today announced OpenAI will be a preferred intelligence capability for enterprises that run more than 80 billion workflows each year on its platform.</span></p><p><span>Enterprises around the world use ServiceNow to orchestrate workflows that keep their systems and operations running smoothly. In complex environments where technology is spread across many systems, teams, and vendors, ServiceNow ties everything together—helping organizations spot issues early, route work to the right people, manage approvals, and resolve challenges quickly so the business keeps moving.</span></p><p><span>ServiceNow’s AI Platform brings OpenAI models like GPT‑5.2 directly into these enterprise workflows, so AI can understand what’s happening, help decide what to do next, and take action within a customer’s secure infrastructure. With OpenAI, ServiceNow will unlock a new level of automation for the world’s largest companies enabling enterprise intelligence at scale for any function or department including IT, finance, sales, human resources, and more.&nbsp;</span></p><p><span>“ServiceNow leads the market in AI-powered workflows, setting the enterprise standard for real-world AI outcomes,” said Amit Zavery, president, chief operating officer, and chief product officer at ServiceNow. “Together, Service and OpenAI are building the future of AI experiences: deploying AI that takes end-to-end action in complex enterprise environments—not sandboxes. As companies shift experimenting with AI to deploying it at scale, they need the power of multiple AI leaders working together, to deliver faster, better outcomes. Bringing together our engineering teams and our respective technologies will drive faster value for customers and more intuitive ways of working with AI.”&nbsp;</span></p><p><span>“ServiceNow is helping enterprises bring agentic AI into workflows that are secure, scalable, and designed to deliver measurable outcomes,” said Brad Lightcap, chief operating officer at OpenAI. “With OpenAI frontier models and multimodal capabilities in ServiceNow, enterprises across every industry will benefit from intelligence that handles work end to end in even the most complex environments.”</span></p><p><span>With OpenAI, the ServiceNow AI Platform will leverage frontier intelligence like GPT‑5.2 so customers can understand more about what’s happening and take action inside enterprise workflows.</span></p><div id=\"powering-actionable-ai-workflows-for-enterprise-customers\"><p></p><h2><span>Powering actionable AI workflows for enterprise customers&nbsp;</span></h2><p></p></div><p><span>ServiceNow and OpenAI will support enterprises in adopting AI systems that can reason across tasks and carry out work with little human intervention. Customers can leverage OpenAI models alongside with ServiceNow workflows:&nbsp;</span></p><div><ul><li><b><span>AI assistance</span></b><span> that lets employees ask questions in natural language and get clear, actionable answers based on real enterprise data.</span></li><li><b><span>AI-powered summarization and content generation</span></b><span> for incidents, cases, knowledge articles, and service interactions, helping teams resolve issues faster with less manual effort.</span></li><li><b><span>Developer and admin tools</span></b><span> that turn intent into workflows, logic, and automation, dramatically speeding how business processes are built and updated.</span></li><li><b><span>Intelligent search and discovery</span></b><span> that pulls the right information from across enterprise systems exactly when it’s needed.</span></li></ul></div><p><span>For example, employees use ServiceNow in an intuitive experience where data, models, AI modalities, and workflows converge to ask for what they need in plain language, like “I need to view my benefits” or “this customer issue needs to be escalated.”</span></p><p><span>With GPT‑5.2 built directly into the ServiceNow AI Platform, those requests aren’t just answered—they’re acted on. The model pairs with the ServiceNow workflow engine, where it can access enterprise data, respect governance and permissions, and provide insights to trigger real actions. GPT‑5.2 helps add more context, decide what should happen next, and, via the ServiceNow platform, move work through approvals, and updates until it’s done. To employees it feels like chatting with a smart coworker; behind the scenes, it’s AI running real enterprise workflows end to end.</span></p><p><span>Looking ahead, ServiceNow and OpenAI will build toward more natural, multimodal experiences, where users can talk, type, or use visuals to interact with AI agents seamlessly.</span></p><div><p><span>ServiceNow extends OpenAI’s work with the world’s largest and most established enterprises, including </span><a href=\"https://openai.com/index/accenture-partnership/\" target=\"_blank\" rel=\"noopener noreferrer\"><span>Accenture</span></a><span>, </span><a href=\"https://corporate.walmart.com/news/2025/10/14/walmart-partners-with-openai-to-create-ai-first-shopping-experiences\" target=\"_blank\" rel=\"noopener noreferrer\"><span>Walmart</span>⁠<span>(opens in a new window)</span></a><span>, </span><a href=\"https://newsroom.paypal-corp.com/2025-10-28-OpenAI-and-PayPal-Team-Up-to-Power-Instant-Checkout-and-Agentic-Commerce-in-ChatGPT\" target=\"_blank\" rel=\"noopener noreferrer\"><span>PayPal</span>⁠<span>(opens in a new window)</span></a><span>, </span><a href=\"https://openai.com/index/intuit-partnership/\" target=\"_blank\" rel=\"noopener noreferrer\"><span>Intuit</span></a><span>, </span><a href=\"https://openai.com/index/target-partnership/\" target=\"_blank\" rel=\"noopener noreferrer\"><span>Target</span></a><span>, </span><a href=\"https://corporate.thermofisher.com/us/en/index/newsroom/Our-stories/Thermo-fisher-scientific-open-ai-collaboration.html\" target=\"_blank\" rel=\"noopener noreferrer\"><span>Thermo Fisher</span>⁠<span>(opens in a new window)</span></a><span>, </span><a href=\"https://openai.com/index/bny/\" target=\"_blank\" rel=\"noopener noreferrer\"><span>BNY</span></a><span>, </span><a href=\"https://openai.com/index/morgan-stanley/\" target=\"_blank\" rel=\"noopener noreferrer\"><span>Morgan Stanley</span></a><span>, </span><a href=\"https://openai.com/index/bbva-collaboration-expansion/\" target=\"_blank\" rel=\"noopener noreferrer\"><span>BBVA</span></a><span>, and many more.&nbsp;</span></p></div></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/3g24XPmpuheRJ5q9EZg74C/d22018f7cffe15b7833e1a582d788b46/openai-servicenow-16_9.png?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/index/our-approach-to-age-prediction",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/our-approach-to-age-prediction",
    "title": "Our approach to age prediction",
    "publishedAt": "Tue, 20 Jan 2026 00:00:00 GMT",
    "fetchedAt": "2026-01-25T19:08:03.410Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div><p><span>We’re rolling out age prediction on ChatGPT consumer plans to help determine whether an account likely belongs to someone under 18, so the right experience and safeguards can be applied to teens. As we’ve outlined in our </span><a href=\"https://openai.com/index/introducing-the-teen-safety-blueprint/\" target=\"_blank\" rel=\"noopener noreferrer\"><span>Teen Safety Blueprint</span>⁠</a><span> and </span><a href=\"https://openai.com/index/updating-model-spec-with-teen-protections/\" target=\"_blank\" rel=\"noopener noreferrer\"><span>Under-18 Principles for Model Behavior</span>⁠</a><span>, young people deserve technology that both expands opportunity and protects their well-being.</span></p><p><span>Age prediction builds on protections already in place. Teens who tell us they are under 18 when they sign up automatically receive additional safeguards to reduce exposure to sensitive or potentially harmful content. This also enables us to treat adults like adults and use our tools in the way that they want, within the bounds of safety. </span></p><p><span>We previously shared our </span><a href=\"https://openai.com/index/building-towards-age-prediction/\" target=\"_blank\" rel=\"noopener noreferrer\"><span>early plans</span>⁠</a><span> for age prediction, and today we’re sharing more detail as the rollout is underway.</span></p><div id=\"how-age-prediction-works\"><p></p><h2><span>How age prediction works</span></h2><p></p></div><p><span>ChatGPT uses an age prediction model to help estimate whether an account likely belongs to someone under 18. The model looks at a combination of behavioral and account-level signals, including how long an account has existed, typical times of day when someone is active, usage patterns over time, and a user’s stated age. Deploying age prediction helps us learn which signals improve accuracy, and we use those learnings to continuously refine the model over time.</span></p><p><span>Users who are incorrectly placed in the under-18 experience will always have a fast, simple way to confirm their age and restore their full access with a selfie through Persona, a secure identity-verification service. Users can check if safeguards have been added to their account and start this process at any time by going to Settings &gt; Account.</span></p><p><span>When the age prediction model estimates that an account may belong to someone under 18, ChatGPT automatically applies </span><a href=\"https://openai.com/index/updating-model-spec-with-teen-protections/\" target=\"_blank\" rel=\"noopener noreferrer\"><span>additional protections</span>⁠</a><span> designed to reduce exposure to sensitive content, such as:</span></p><div><ul><li><span>Graphic violence or gory content</span></li><li><span>Viral challenges that could encourage risky or harmful behavior in minors</span></li><li><span>Sexual, romantic, or violent role play</span></li><li><span>Depictions of self-harm</span></li><li><span>Content that promotes extreme beauty standards, unhealthy dieting, or body shaming</span></li></ul></div><p><span>This approach is guided by expert input and rooted in academic literature about the science of child development and acknowledges known teen differences in risk perception, impulse control, peer influence, and emotional regulation. While these content restrictions help reduce teens’ exposure to sensitive material, we are focused on continually improving these protections, especially to address attempts to bypass our safeguards. When we are not confident about someone’s age or have incomplete information, we default to a safer experience.</span></p><p><span>In addition to these safeguards, parents can choose to customize their teen’s experience further through </span><a href=\"https://help.openai.com/en/articles/12315553-parental-controls-on-chatgpt-faq\" target=\"_blank\" referrerpolicy=\"no-referrer-when-downgrade\" rel=\"noopener noreferrer\"><span>parental controls</span>⁠<span>(opens in a new window)</span></a><span> including setting quiet hours when ChatGPT can not be used, controlling features such as memory or model training, and receiving notifications if signs of acute distress are detected.</span></p><div id=\"whats-next\"><p></p><h2><span>What’s next</span></h2><p></p></div><p><span>We’re learning from the initial rollout and continuing to improve the accuracy of age prediction over time. We will closely track rollout and use those signals to guide ongoing improvements.</span></p><p><span>In the EU, age prediction will roll out in the coming weeks to account for regional requirements. For more detail, visit our </span><a href=\"https://help.openai.com/en/articles/12652064-age-prediction-in-chatgpt\" target=\"_blank\" referrerpolicy=\"no-referrer-when-downgrade\" rel=\"noopener noreferrer\"><span>help page</span>⁠<span>(opens in a new window)</span></a><span>. </span></p><p><span>While this is an important milestone, our work to support teen safety is ongoing. We’ll continue to share updates on our progress and what we’re learning, in dialogue with experts including the American Psychological Association, ConnectSafely, and </span><a href=\"https://openai.com/index/strengthening-chatgpt-responses-in-sensitive-conversations/\" target=\"_blank\" rel=\"noopener noreferrer\"><span>Global Physicians Network</span>⁠</a><span>.</span></p></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/6Zc47ksvon6g1VivNjTI0R/b5c02b2cec9669fd1f46822d3bfad12b/OAI_AgePrediction_Blog_ArtCard_1200x630.png?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/index/ai-for-self-empowerment",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/ai-for-self-empowerment",
    "title": "AI for self empowerment",
    "publishedAt": "Sun, 18 Jan 2026 12:00:00 GMT",
    "fetchedAt": "2026-01-25T19:08:04.628Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div><p><span>We create AI in order to empower people. As AI technology progress continues, a key focus for the world should be tracking the </span><b><span>capability overhang</span></b><span>: the gap between what AI systems can now do and the value most people, businesses, and countries are actually capturing from them at scale.</span></p><p><span>One challenge with even understanding the size of the capability overhang is that AI is a very counterintuitive technology which continually plays out in surprising ways. We launched ChatGPT three years ago with an at-the-time frontier AI that could answer simple questions and were shocked by how quickly it was adopted and the creative ways people found to apply it in their lives. We now have frontier AI which can reason and act across increasingly complex tasks, from building software to performing mathematical research, and we don’t yet know the full extent of how it will integrate into business or personal life. As Alan Kay said, “the best way to predict the future is to invent it,” and we’ve found that it takes a community of people exploring these tools to find amazing new uses that their capability has unlocked.</span></p><p><span>Just like with the invention of computers themselves, those who lean into the technology can reach a new level of individual productivity. For example, ChatGPT usage data reveals that the typical power user uses 7x more thinking power (and thus 7x more compute power) than the typical user. Power users don’t just use AI more—they use AI more comprehensively, applying the most advanced capabilities across a wider range of tasks—and as a result they can produce more economically valuable work.</span></p><p><span>We expect AI to enable some incredible high-level outcomes—such as double-digit GDP growth, affordable and effective healthcare, and rapid scientific advancement—which can raise the floor for everyone, while also raising the ceiling in new ways. The better we manage the capability overhang as a society, the more people will empower themselves to create new economic opportunities by fully exploring what these new tools can do.</span></p><div id=\"openais-principles-for-managing-the-capability-overhang\"><p></p><h2><span>OpenAI’s principles for managing the capability overhang</span></h2><p></p></div><p><span>In periods of rapid change, accurate information creates agency. People, businesses, and policymakers can make better decisions given well-grounded, credible data about what is actually happening: which roles are growing or shrinking, how AI is being used in practice, and where productivity gains are emerging. We don’t have all the answers, but we can help.</span></p><p><span>That’s why we’ve been making public our foundational economic data based insights, including a measurement of how AI tools match up in terms of performance with humans across a range of tasks.</span></p><p><span>As AI increasingly shapes economic outcomes, access to core tools will help people achieve more. Businesses need practical ways to adopt AI at scale, and countries need a systematic way for AI to be applied in their jurisdiction. AI’s usefulness will scale directly with compute power, and thus every individual, business, and country needs ways of accessing their own slice of compute.</span></p><p><span>That’s why we </span><b><span>created a free tier of ChatGPT, supported by advertising</span></b><span>, towards our mission of ensuring AGI benefits all of humanity. We created a new industry-standard API for developers to build applications on top of. We work with many institutions large and small—including governments—to support broad access to frontier AI capabilities.</span></p><p><span>We build tools which people can use to shape the future. That means putting a lot of power into people’s hands and designing our tools to be customizable and usable in ways we didn’t anticipate.</span></p><p><span>This approach is useful for </span><b><span>everyday users and small businesses</span></b><span>, where we design product experiences that help people do more than they thought they could—optimize a family’s budget, find jobs more effectively, develop ideas for a future business. It’s also useful for unlocking the next wave of innovation, such as for</span><b><span> builders and founders</span></b><span>, where we support high-agency people who turn frontier capability into new companies, products, and markets.</span></p><p><span>We believe this is how the Intelligence Age can expand opportunity for everyone, and result in a future that is much better than the present. We believe everyone should focus on managing the capability overhang so as many people, businesses, and countries empower themselves to participate in and benefit from the positive transformative potential of AI.</span></p></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/1s3RalD0qSDlBndLNMlJon/530f022ce5362306b85cc0da616fe331/ai_empowerment.png?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/index/the-truth-elon-left-out",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/the-truth-elon-left-out",
    "title": "The truth left out from Elon Musk’s recent court filing",
    "publishedAt": "Fri, 16 Jan 2026 12:00:00 GMT",
    "fetchedAt": "2026-01-25T19:08:03.937Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div><div><p><img alt=\"Screenshot comparing a court filing summary with a longer excerpt of Elon Musk's actual 2017 remarks. The top box shows the filing's claiming that Elon wanted OpenAI to remain &quot;essentially philanthropic,&quot; while the lower section highlights Musk's original comments about transitioning from a nonprofit to a &quot;B-corp&quot; or &quot;C-corp&quot;. Blue highlights mark text shown in the court filing; red highlights mark added emphasis.\" data-nosnippet=\"true\" loading=\"lazy\" width=\"2262\" height=\"1682\" decoding=\"async\" data-nimg=\"1\" sizes=\"(min-width: 1728px) 1728px, 100vw\" srcset=\"https://images.ctfassets.net/kftzwdyauwt9/i5W4vlX7N6jkUkFXJZq69/e56406ab7a6c8c1873539ab8967d11e3/OAI_Court_Filing_Excerpt_v3.1.png?w=640&amp;q=90&amp;fm=webp 640w, https://images.ctfassets.net/kftzwdyauwt9/i5W4vlX7N6jkUkFXJZq69/e56406ab7a6c8c1873539ab8967d11e3/OAI_Court_Filing_Excerpt_v3.1.png?w=750&amp;q=90&amp;fm=webp 750w, https://images.ctfassets.net/kftzwdyauwt9/i5W4vlX7N6jkUkFXJZq69/e56406ab7a6c8c1873539ab8967d11e3/OAI_Court_Filing_Excerpt_v3.1.png?w=828&amp;q=90&amp;fm=webp 828w, https://images.ctfassets.net/kftzwdyauwt9/i5W4vlX7N6jkUkFXJZq69/e56406ab7a6c8c1873539ab8967d11e3/OAI_Court_Filing_Excerpt_v3.1.png?w=1080&amp;q=90&amp;fm=webp 1080w, https://images.ctfassets.net/kftzwdyauwt9/i5W4vlX7N6jkUkFXJZq69/e56406ab7a6c8c1873539ab8967d11e3/OAI_Court_Filing_Excerpt_v3.1.png?w=1200&amp;q=90&amp;fm=webp 1200w, https://images.ctfassets.net/kftzwdyauwt9/i5W4vlX7N6jkUkFXJZq69/e56406ab7a6c8c1873539ab8967d11e3/OAI_Court_Filing_Excerpt_v3.1.png?w=1920&amp;q=90&amp;fm=webp 1920w, https://images.ctfassets.net/kftzwdyauwt9/i5W4vlX7N6jkUkFXJZq69/e56406ab7a6c8c1873539ab8967d11e3/OAI_Court_Filing_Excerpt_v3.1.png?w=2048&amp;q=90&amp;fm=webp 2048w, https://images.ctfassets.net/kftzwdyauwt9/i5W4vlX7N6jkUkFXJZq69/e56406ab7a6c8c1873539ab8967d11e3/OAI_Court_Filing_Excerpt_v3.1.png?w=3840&amp;q=90&amp;fm=webp 3840w\" src=\"https://images.ctfassets.net/kftzwdyauwt9/i5W4vlX7N6jkUkFXJZq69/e56406ab7a6c8c1873539ab8967d11e3/OAI_Court_Filing_Excerpt_v3.1.png?w=3840&amp;q=90&amp;fm=webp\" style=\"max-width: 100%; height: auto; border-radius: 1rem; margin: 2rem 0px;\"></p></div><p><span>In his </span><a href=\"https://storage.courtlistener.com/recap/gov.uscourts.cand.433688/gov.uscourts.cand.433688.379.59.pdf\" target=\"_blank\" rel=\"noopener noreferrer\"><span>latest court filing</span>⁠<span>(opens in a new window)</span></a><span>, Elon cherry-picks and publishes snippets from Greg Brockman's private journal entries (obtained as part of legal discovery) which, when read with the surrounding context, tell a very different story from what Elon claims.</span></p><p><span>The truth is that we and Elon agreed in 2017 that a for-profit structure would be the next phase for OpenAI; negotiations ended when we refused to give him full control; we rejected his offer to merge OpenAI into Tesla; we tried to find another path to achieve the mission together; and then he quit OpenAI, encouraging us to find our own path to raising billions of dollars, without which he gave us a </span><a href=\"https://openai.com/index/elon-musk-wanted-an-openai-for-profit/#december-2018-elon-told-us-to-raise-billions-per-year-immediately-or-forget-it\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>0% chance</span></u>⁠</a><span> of success.</span></p><p><span>We did find a path to advance the mission, with OpenAI </span><a href=\"https://openai.com/index/built-to-benefit-everyone/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>now structured</span></u>⁠</a><span> as two main entities: a public benefit corporation (“PBC”) and a controlling non-profit which owns equity in the PBC currently valued at approximately $130 billion.</span></p><div><blockquote><p><span>In 2017, OpenAI’s founders became concerned that developing artificial general intelligence would require more resources than a nonprofit could raise through charitable donations. Ex. 38. They discussed numerous ideas, including creating a for-profit arm for OpenAI, collaborating with an existing company, or restructuring in some other manner. Ex. 1 (Musk Tr.) at 70:6-72:15, 78:18- 79:14, 95:8-16. Musk insisted that any new entity “support[ ] the nonprofit’s mission” and that OpenAI remain</span><span> </span><span>“essentially [a] philanthropic endeavor.”</span></p></blockquote></div><div data-shaded-container=\"true\"><!--$--><div><p><span>gdb: over upcoming weeks, how much of your time should we plan for?<br></span><span>elon:</span><span> coming weeks, top priority. </span><span>gotta figure out how do we transition from non-profit to something which is</span><span> </span><span>essentially philanthropic endeavor</span><span> </span><span>and is B-corp or C-corp or something.</span><span> must tell the story and not lose moral high ground. </span><span>absolutely vital.</span><span><br>gdb: yep.<br>elon: need to understand B-corp situation.<br>ilya: i have *some* thoughts. one idea keep non-profit and have C-corp. but i find this approach less appealing because in some sense C-corp not beholden. one formulation: mission is to minimize ex risk by building friendly AGI. could be a way to go. like it more as a new entity beholden to the mission.<br>elon: agree, does sound better. never even heard of a B-corp until sam brought it up.</span><b><span> </span></b><span>it does sound like right move. would not shut down </span><span>the non-profit, should still exist in some form.</span><span><br>ilya: no opinion, as long as the main entity has something fundamentally philanthropic.<br>elon: any prefs on name?<br>ilya: openai. continuity of the mission. it’s all the same.<br>elon: i agree, think that makes sense. well, i’m pretty excited about doing this with you.<br>ilya: all that’s left is the minor thing of actually doing it.<br>elon: alright cool. </span><span>i’m gonna figure out the details of the whole B-corp thing tomorrow</span><span> and get that process under way. and then let’s just stay in frequent touch. make this happen as quickly as possible.</span></p></div><!--/$--><!--$--><div><p><span>blue</span><span> </span><i><span>= quote shown in Elon’s court filing<br></span></i><span>red</span><span> </span><i><span>= emphasis added</span></i></p></div><!--/$--></div><p><span>Elon did not think that OpenAI needed to remain solely a non-profit. As the context shows, he agreed that OpenAI needed both a non-profit and a for-profit entity—the exact structure OpenAI has today, and that Elon is now suing OpenAI over. At the time, he said only that the non-profit should continue to exist “in some form.” Ilya, not Elon, suggested that the for-profit should have a connection to the OpenAI mission. Shortly after this call, Elon actually </span><a href=\"https://openai.com/index/elon-musk-wanted-an-openai-for-profit/#september-2017-elon-created-the-public-benefit-corporation-called-open-artificial-intelligence-technologies-inc\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>created</span></u>⁠</a><span> an OpenAI PBC (or “B-corp”).</span></p><p><span>Despite his court filings glossing over the details of these negotiations, they were quite intense and involved deeply personal conversations. Elon said he wanted to accumulate $80B for a self-sustaining city on Mars, and that he needed and deserved majority equity. He said that he needed full control since he’d been burned by not having it in the past, and when we discussed succession he surprised us by talking about his children controlling AGI.</span></p><p><span>Discussions about OpenAI’s structure—and Elon’s proposal that he lead and control it—progressed to the point that Elon asked us to check references with people who had worked closely with him. One pointed out the parallel to Elon’s Mars ambitions, which had started as a </span><a href=\"https://spaceref.com/status-report/marsnow-19-profile-elon-musk-life-to-mars-foundation/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>philanthropic project</span></u>⁠<span>(opens in a new window)</span></a><span> and grew into a commercial one, and mentioned that Elon tends to vilify people who quit his companies.</span></p><p><span>Even before negotiations over OpenAI’s structure began, Elon leveraged OpenAI for the benefit of his for-profit ventures. For example, in early 2017, he asked OpenAI to send a team to help fix Tesla’s self-driving program, Autopilot. Scott Gray, Ilya, Greg, and Andrej Karpathy ended up devoting significant time to improving Autopilot, which led to Elon recruiting Andrej to join Tesla fulltime. Elon never truly treated OpenAI as an independent non-profit.</span></p><div><blockquote><p><span>But Musk’s co-founders secretly had other plans. On November 6, 2017, following a meeting with Sutskever, Brockman admitted in his private diary that their </span><span>“conclusion is we truly want the [for-profit] b-corp.”</span></p></blockquote></div><div data-shaded-container=\"true\"><!--$--><div><p><span>- sam: </span><span>say, we wanna do openai, if you wanna do inside tesla it’s ok. if weirdly competitive should revisit.</span><span><br>- ilya: was thinking, what we need.<br>- sam: depends how strategically dependent we would be, could imagine a way that works.<br>- ilya: earlier more concerned. don’t want only strategy to be tesla. wouldn’t wanna be locked into something that only tesla<br>- gdb: why be ok with similar effort in tesla?<br>- sam: won’t work, how little<br>- sam: would like E to stay on board, not go to war. don’t think will work, tell him that. maybe he’ll get the hardware built inside of tesla.<br>- ilya: if i’m truly honest, </span><span>my prefs here are not set in stone, some pref for b-corp. can be made happy in the non-profit world.</span><span><br>- sam: what involvement?<br>- sam: would prefer to have him involved,<br>- sam: much more interested in you two being motivated + non-distracted. normally have one thing. that’s moved around a lot. thing i care about the most optimum output. if you guys are not gonna be happy with the non-profit, let’s figure out the b-corp. If you don’t want e involved,<br>&nbsp;- do have weakly held views, but pale in comparison to making you guys fully happy.</span></p><p><span>** ilya and me breakfast</span></p><p><span>- </span><span>conclusion is we truly want the b-corp.</span><span> honestly we also want to get back to work. but it’s not super clear how we get there.</span></p></div><!--/$--><!--$--><div><p><span>blue</span><span> </span><i><span>= quote shown in Elon’s court filing<br></span></i><span>red</span><span> </span><i><span>= emphasis added</span></i></p></div><!--/$--></div><p><span>While Greg and Ilya preferred the B-corp, they were open to pursuing the mission within the standalone non-profit—if it could raise enough funding. Their preference was not a secret; the thinking was shared with Elon and his key staff.</span></p><p><span>Negotiations over an OpenAI for-profit with Elon fell through in September 2017 because we wouldn’t give him absolute control. In early October, Shivon Zilis (at the time Elon’s liaison to OpenAI) told Greg and Ilya that Elon wanted them to “commit” to the non-profit by giving him two more board seats, agreeing not to quit for some period of time, and signing a non-solicit.&nbsp;Greg and Ilya considered this proposal but </span><b><span>never agreed</span></b><span> to it given their concerns about the non-profit’s ability to raise enough capital and Elon’s ability to start a competitor without consequence. They discussed with Shivon whether a B-corp with Elon was still possible; she said Elon had told her it could be but not for the next 6-9 months—enough time to get some distance from these intense negotiations and for Elon to focus on Tesla’s Model 3 ramp-up.</span></p><p><span>A few weeks later, Elon told us that it was a happy accident that the for-profit hadn’t materialized as it never could have obtained enough funding. Instead, he began trying to convince us that merging OpenAI into Tesla was the only path to the mission, and it seemed that he would pursue an AGI competitor within Tesla regardless.</span></p><p><span>By early November, we were trying to figure out a path forward that didn’t involve ending up at Tesla. The November 6, 2017 entry goes through more thinking (e.g. “</span><b><span>the answer is that we would have preferred the b-corp, but we prefer the non-profit to tesla.</span></b><span>”) and eventually comes to an ordered list of options for how to move forward: “</span><b><span>[1] b-corp w/ appropriate control structure [2] non-profit w/ lots of funding [3] us quitting and doing our own thing</span></b><span>”.</span></p><div><blockquote><p><span>Brockman privately fretted about concealing their plans from Musk. </span><span>“[C]annot say that we are committed to the non-profit. don’t wanna say that we’re committed. if three months later we’re doing b-corp then it was a lie.”</span><span> Ex. 43 at 2. </span><span>“[Musk’s] story will correctly be that we weren’t honest with him in the end about still wanting to do the for profit.”</span><span> Id. at 3. </span><span>“[I]t’d be wrong to steal the non-profit from [Musk]. to convert to a b-corp without him. that’d be pretty morally bankrupt.”</span></p></blockquote></div><div data-shaded-container=\"true\"><!--$--><div><p><span>if he starts the competitor</span><span> going to be less</span></p><p><span>cannot say that we are committed to the non-profit. don’t wanna say that we’re committed. if three months later we’re doing b-corp then it was a lie.</span></p><p><span>statement must be, right now we have these concerns, </span><span>we want to see the fundraising landscape.</span><span> hypothesis: after robot hand and 5v5, totally diff world. we need, upper bound, $150M for 2018. and right now more dollars wouldn’t make us move faster.</span></p><p><span>and so... what does this all mean. </span><span>we are really unsure if he starts a competitor that it’s going to end in a good place.</span><span> btw right now we have this great position of power. but it can of course all go away very quickly.</span></p><p><span>- policy gradients</span></p><p><span>ok, so not feeling so great about all of this. the true answer is that we want him out.</span></p><p><span>ok, so talking to shivon: </span><span>she’s like how are you gonna raise the billions in the non-profit? of course E isn’t going to put personal money on the line, not going to give up on mars.</span></p><p><span>if he really thinks that AGI is gonna happen first and be the craziest thing and change everything, then why not?</span></p><p><span>can’t see us turning this into a for-profit without a very nasty fight. i’m just thinking about the office and we’re in the office. </span><span>and his story will correctly be that we weren’t honest with him in the end about still wanting to do the for profit</span><span> </span><span>just without him.</span></p><p><span>[...]</span></p><p><span>he was like, </span><span>ok. fundraising is super hard. i’ve worked hard on gates and he didn’t even stop by office. dustin donated but doesn’t even show up personally. that’s how much these people care about this. didn’t expect to be 70% of the cash contributions. thought I’d be one piece. there are all these names on the website and they haven’t contributed. reality check, no one’s gonna give you this amount of money, when they see the $10B they’re going to run to the hills.</span></p><p><span>one of the two of us is not based in reality.</span></p><p><span>but he was super supportive of us trying, and said, go ahead, I’m happy with anyone (even people who just want to get access to me), happy to give them any fancy title, diminish my own title, etc.. if you can do it then i want to learn from you. I’m very good at getting people to part with their money, i could raise $lb for tesla in a week and have you seen that company’s financials?</span></p><p><span>anyway, definitely the best this meeting could have gone. </span><span>we now have a focus, a goal, and if we accomplish it, then we’ll really have shown him that we can outperform him even at something he’s great at. if we fail, well, we’ll deal with it then.</span></p><p><span>btw another realization from this is that </span><span>it’d be wrong to steal the non-profit from him. to convert to a b-corp without him. that’d be pretty morally bankrupt.</span><span> and he’s really not an idiot.</span></p></div><!--/$--><!--$--><div><p><span>purple</span><span> = </span><i><span>Greg’s notes on what Elon said</span></i><span><br></span><span>blue</span><span> </span><i><span>= quote shown in Elon’s court filing<br></span></i><span>red</span><span> </span><i><span>= emphasis added</span></i></p></div><!--/$--></div><p><span>In this entry, Greg and Ilya were still considering Elon’s demand that they “commit” to the non-profit by accepting his terms—something that, again, </span><b><span>never happened</span></b><span>. There was a chance that Elon would resume funding if they agreed to his conditions; there was a chance he’d resign to go create an AGI competitor within Tesla. Greg and Ilya felt that it’d be deceptive to accept Elon’s terms and then later create a for-profit without his approval. So they were nervous that, by accepting, they’d get stuck in a structure that was unable to raise sufficient capital while Elon left to pursue his own AGI project at Tesla. </span><b><span>That’s why they decided not to accept his proposal</span></b><span>. No one ever lied to Elon; no one ever told him they’d accepted his terms when they hadn’t.</span></p><p><span>In early November, we privately considered removing Elon from our board. We didn’t want to merge OpenAI into Tesla as he’d suggested, and he seemed intent on starting a competitor there regardless of what we did. Elon’s departure from OpenAI would have made it easier to figure out some structure for raising capital because it would have removed the impasse caused by his need for absolute control.</span></p><p><span>Still, though we felt Elon’s departure would have facilitated pursuit of the mission, we didn’t remove him. We kept trying to find a path forward with him because we thought that was the moral thing to do (per the same journal entry: “</span><b><span>Ilya feeling like we morally should not be kicking elon out, and should be trying to make the non-profit work and convince him to stay</span></b><span>”). We decided to try fundraising in the non-profit for a time to see what was achievable. We said that we’d need to eventually raise $10B, which Elon said seemed totally impossible. It was clear we’d need a long-term solution other than remaining solely a non-profit indefinitely.</span></p><div id=\"what-happened-next\"><p></p><h2><span>What happened next</span></h2><p></p></div><p><span>Over the next few months, we worked on fundraising and brainstorming ideas to obtain the next level of funding necessary to pursue and achieve the mission. In mid-January 2018, Elon congratulated us on a successful fundraise, agreed we should do an initial coin offering (“ICO”) to raise $10B—which would involve a for-profit subsidiary—and told us that we'd solved the long-term funding problem. By the end of January, however, he told us he no longer supported the ICO (which we’d soured on too by then) and that OpenAI was “on a path of certain failure relative to Google.”</span></p><p><span>By February 2018, Elon had decided that OpenAI would not be able to raise sufficient funding. That month, he quit even though we </span><a href=\"https://openai.com/index/elon-musk-wanted-an-openai-for-profit/#january-2018-elon-said-openai-was-on-a-path-for-certain-failure-unless-we-merged-into-tesla\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>told him</span></u>⁠</a><span> that we’d “</span><b><span>been working on a fundraising structure that does not rely on a public offering, and we will be curious to hear your feedback</span></b><span>.” On Elon’s way out, he said that he supported us pursuing the path we saw to raising billions of dollars—he just didn’t think we could succeed and he would instead focus on building AGI at Tesla for that reason.</span></p><p><span>For a time, the split with Elon seemed amicable. Shivon Zilis joined our board and helped us navigate Elon’s moods when, on occasion, he lashed out. But then Elon prepared to launch xAI and Shivon stepped off our board. Elon began the campaign of harassment that he’s waging now, with relentless public attacks and various lawsuits, as he’s tried to gain competitive ground for xAI.</span></p><p><span>While there’s a long way to go, we’ve made much more progress than Elon thought possible—including getting the OpenAI non-profit, now called the </span><a href=\"https://openai.com/foundation/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>OpenAI Foundation</span></u>⁠</a><span>, on track to become the best resourced non-profit in history. We’re grateful for the many users and partners who work with us to collectively advance our mission of ensuring AGI benefits all of humanity.</span></p></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/3yR9T1QSWtgPPAMi1IUied/4cef549a8dbd7a35df0786eb7294a202/OAI_Court_Filing_Hero_16x9_v2.png?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/index/introducing-chatgpt-go",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/introducing-chatgpt-go",
    "title": "Introducing ChatGPT Go, now available worldwide",
    "publishedAt": "Fri, 16 Jan 2026 00:00:00 GMT",
    "fetchedAt": "2026-01-25T19:08:04.311Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div id=\"main\" tabindex=\"-1\"><span aria-live=\"polite\" aria-atomic=\"true\">OpenAI</span><nav inert=\"\"></nav><article><div><p><span>In August 2025, we introduced ChatGPT Go in India as a low-cost subscription designed to expand access to ChatGPT’s most popular features and help more people use advanced AI in their daily life. Since then, ChatGPT Go has rolled out to 170 additional countries, making it our fastest growing plan and among the most affordable AI subscription globally. </span></p><p><span>In markets where Go has been available, we’ve seen strong adoption and regular everyday use for tasks like writing, learning, image creation, and problem-solving. This early momentum helped inform our decision to make ChatGPT Go available globally. </span></p><p><span>Starting today, ChatGPT Go is rolling out everywhere ChatGPT is available. In the US, Go is available for $8 per month.</span></p><p><span>With this launch, ChatGPT now offers three subscription tiers globally:</span></p><div><ul><li><span>ChatGPT Go at $8 USD/month*</span></li><li><span>ChatGPT Plus at $20 USD/month</span></li><li><span>ChatGPT Pro at $200 USD/month</span></li></ul></div><p><sup><span>*US price displayed. Go pricing is localized in some markets.</span></sup></p><div id=\"what-you-get-with-chatgpt-go\"><p></p><h2><span>What you get with ChatGPT Go</span></h2><p></p></div><p><span>ChatGPT Go is designed for people who want expanded access to our latest model, GPT‑5.2 Instant, at a lower price point—more messages, more uploads, and more image creation. With ChatGPT Go, you get:</span></p><div><ul><li><span>10x more messages, file uploads and image creation than the free tier, so you can keep chatting with no limits on GPT‑5.2 Instant.</span></li><li><span>Longer memory and context window, so ChatGPT can remember more helpful details about you over time.</span></li></ul></div><p><span>This now sits alongside our two existing consumer subscription plans: ChatGPT Plus and ChatGPT Pro.</span></p><p><span>ChatGPT Plus is designed for work that requires deeper reasoning—like writing and editing documents, learning and research, or data analysis. It offers expanded access to our most advanced models, including GPT‑5.2 Thinking, along with the flexibility to choose legacy models and use our coding agent, Codex. Compared to Go, Plus includes higher limits for messages, file uploads, memory, and context, so ChatGPT can remember more detail from past conversations and support longer, more continuous workflows.</span></p><p><span>ChatGPT Pro is built for AI power users pushing the limits of advanced intelligence. It offers full access to our most powerful model, GPT‑5.2 Pro, along with maximum memory and context, and early previews of our newest features.</span></p><div id=\"supporting-accessibility-with-ads\"><p></p><h2><span>Supporting accessibility with ads</span></h2><p></p></div><p><span>We plan to begin testing ads in the free tier and ChatGPT Go in the US soon. Ads support our commitment to making AI accessible to everyone by helping us keep ChatGPT available at free and affordable price points.</span></p><p><span>ChatGPT Plus, Pro, Business and Enterprise will remain ad-free.</span></p><p><span>Read more about how we plan to introduce ads </span><a href=\"https://openai.com/index/our-approach-to-advertising-and-expanding-access/\" target=\"_blank\" rel=\"noopener noreferrer\"><span>here</span>⁠</a><span>.</span></p><div id=\"plan-details\"><p></p><h2><span>Plan details</span></h2><p></p></div></div><section id=\"citations\" data-testid=\"citations\"><ul><li><a href=\"https://openai.com/news/?tags=2026\" target=\"_blank\" rel=\"noopener noreferrer\">2026</a></li></ul></section></article></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/3zF5sZPzDdth82KtAetQeH/181e176a9b9ea8f3d2f5325dac534494/OAI_Go_Blog_OpenGraph_1200x630.png?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/index/our-approach-to-advertising-and-expanding-access",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/our-approach-to-advertising-and-expanding-access",
    "title": "Our approach to advertising and expanding access to ChatGPT",
    "publishedAt": "Fri, 16 Jan 2026 00:00:00 GMT",
    "fetchedAt": "2026-01-25T19:08:04.428Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div id=\"main\" tabindex=\"-1\"><span aria-live=\"polite\" aria-atomic=\"true\">OpenAI</span><article><div><p><span>AI is reaching a point where everyone can have a personal super-assistant that helps them learn and do almost anything. Who gets access to that level of intelligence will shape whether AI expands opportunity or reinforces the same divides.</span></p><p><span>We’ve been working to make powerful AI accessible to everyone through our free product and low-cost subscription tier, ChatGPT Go, which has launched in 171 countries since August. Today we’re </span><a href=\"https://openai.com/index/introducing-chatgpt-go/\" target=\"_blank\" rel=\"noopener noreferrer\"><span>bringing Go to the U.S. and everywhere ChatGPT is available</span>⁠</a><span>, giving people expanded access to messaging, image creation, file uploads and memory for $8 USD/month. In the coming weeks, we’re also planning to start testing ads in the U.S. for the free and Go tiers, so more people can benefit from our tools with fewer usage limits or without having to pay. Plus, Pro, Business, and Enterprise subscriptions will not include ads.</span></p><p><span>People trust ChatGPT for many important and personal tasks, so as we introduce ads, it’s crucial we preserve what makes ChatGPT valuable in the first place. That means you need to trust that ChatGPT’s responses are driven by what’s objectively useful, never by advertising. You need to know that your data and conversations are protected and never sold to advertisers. And we need to keep a high bar and give you control over your experience so you see truly relevant, high-quality ads—and can turn off personalization if you want. </span></p><p><span>Given that, we want to be clear about the principles that guide our approach to advertising:</span></p><div id=\"our-ads-principles\"><p></p><h2><span>Our ads principles</span></h2><p></p></div><div><ul><li><b><span>Mission alignment: </span></b><span>Our mission is to ensure AGI benefits all of humanity; our pursuit of advertising is always in support of that mission and making AI more accessible.</span></li><li><b><span>Answer independence: </span></b><span>Ads do not influence the answers ChatGPT gives you. Answers are optimized based on what's most helpful to you. Ads are always separate and clearly labeled.</span></li><li><b><span>Conversation privacy: </span></b><span>We keep your conversations with ChatGPT private from advertisers, and we never sell your data to advertisers.</span></li><li><b><span>Choice and control: </span></b><span>You control how your data is used. You can turn off personalization, and you can clear the data used for ads at any time. We’ll always offer a way to not see ads in ChatGPT, including a paid tier that’s ad-free.</span></li><li><b><span>Long-term value: </span></b><span>We do not optimize for time spent in ChatGPT. We prioritize user trust and user experience over revenue.</span></li></ul></div><p><span>We’re not launching ads yet, but we do plan to start testing in the coming weeks for logged in adults in the U.S. on the free and Go tiers. To start, we plan to test ads at the bottom of answers in ChatGPT when there’s a relevant sponsored product or service based on your current conversation. Ads will be clearly labeled and separated from the organic answer. You’ll be able to learn more about why you’re seeing that ad, or dismiss any ad and tell us why. During our test, we will not show ads in accounts where the user tells us or we predict that they are under 18, and ads are not eligible to appear near sensitive or regulated topics like health, mental health or politics.</span></p><p><span>Here’s an example of what the first ad formats we plan to test could look like: </span></p><div><p><img alt=\"Mobile phone screen showing a ChatGPT response with simple, authentic Mexican dinner party recipes, followed by a clearly labeled sponsored product recommendation from Harvest Groceries for a hot sauce item, displayed against a soft blue gradient background.\" data-nosnippet=\"true\" loading=\"lazy\" width=\"3840\" height=\"2160\" decoding=\"async\" data-nimg=\"1\" sizes=\"(min-width: 1728px) 1728px, 100vw\" srcset=\"https://images.ctfassets.net/kftzwdyauwt9/73QmMtFD4PrKmQkzxO5ErF/2c226c43ba3658e8dab69b1299aa0ebf/OAI_Ad_Blog_Inline-AdMock2_16x9__1_.png?w=640&amp;q=90&amp;fm=webp 640w, https://images.ctfassets.net/kftzwdyauwt9/73QmMtFD4PrKmQkzxO5ErF/2c226c43ba3658e8dab69b1299aa0ebf/OAI_Ad_Blog_Inline-AdMock2_16x9__1_.png?w=750&amp;q=90&amp;fm=webp 750w, https://images.ctfassets.net/kftzwdyauwt9/73QmMtFD4PrKmQkzxO5ErF/2c226c43ba3658e8dab69b1299aa0ebf/OAI_Ad_Blog_Inline-AdMock2_16x9__1_.png?w=828&amp;q=90&amp;fm=webp 828w, https://images.ctfassets.net/kftzwdyauwt9/73QmMtFD4PrKmQkzxO5ErF/2c226c43ba3658e8dab69b1299aa0ebf/OAI_Ad_Blog_Inline-AdMock2_16x9__1_.png?w=1080&amp;q=90&amp;fm=webp 1080w, https://images.ctfassets.net/kftzwdyauwt9/73QmMtFD4PrKmQkzxO5ErF/2c226c43ba3658e8dab69b1299aa0ebf/OAI_Ad_Blog_Inline-AdMock2_16x9__1_.png?w=1200&amp;q=90&amp;fm=webp 1200w, https://images.ctfassets.net/kftzwdyauwt9/73QmMtFD4PrKmQkzxO5ErF/2c226c43ba3658e8dab69b1299aa0ebf/OAI_Ad_Blog_Inline-AdMock2_16x9__1_.png?w=1920&amp;q=90&amp;fm=webp 1920w, https://images.ctfassets.net/kftzwdyauwt9/73QmMtFD4PrKmQkzxO5ErF/2c226c43ba3658e8dab69b1299aa0ebf/OAI_Ad_Blog_Inline-AdMock2_16x9__1_.png?w=2048&amp;q=90&amp;fm=webp 2048w, https://images.ctfassets.net/kftzwdyauwt9/73QmMtFD4PrKmQkzxO5ErF/2c226c43ba3658e8dab69b1299aa0ebf/OAI_Ad_Blog_Inline-AdMock2_16x9__1_.png?w=3840&amp;q=90&amp;fm=webp 3840w\" src=\"https://images.ctfassets.net/kftzwdyauwt9/73QmMtFD4PrKmQkzxO5ErF/2c226c43ba3658e8dab69b1299aa0ebf/OAI_Ad_Blog_Inline-AdMock2_16x9__1_.png?w=3840&amp;q=90&amp;fm=webp\" style=\"max-width: 100%; height: auto; border-radius: 1rem; margin: 2rem 0px;\"></p></div><p><span>The best ads are useful, entertaining, and help people discover new products and services. Given what AI can do, we're excited to develop new experiences over time that people find more helpful and relevant than any other ads. Conversational interfaces create possibilities for people to go beyond static messages and links. For example, soon you might see an ad and be able to directly ask the questions you need to make a purchase decision. </span></p><div><p><img alt=\"Two mobile phone screens showing a ChatGPT conversation about traveling to Santa Fe, New Mexico, with an informational travel response on the left and a clearly labeled sponsored listing for “Pueblo &amp; Pine” desert cottages, and a follow-up chat view with a text input on the right, displayed against a soft blue gradient background.\" data-nosnippet=\"true\" loading=\"lazy\" width=\"3840\" height=\"2160\" decoding=\"async\" data-nimg=\"1\" sizes=\"(min-width: 1728px) 1728px, 100vw\" srcset=\"https://images.ctfassets.net/kftzwdyauwt9/1oiSiUkLymK0xlEOWcJubw/d7e078d14fb84534abc115d16223c5ca/OAI_Ad_Blog_Inline-AdMock1_16x9.png?w=640&amp;q=90&amp;fm=webp 640w, https://images.ctfassets.net/kftzwdyauwt9/1oiSiUkLymK0xlEOWcJubw/d7e078d14fb84534abc115d16223c5ca/OAI_Ad_Blog_Inline-AdMock1_16x9.png?w=750&amp;q=90&amp;fm=webp 750w, https://images.ctfassets.net/kftzwdyauwt9/1oiSiUkLymK0xlEOWcJubw/d7e078d14fb84534abc115d16223c5ca/OAI_Ad_Blog_Inline-AdMock1_16x9.png?w=828&amp;q=90&amp;fm=webp 828w, https://images.ctfassets.net/kftzwdyauwt9/1oiSiUkLymK0xlEOWcJubw/d7e078d14fb84534abc115d16223c5ca/OAI_Ad_Blog_Inline-AdMock1_16x9.png?w=1080&amp;q=90&amp;fm=webp 1080w, https://images.ctfassets.net/kftzwdyauwt9/1oiSiUkLymK0xlEOWcJubw/d7e078d14fb84534abc115d16223c5ca/OAI_Ad_Blog_Inline-AdMock1_16x9.png?w=1200&amp;q=90&amp;fm=webp 1200w, https://images.ctfassets.net/kftzwdyauwt9/1oiSiUkLymK0xlEOWcJubw/d7e078d14fb84534abc115d16223c5ca/OAI_Ad_Blog_Inline-AdMock1_16x9.png?w=1920&amp;q=90&amp;fm=webp 1920w, https://images.ctfassets.net/kftzwdyauwt9/1oiSiUkLymK0xlEOWcJubw/d7e078d14fb84534abc115d16223c5ca/OAI_Ad_Blog_Inline-AdMock1_16x9.png?w=2048&amp;q=90&amp;fm=webp 2048w, https://images.ctfassets.net/kftzwdyauwt9/1oiSiUkLymK0xlEOWcJubw/d7e078d14fb84534abc115d16223c5ca/OAI_Ad_Blog_Inline-AdMock1_16x9.png?w=3840&amp;q=90&amp;fm=webp 3840w\" src=\"https://images.ctfassets.net/kftzwdyauwt9/1oiSiUkLymK0xlEOWcJubw/d7e078d14fb84534abc115d16223c5ca/OAI_Ad_Blog_Inline-AdMock1_16x9.png?w=3840&amp;q=90&amp;fm=webp\" style=\"max-width: 100%; height: auto; border-radius: 1rem; margin: 2rem 0px;\"></p></div><p><span>Ads also can be transformative for small businesses and emerging brands trying to compete. AI tools level the playing field even further, allowing anyone to create high-quality experiences that help people discover options they might never have found otherwise.</span></p><p><span>We’ll learn from feedback and refine how ads show up over time, but our commitment to putting users first and maintaining trust won’t change. By starting our ad platform from the ground up with these principles in place, we can align our incentives with what people want from ChatGPT. Our long-term focus remains on building products that millions of people and businesses find valuable enough to pay for. Our enterprise and subscription businesses are already strong, and we believe in having a diverse revenue model where ads can play a part in making intelligence more accessible to everyone.</span></p><p><span>Once we begin testing our first ad formats in the coming weeks and months, we look forward to getting people's feedback and ensuring that ads can support broad access to AI and keep the trust that makes ChatGPT valuable.</span></p></div><section id=\"citations\" data-testid=\"citations\"><ul><li><a href=\"https://openai.com/news/?tags=2026\" target=\"_blank\" rel=\"noopener noreferrer\">2026</a></li><li><a href=\"https://openai.com/news/?tags=chatgpt\" target=\"_blank\" rel=\"noopener noreferrer\">ChatGPT</a></li></ul></section></article></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/5s44WB2F1IO0YAfgRqAiBa/21d496f2d34f61eeef89b59c8129db19/OAI_Ads_Blog_OpenGraph_1200x630.png?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/index/cerebras-partnership",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/cerebras-partnership",
    "title": "OpenAI partners with Cerebras  ",
    "publishedAt": "Wed, 14 Jan 2026 14:00:00 GMT",
    "fetchedAt": "2026-01-25T19:08:04.526Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div id=\"main\" tabindex=\"-1\"><span aria-live=\"polite\" aria-atomic=\"true\">OpenAI</span><article><div><p>OpenAI is partnering with Cerebras to add 750MW of ultra low-latency AI compute to our platform. </p></div><div><p><span>Cerebras builds purpose-built AI systems to accelerate long outputs from AI models. Its unique speed comes from putting massive compute, memory, and bandwidth together on a single giant chip and eliminating the bottlenecks that slow inference on conventional hardware.&nbsp;</span></p><p><span>&nbsp;Integrating Cerebras into our mix of compute solutions is all about making our AI respond much faster. When you ask a hard question, generate code, create an image, or run an AI agent, there is a loop happening behind the scenes: you send a request, the model thinks, and it sends something back. When AI responds in real time, users do more with it, stay longer, and run higher-value workloads.</span></p><p><span>We will integrate this low-latency capacity into our inference stack in phases, expanding across workloads.&nbsp;&nbsp;</span></p><p><span>“OpenAI’s compute strategy is to build a resilient portfolio that matches the right systems to the right workloads. Cerebras adds a dedicated low-latency inference solution to our platform. That means faster responses, more natural interactions, and a stronger foundation to scale real-time AI to many more people,” said Sachin Katti of OpenAI.</span></p><p><span>“We are delighted to partner with OpenAI, bringing the world’s leading AI models to the world’s fastest AI processor. Just as broadband transformed the internet, real-time inference will transform AI, enabling entirely new ways to build and interact with AI models,” said Andrew Feldman, co-founder and CEO of Cerebras.&nbsp;</span></p><p><span>The capacity will come online in multiple tranches through 2028.</span></p></div></article></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/3AKrxHQZGWRq0XSFr3Tz8y/e1b2721e08ac271ec8c8f9b595bbe350/OpenAI_Cerebras__1_.png?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/index/zenken",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/zenken",
    "title": "Zenken boosts a lean sales team with ChatGPT Enterprise",
    "publishedAt": "Tue, 13 Jan 2026 16:00:00 GMT",
    "fetchedAt": "2026-01-25T19:08:04.203Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div><p><span>Zenken combines GPT‑5, custom GPTs, image generation, and the latest OpenAI models and tools to accelerate both of its core businesses: web marketing and the fast growing overseas human resources business. As one of the first companies in Japan to roll out ChatGPT Enterprise across the organization, Zenken is putting an AI first approach into practice and seeing clear business impact.</span></p><p><span>Today Zenken reports:</span></p><div><ul><li><span>More than 90% weekly active usage of ChatGPT Enterprise</span></li><li><span>Average time savings of 30 to 50% across knowledge work tasks</span></li><li><span>5 to 15 additional hours per employee every month, reinvested in higher value work</span></li><li><span>50 million yen in annual outsourcing cost savings compared with the previous year</span></li></ul></div><div id=\"deciding-to-adopt-chatgpt-enterprise-that-meets-twelve-critical-requirements\"><p></p><h2><span>Deciding to adopt ChatGPT Enterprise that meets twelve critical requirements</span></h2><p></p></div><p><span>Before adopting ChatGPT Enterprise, Zenken relied on manual processes for a wide range of knowledge tasks. Employees spent large amounts of time on research, summarization, translation, and content creation. Sales teams also faced long preparation times for client meetings, which reduced the number and quality of customer conversations.</span></p><p><span>To address these issues, Zenken decided to introduce AI in a structured and secure way. Yuji Okada, Manager of the Corporate Planning Department in the Administration Division, explains that when they evaluated potential solutions, they “focused on twelve capabilities required for our business, such as security and advanced support for complex thinking,” and recalls that “ChatGPT Enterprise was the only solution to meet all of these conditions.” He notes, \"Because we deal with client and sensitive internal information, preventing data leaks is non-negotiable. ChatGPT Enterprise guarantees that our data won't be used to train its AI. This security feature gave us the confidence to safely handle confidential data.\"</span></p><p><span>The availability of reasoning models was also a decisive reason for choosing ChatGPT Enterprise. In Zenken’s core web marketing business, teams need to analyze clients’ business challenges in depth and propose strategic solutions. The reasoning model released by OpenAI in 2024 provides the advanced support for complex thinking that Zenken was looking for and has further accelerated the company’s use of AI. Okada explains, “The reasoning model goes beyond simply providing information and supports management level decision making in areas such as market analysis, competitive strategy, and evaluation of new business opportunities.”</span></p><p><span>Today, the reasoning model improves the quality of strategy planning and analysis across teams and is also used to examine Zenken’s own management issues and new challenges from a strategic perspective. It has become a key driver of Zenken’s business growth.</span></p><div id=\"transforming-sales-activities-with-ai-supported-workflows\"><p></p><h2><span>Transforming sales activities with AI supported workflows</span></h2><p></p></div><p><span>The impact of ChatGPT Enterprise is especially visible in sales. Before using ChatGPT Enterprise, the sales team had to spend large amounts of time on preparation work such as researching prospects, creating proposal materials, and writing sales emails. Okada recalls, “Even before we could think about increasing the number of clients we approached, our people were already losing a lot of time on preparation. Because they had to respond to inquiries and create proposal documents, the time they could actually spend with customers was limited, and sometimes we missed out on opportunities.” Writing each email also took time, which created a natural limit on how many prospects a salesperson could reach in a single day.</span></p><p><span>By rolling out ChatGPT Enterprise across the company, Zenken has significantly improved the quality of its sales activities. The table below compares the sales process before and after ChatGPT at each phase.</span></p><div><table><tbody><tr><th></th><th><p><span>Before ChatGPT</span></p></th><th><p><span>With ChatGPT</span></p></th></tr><tr><td><p><span>Preparation phase</span></p></td><td><p><span>Gather information manually&nbsp;</span></p></td><td><p><b><span>Use ChatGPT for deeper industry and customer analysis </span></b></p></td></tr><tr><td><p><span>Discovery phase</span></p></td><td><p><span>One way, checklist style questioning </span></p></td><td><p><b><span>Two way, consultative conversations </span></b></p></td></tr><tr><td><p><span>Meeting phase</span></p></td><td><p><span>When questions arise, answers are often deferred to a later follow up</span></p></td><td><p><b><span>Ask ChatGPT during the meeting and respond on the spot </span></b></p></td></tr><tr><td><p><span>Proposal phase</span></p></td><td><p><span>Standard product centric proposals focused on specs and features&nbsp;</span></p></td><td><p><b><span>Personalized proposals based on customer insights</span></b></p></td></tr></tbody></table></div><p><span>As a result, Zenken has seen clear gains in sales performance:</span></p><div><ul><li><span>Proposals passing initial review up 15 to 20%</span></li><li><span>Win rate for new deals up 5 to 10%</span></li><li><span>Approval rate for final proposals up about 30%</span></li></ul></div><p><span>“ChatGPT helps us shorten the time required for research and preparation, while also making our conversations with clients smoother,” explains Okada.</span></p><div id=\"strengthening-international-communication\"><p></p><h2><span>Strengthening international communication</span></h2><p></p></div><p><span>ChatGPT Enterprise has also become essential to Zenken’s fast growing overseas human resources business. Because most employees are native Japanese speakers, the company previously had to devote significant time and budget to translating job postings, contracts, and other documents for overseas candidates. Okada recalls, “When we needed to communicate in multiple languages including English, conventional translation tools often failed to carry over the right context and nuance, which made some international communication quite challenging.”</span></p><p><span>After implementing ChatGPT Enterprise, the team was able to accurately translate a wide range of documents into English and other languages. This allowed them to cut outsourcing costs while significantly increasing translation speed. “Even with a smaller team, we have been able to maintain an organization that continues to drive revenue growth,” says Okada.</span></p><p><span>Employees are also using ChatGPT in languages beyond English to gather information from news sites, technical articles, and other sources that are important for the business. This makes it easier to design new services and business initiatives with global expansion in mind and enables more people at Zenken to participate directly in cross border work than ever before.</span></p><div id=\"shifting-from-routine-tasks-to-creative-high-value-work\"><p></p><h2><span>Shifting from routine tasks to creative, high value work</span></h2><p></p></div><p><span>ChatGPT Enterprise is reshaping how day to day work gets done at Zenken. Teams now use ChatGPT to generate first drafts of sales emails, proposals, marketing content, and internal documents in minutes, and overall productivity has roughly doubled across the organization. Work that was previously outsourced is increasingly handled in house, cutting annual outsourcing costs by around 50 million yen and improving margins. “Instead of being tied up in repetitive tasks, employees across the company now have more time to focus on the substance of their proposals,” says Okada.</span></p><p><span>Adoption is also strong at the individual level. Weekly active usage of ChatGPT Enterprise exceeds 90%, and employees send an average of about 900 messages per person each month. “It has become second nature for us to turn to ChatGPT first,” Okada explains. “We use ChatGPT to develop an initial hypothesis and then discuss it with our managers or colleagues. Working this way has greatly reduced the time people spend feeling stuck before they talk to others or move forward.”</span></p><p><span>For Zenken, ChatGPT Enterprise is more than a tool. In Okada’s words, it has become a partner that is changing how employees think and work. The company now sees ChatGPT Enterprise as a core platform that supports everything from day to day efficiency and strategic planning to talent development and, ultimately, company wide transformation.</span></p></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/19Sz7JHI83sYEbpUVQvOMn/6ff976b42129bf31e00f6bc71f7d04fd/oai_Zenken_SEO.png?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/index/stargate-sb-energy-partnership",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/stargate-sb-energy-partnership",
    "title": "OpenAI and SoftBank Group partner with SB Energy",
    "publishedAt": "Fri, 09 Jan 2026 11:00:00 GMT",
    "fetchedAt": "2026-01-25T19:08:04.846Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div id=\"main\" tabindex=\"-1\"><span aria-live=\"polite\" aria-atomic=\"true\">OpenAI</span><article><div><div><ul><li><i><span>SoftBank Group and OpenAI invest $1 billion in SB Energy to support its growth as a leading development and execution partner for data center campuses&nbsp;</span></i></li><li><i><span>OpenAI signs 1.2 GW data center lease for initial data center buildout</span></i></li><li><i><span>SB Energy will become a major customer of OpenAI, leveraging its APIs and deploying ChatGPT for its employees</span></i></li><li><i><span>SB Energy additionally secured $800 million of Redeemable Preferred Equity from Ares to further support the company’s growth</span></i></li></ul></div><p><b><span>Redwood City, CA, Jan. 9, 2026</span></b><span>—</span><a href=\"https://sbenergy.com/\" target=\"_blank\" rel=\"noopener noreferrer\"><span>SB Energy</span>⁠<span>(opens in a new window)</span></a><span>, a SoftBank Group company, announced today a strategic partnership with OpenAI as part of </span><a href=\"https://group.softbank/en/news/press/20250924\" target=\"_blank\" rel=\"noopener noreferrer\"><span>Stargate</span>⁠<span>(opens in a new window)</span></a><span>, marking a significant step forward in the build out of next-generation artificial intelligence (AI) and energy infrastructure in the United States. The investment builds on the $500 billion Stargate commitment announced in January at the White House.</span></p><p><span>To support the partnership and as demand for AI compute accelerates, OpenAI and SoftBank Group are each investing $500 million into SB Energy. OpenAI has also selected SBE to build and operate its </span><a href=\"https://openai.com/index/five-new-stargate-sites/\" target=\"_blank\" rel=\"noopener noreferrer\"><span>previously-announced</span></a><span> 1.2 GW data center site in Milam County. The equity funding supports SB Energy’s growth as a leading development and execution partner for data center campuses and associated energy infrastructure. SB Energy is currently developing several multi-gigawatt data center campuses, with initial facilities under construction and expected to enter service starting in 2026.&nbsp;</span></p><p><b><span>OpenAI co-founder and President Greg Brockman</span></b><span> said, “Partnering with SB Energy brings together their strength in data center infrastructure and energy development and OpenAI’s deep domain expertise in data center engineering. The result is a fast, reliable way to scale compute through large, highly optimized AI data centers.”</span></p><p><b><span>SB Energy co-CEO Rich Hossfeld</span></b><span> said, “SB Energy’s strategic partnership with OpenAI accelerates our delivery of advanced AI data center campuses and associated energy infrastructure at the scale required to advance Stargate and secure America’s AI future. We are grateful for our longstanding sponsor SoftBank Group and new partner OpenAI for their investment in our platform, our team, and our long-term vision.”</span></p><p><span>As part of this transaction, OpenAI, SoftBank Group, and SB Energy have also formed a non-exclusive preferred partnership to develop a new model for data center builds that brings together OpenAI’s first-party data center design with SB Energy’s proven expertise in speed, cost discipline, and integrated energy delivery to deliver purpose-built AI infrastructure at scale. With each project, SB Energy and OpenAI will invest in communities through well-paying jobs, workforce development, and grid modernization to deliver durable economic growth for partner communities.</span></p><p><span>The Milam County Data Center will create thousands of construction jobs. OpenAI and SB Energy have designed the data center to minimize water usage, and plan to build new generation to support the Milam County Data Center’s energy needs and protect Texas ratepayers.</span></p></div><section id=\"citations\" data-testid=\"citations\"><ul><li><a href=\"https://openai.com/news/?tags=partnerships\" target=\"_blank\" rel=\"noopener noreferrer\">Partnerships</a></li><li><a href=\"https://openai.com/news/?tags=2026\" target=\"_blank\" rel=\"noopener noreferrer\">2026</a></li></ul></section></article></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/5pUtaUecrqepOFROa4AHBp/195895c2b1318d9b7d16be007a480921/OpenAI_and_SoftBank_Group_partner_with_SB_Energy.png?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/index/datadog",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/datadog",
    "title": "Datadog uses Codex for system-level code review",
    "publishedAt": "Fri, 09 Jan 2026 00:00:00 GMT",
    "fetchedAt": "2026-01-25T19:08:04.744Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div><p><a href=\"https://www.datadoghq.com/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>Datadog</span></u>⁠<span>(opens in a new window)</span></a><span> runs one of the world’s most widely-used observability platforms, helping companies monitor, troubleshoot, and secure complex distributed systems. When something breaks, customers depend on Datadog to surface issues fast, which means reliability has to be built in long before code ever reaches production.</span></p><p><span>For Datadog’s engineering teams, that makes code review a high-stakes moment. It’s not just about catching mistakes, but about understanding how changes ripple through interconnected systems—an area where traditional static analysis and rule-based tools often fall short.</span></p><p><span>To meet this challenge, Datadog’s AI Development Experience (AI DevX) team turned to Codex, the coding agent from OpenAI, which brings system-level reasoning into code review and surfaces risks humans can’t easily see at scale.</span></p><p><span>“Time savings are real and important,” says Brad Carter, who leads Datadog’s AI DevX team. “But preventing incidents is far more compelling at our scale.”</span></p><div id=\"bringing-system-level-context-to-code-review-with-codex\"><p></p><h2><span>Bringing system-level context to code review with Codex</span></h2><p></p></div><p><span>Effective code review at Datadog traditionally relied heavily on senior engineers—the people who understand the codebase, its history, and the architectural tradeoffs well enough to spot systemic risk.&nbsp;</span></p><p><span>But that kind of deep context is hard to scale, and early AI code review tools didn’t solve this problem; many behaved like advanced linters, flagging surface-level issues while missing broader system nuances. Datadog’s engineers often found the suggestions too shallow or too noisy, and ignored them.</span></p><p><span>Datadog began piloting Codex, the coding agent from OpenAI, by integrating it into the live development workflows. In one of the company’s largest and most heavily used repositories, every pull request was automatically reviewed by Codex. Engineers reacted to comments from Codex with thumbs up or down and shared informal feedback across teams. Many noted that the Codex feedback was worth reading, unlike previous tools that produced noisy or shallow suggestions.</span></p><div id=\"validating-ai-review-against-real-incidents\"><p></p><h2><span>Validating AI review against real incidents</span></h2><p></p></div><p><span>To test whether AI‑assisted review could do more than point out style issues, Datadog built an incident replay harness.</span></p><p><span>Instead of using hypothetical scenarios, the team went back to historical incidents. They reconstructed pull requests that had contributed to incidents, ran Codex against each one as if it were part of the original review, then asked the engineers who owned those incidents whether feedback from Codex would have made a difference.</span></p><p><span>The result: Codex found more than 10 cases, or roughly </span><b><span>22%</span></b><span> </span><b><span>of the incidents </span></b><span>that Datadog examined, where engineers confirmed that the feedback Codex provided would have made a difference—more than any other tool evaluated.</span></p><p><span>Because these pull requests had already passed code review, the replay test showed that Codex surfaced risks reviewers hadn’t seen at the time, complementing human judgment rather than replacing it.</span></p><div id=\"delivering-consistent-high-signal-feedback\"><p></p><h2><span>Delivering consistent, high-signal feedback</span></h2><p></p></div><p><span>Datadog’s analysis showed that Codex consistently flagged issues that aren’t obvious from the immediate diff alone and can’t be caught by deterministic rules.</span></p><p><span>Engineers described Codex comments as more than “bot noise”:</span></p><div><ul><li><span>Codex pointed out interactions with modules not touched in the diff</span></li><li><span>It identified missing test coverage in areas of cross‑service coupling</span></li><li><span>It highlighted API contract changes that carried downstream risk</span></li></ul></div><div><blockquote>“For me, a Codex comment feels like the smartest engineer I’ve worked with and who has infinite time to find bugs. It sees connections my brain doesn’t hold all at once.”</blockquote><p>—Brad Carter, Engineering Manager at Datadog</p></div><p><span>That ability to connect review feedback to real reliability outcomes was what made Codex stand out in Datadog’s evaluation. Unlike static analysis tools, Codex compares the intent of the pull request with submitted code changes, reasoning over the entire codebase and dependencies to execute code and tests to validate behavior.</span></p><div><p><span>“It was the first one that actually seemed to consider the diff in the larger context of the program,” says Carter. “That was novel and eye‑opening.”</span></p><p>For many engineers, that shift changed how they engaged with AI review altogether. “I started treating Codex comments like real code review feedback,” says Ted Wexler, Senior Software Engineer at Datadog. “Not something I’d skim or ignore, but something worth paying attention to.”</p></div><div id=\"focusing-engineers-on-design-over-detection\"><p></p><h2><span>Focusing engineers on design over detection</span></h2><p></p></div><p><span>Following the evaluation, Datadog deployed Codex more broadly across its engineering workforce. Today </span><b><span>more than 1,000 engineers </span></b><span>use it regularly.&nbsp;</span></p><p><span>Feedback is largely surfaced organically rather than through formal in‑tool metrics. Engineers post to Slack about useful insights, constructive comments, and moments where Codex helped them think differently about a problem.</span></p><p><span>While time savings are significant, teams consistently pointed to a more meaningful shift in how work got done.&nbsp;</span></p><div><blockquote>“Codex changed my mind for what code review should be. It’s not about replicating our best human reviewers. It's about finding critical flaws and edge cases that humans struggle to see when reviewing changes in isolation.”</blockquote><p>—Brad Carter, Engineering Manager at Datadog</p></div><div id=\"redefining-code-review-around-risk-not-speed\"><p></p><h2><span>Redefining code review around risk, not speed</span></h2><p></p></div><p><span>The broader impact for Datadog was a change in how code review itself is defined. Rather than treating review as a checkpoint for catching errors or optimizing cycle time, the team now sees Codex as a core reliability system that acts as a partner:</span></p><div><ul><li><span>Surfacing risk beyond what individual reviewers can hold in context</span></li><li><span>Highlighting cross-module and cross-service interactions</span></li><li><span>Increasing confidence in shipping at scale</span></li><li><span>Allowing human reviewers to focus on architecture and design</span></li></ul></div><p><span>This shift aligns with how Datadog’s leaders frame engineering priorities, where reliability and trust matter as much as, if not more than, velocity.</span></p><p><span>“We are the platform companies rely on when everything else is breaking,” says Carter. “Preventing incidents strengthens the trust our customers place in us.”</span></p></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/619kruHqeZXsnNOyg336Ho/70558438f79acb321fb1b6cf96bded13/oai_datadog_SEO.png?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/index/openai-for-healthcare",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/openai-for-healthcare",
    "title": "OpenAI for Healthcare",
    "publishedAt": "Thu, 08 Jan 2026 12:00:00 GMT",
    "fetchedAt": "2026-01-25T19:08:07.274Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div><p><span>We’re introducing OpenAI for Healthcare, a set of products designed to help healthcare organizations deliver more consistent, high-quality care for patients—while supporting their HIPAA compliance requirements.&nbsp;</span></p><p><span>This includes </span><b><span>ChatGPT for Healthcare</span></b><span>, available starting today and already rolling out to leading institutions like AdventHealth, Baylor Scott &amp; White Health, Boston Children’s Hospital, Cedars-Sinai Medical Center, HCA Healthcare, Memorial Sloan Kettering Cancer Center, Stanford Medicine Children’s Health, and University of California, San Francisco (UCSF).</span></p><p><span>It also includes the </span><b><span>OpenAI API</span></b><span>, which powers much of today’s healthcare ecosystem. Thousands of organizations have configured it to support HIPAA-compliant use—such as Abridge, Ambience, and EliseAI.&nbsp;&nbsp;&nbsp;</span></p><p><span>Healthcare is under unprecedented strain. Demand is rising, clinicians are overwhelmed by administrative work, and critical medical knowledge is fragmented across countless sources. At the same time, AI adoption in healthcare is gaining momentum, driven by its potential to help address these challenges. Advances in models have significantly </span><a href=\"https://openai.com/index/healthbench/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>improved</span></u>⁠</a><span> AI’s ability to support real-world clinical and administrative work, like helping clinicians personalize care using the latest evidence. According to the </span><a href=\"https://www.ama-assn.org/system/files/physician-ai-sentiment-report.pdf\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>American Medical Association</span></u>⁠<span>(opens in a new window)</span></a><span>, physicians’ use of AI nearly doubled in a year. Yet many clinicians still have to rely on their own tools because their organizations aren’t adopting AI fast enough, often due to the constraints of regulated environments.</span></p><p><span>OpenAI for Healthcare helps close that gap by giving organizations a secure, enterprise-grade foundation for AI—so teams can use the same tools to deliver better, more reliable care, while supporting HIPAA compliance.</span></p><div id=\"chatgpt-for-healthcare\"><p></p><h2><span>ChatGPT for Healthcare</span></h2><p></p></div><p><span>ChatGPT for Healthcare is built to support the careful, evidence-based reasoning required in real patient care, while reducing administrative burden so teams can spend more time with patients. Organizations can bring clinicians, administrators, and researchers into a secure workspace with the controls they need to deploy AI securely and at scale.</span></p><p><span>Here’s what it includes:</span></p><div><ul><li><b><span>Models built for healthcare workflows:</span></b><span> High-quality responses for clinical, research, and operational work—powered by GPT‑5 models built for healthcare and evaluated through physician-led testing across benchmarks and real workflows, including </span><a href=\"https://openai.com/index/healthbench/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>HealthBench</span></u>⁠</a><span> and </span><a href=\"https://openai.com/index/gdpval/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>GDPval</span></u>⁠</a><span>.</span></li><li><b><span>Evidence retrieval with transparent citations:</span></b><span> Answers grounded in relevant medical sources—drawing from millions of peer-reviewed research studies, public health guidance, and clinical guidelines—with clear citations including titles, journals, and publication dates to support quick source-checking. This helps clinicians reason through cases with greater confidence, so patients get to the right diagnosis and treatment sooner.</span></li><li><b><span>Institutional policy and care pathway alignment:</span></b><span> Integrations with enterprise tools such as Microsoft SharePoint and other systems, so responses can incorporate an institution’s approved policies, pathway documents, and operational guidance to support consistent execution across teams and help ensure patients receive high-quality care.</span></li><li><b><span>Reusable templates to automate workflows:</span></b><span> Shared templates for common tasks like drafting discharge summaries, patient instructions, clinical letters, and prior authorization support. Clinical teams spend less time rewriting and searching, and patients have clearer next steps and smoother transitions of care.</span></li><li><b><span>Access management and governance:</span></b><span> A centralized workspace with role-based access controls and organization-wide user management through SAML SSO and SCIM. This gives healthcare organizations the governance and visibility they need to deploy AI across clinical, administrative, and research teams.</span></li><li><b><span>Data control and support for HIPAA compliance:</span></b><span> Patient data and PHI remain under an organization’s control, with options for data residency, audit logs, customer-managed encryption keys, and a Business Associate Agreement (BAA) with OpenAI to support HIPAA-compliant use. Content shared with ChatGPT for Healthcare is not used to train models.&nbsp;</span></li></ul></div><p><a href=\"https://openai.com/business-data/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>Learn more</span></u>⁠</a><span> about our enterprise-grade security, privacy, and compliance programs.&nbsp;</span></p><p><b><span>Supporting clinical and operational workflows: </span></b><span>In practice, teams use ChatGPT for Healthcare to synthesize medical evidence alongside institutional guidance and apply it to a patient’s specific context, draft clinical and administrative documentation, and adapt patient-facing education materials for readability and translation. This reduces time spent on admin, helps teams follow shared standards of care, and supports a better patient experience—while clinicians stay in charge.</span></p><div id=\"early-hospital-partners\"><p></p><h2><span>Early hospital partners</span></h2><p></p></div><p><span>Healthcare is among the fastest-growing </span><a href=\"https://openai.com/index/the-state-of-enterprise-ai-2025-report/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>enterprise markets</span></u>⁠</a><span> adopting AI, and hospitals and academic medical centers are already rolling out ChatGPT for Healthcare across their teams.</span></p><div id=\"openai-api-for-healthcare\"><p></p><h2><span>OpenAI API for Healthcare</span></h2><p></p></div><p><span>With the OpenAI API platform, developers can power tools and products with our latest models—including GPT‑5.2—and embed AI directly into healthcare systems and workflows. Eligible customers can apply for a Business Associate Agreement (BAA) with OpenAI to support HIPAA compliance requirements.</span></p><p><span>In practice, teams are using our APIs to build healthcare applications including patient chart summarization, care team coordination, and discharge workflows. Companies like Abridge, Ambience, and EliseAI are building capabilities like ambient listening, automated clinical documentation, and appointment scheduling for clinicians and patients.</span></p><div id=\"ai-models-optimized-for-healthcare\"><p></p><h2><span>AI models optimized for healthcare</span></h2><p></p></div><p><span>All OpenAI for Healthcare products are powered by GPT‑5.2 models, which outperform earlier OpenAI models and were developed through ongoing research and real-world evaluation that reflect how clinicians actually use AI.</span></p><p><span>Over the past two years, we’ve </span><a href=\"https://openai.com/index/healthbench/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>partnered with</span></u>⁠</a><span> a global network of more than 260 licensed physicians across 60 countries of practice to evaluate model performance using real clinical scenarios. To date, this group has reviewed more than 600,000 model outputs spanning 30 areas of focus. Their continuous feedback has directly informed model training, safety mitigations, and product iteration. ChatGPT for Healthcare went through multiple rounds of physician-led red teaming to tune model behavior, trustworthy information retrieval, and other evaluations.</span></p><p><span>We also look to evidence from live deployments. A study with Penda Health found that an </span><a href=\"https://openai.com/index/ai-clinical-copilot-penda-health/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>OpenAI-powered clinical copilot</span></u>⁠</a><span> used in routine primary care reduced both diagnostic and treatment errors—early evidence that AI, when deployed with appropriate safeguards and clinician oversight, can improve care quality.</span></p><p><span>Benchmarks like </span><a href=\"https://openai.com/index/healthbench/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>HealthBench</span></u>⁠</a><span>, an open, clinician-designed evaluation, also reinforce this progress. HealthBench measures model behavior across realistic medical scenarios using rubrics written by physicians. It goes beyond factual recall to assess clinical reasoning, safety, uncertainty handling, and communication quality—dimensions that better reflect how clinicians use AI in practice. Across these evaluations, GPT‑5.2 models consistently outperform prior generations and comparator models on real clinical workflows.</span></p><p><span>In real-world healthcare tasks, GPT‑5.2 also performs better than human baselines across every role measured in </span><a href=\"https://openai.com/index/gdpval/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>GDPval</span></u>⁠</a><span>, surpassing earlier OpenAI models.</span></p><div id=\"whats-next\"><p></p><h2><span>What’s next</span></h2><p></p></div><p><span>This announcement builds on OpenAI’s longstanding work across health, biopharma, and life sciences. That includes products like </span><a href=\"https://openai.com/index/introducing-chatgpt-health/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>ChatGPT Health</span></u>⁠</a><span>, which helps people better understand and more confidently navigate their health, ongoing research into how AI can accelerate scientific discovery with companies like </span><a href=\"https://openai.com/index/accelerating-life-sciences-research-with-retro-biosciences/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>Retro Biosciences</span></u>⁠</a><span>, and work with leading life sciences organizations like </span><a href=\"https://openai.com/index/gpt-5-amgen/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>Amgen</span></u>⁠</a><span>, </span><a href=\"https://corporate.thermofisher.com/us/en/index/newsroom/Our-stories/Thermo-fisher-scientific-open-ai-collaboration.html\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>Thermo Fisher</span></u>⁠<span>(opens in a new window)</span></a><span>, </span><a href=\"https://openai.com/index/moderna/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>Moderna</span></u>⁠</a><span>, and others. We also collaborate with leading professional services and consulting firms including Boston Consulting Group (BCG), Bain, McKinsey &amp; Company, and Accenture to help healthcare organizations move faster with AI.</span></p><p><span>OpenAI's mission is to ensure AI benefits all of humanity, and we believe improving health will be one of the defining impacts of AI. We’ll continue working closely with healthcare organizations using OpenAI for Healthcare to learn from real-world use and further improve our products for healthcare.&nbsp;</span></p></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/4UGWFdKeoK2WDO4ITb0sef/e20280d31a4236e5e615831501452e44/OAI_forHealth_ArtCard_16-9.png?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/index/tolan",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/tolan",
    "title": "How Tolan builds voice-first AI with GPT-5.1",
    "publishedAt": "Wed, 07 Jan 2026 10:00:00 GMT",
    "fetchedAt": "2026-01-25T19:08:06.678Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div><p><a href=\"https://www.tolans.com/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>Tolan</span></u>⁠<span>(opens in a new window)</span></a><span> is a voice-first AI companion where people talk with a personalized, animated character that learns from conversations over time.&nbsp;</span></p><p><span>Built by Portola, a veteran team with a prior exit, the app is designed for ongoing, open-ended dialogue rather than quick prompts and replies. “We saw the rise of ChatGPT and knew voice was the next frontier,” says Quinten Farmer, co-founder and CEO of Portola. “But voice is harder. You’re not just responding to typed prompts; you’re holding a live, meandering conversation.”</span></p><p><span>Voice AI raises the bar on latency and context management, but it also enables more open-ended, exploratory interactions than text.&nbsp;</span></p><p><span>With foundation models becoming faster, cheaper, and more capable, the team focused their efforts on two key levers: memory and character design. Portola built a character-driven universe, shaped by award-winning animators and a science fiction writer, using a real-time context management system to keep personality and memory consistent as conversations unfold.</span></p><p><span>The release of the GPT‑5.1 models marked a turning point, delivering major gains in steerability and latency that brought those pieces together, unlocking a more responsive and engaging voice experience.</span></p><div><blockquote>“GPT-5.1 gave us the steerability to finally express the characters we had in mind. It wasn’t just smarter—it was more faithful to the tone and personality we wanted to create.”</blockquote><p>—Quinten Farmer, CEO, Portola</p></div><div id=\"designing-for-natural-voice-interactions\"><p></p><h2><span>Designing for natural voice interactions</span></h2><p></p></div><p><span>Tolan’s architecture is shaped by the demands of voice. Voice users expect instant, natural responses, even when conversations shift midstream. Tolan had to respond quickly, track changing topics, and maintain a consistent personality without lag or tone drift.</span></p><p><span>To feel natural, conversations required near-instant latency. Introducing OpenAI GPT‑5.1 and the Responses API cut speech initiation time by over 0.7 seconds—enough to noticeably improve conversational flow.</span></p><p><span>Equally critical was how the system handled context. Unlike many agents that cache prompts across multiple turns, Tolan rebuilds its context window from scratch each turn. Each context reconstruction pulls in a summary of recent messages, a persona card, vector-retrieved memories, tone guidance, and real-time app signals. This architecture allows Tolan to adapt in real time to abrupt topic shifts, an essential requirement for natural voice-based interaction.</span></p><p><span>“We realized quickly that cached prompts just didn’t cut it,” says Quinten. “Users change subjects all the time. To feel seamless, the system had to adapt midstream.”</span></p><p><span>This real-time reconstruction approach is both technically intensive and foundational to Tolan’s success.</span></p><div id=\"building-memory-and-personality-that-hold-together-over-time\"><p></p><h2><span>Building memory and personality that hold together over time</span></h2><p></p></div><p><span>Context handling is important, but it wasn’t enough to keep conversations feeling coherent over time. To support long, nonlinear conversations, Tolan built a memory system that retains not just facts and preferences, but also emotional “vibe” signals—clues that help steer how a Tolan should respond.</span></p><p><span>Memories are embedded using the OpenAI text-embedding-3-large model and stored in Turbopuffer, a high-speed vector database that enables sub-50ms lookup times. This speed is essential for real-time voice interactions. Each turn, Tolan uses the user’s latest message and system-synthesized questions (e.g., “Who is the user married to?”) to trigger memory recall. To keep memory quality high, Tolan runs a nightly compression job that removes low-value or redundant entries (e.g. “the user drank coffee today”) and resolves contradictions.</span></p><p><span>Personality is just as carefully managed. Each Tolan is seeded with a distinct character scaffold, authored by the team’s in-house science fiction writer and refined by a behavioral researcher. These seeds give Tolans consistency, but also flexibility to adapt over time, evolving alongside the user.&nbsp;</span></p><p><span>A parallel system monitors the emotional tenor of the conversation and dynamically adjusts the Tolan’s delivery. This allows a Tolan to shift seamlessly from playful to grounded depending on user cues, without losing its core personality.&nbsp;</span></p><p><span>The transition to GPT‑5.1 was a turning point. Suddenly, layered prompt instructions—tone scaffolds, memory injections, character traits—were followed more faithfully. Prompts that once required workarounds began behaving as intended.&nbsp;</span></p><p><span>“For the first time, our internal experts felt like the model was really listening,” says Quinten. “Instructions stayed intact across long conversations, persona traits were respected, and we saw far less drift.”</span></p><p><span>Those changes added up to a more consistent and believable personality, which in turn created a more engaging user experience. The Tolan team saw clear, measurable gains: memory recall misses dropped by 30% (based on in-product frustration signals), and next-day user retention rose more than 20% after GPT‑5.1–powered personas went live.</span></p><div id=\"tolans-core-principles-for-building-natural-voice-agents\"><p></p><h2><span>Tolan’s core principles for building natural voice agents&nbsp;</span></h2><p></p></div><p><span>As Tolan evolved, a few principles emerged that now guide how the team builds and evolves its voice architecture:</span></p><div><ul><li><b><span>Design for conversational volatility: </span></b><span>Voice conversations shift mid-sentence. Systems need to pivot just as quickly to feel natural.</span></li><li><b><span>Treat latency as part of the product experience: </span></b><span>Sub-second responsiveness shapes whether a voice agent feels conversational or mechanical.</span></li><li><b><span>Build memory as a retrieval system, not a transcript: </span></b><span>High-quality compression and fast vector search deliver more consistent personality than oversized context windows.</span></li><li><b><span>Rebuild context every turn: </span></b><span>Don’t fight drift with bigger prompts. Regenerating context each turn keeps agents grounded as conversations meander.</span></li></ul></div><p><span>Together, these lessons form the foundation for Tolan’s next phase of innovation and set the direction for where voice AI is headed.</span></p><div id=\"expanding-whats-possible-with-voice-ai\"><p></p><h2><span>Expanding what’s possible with voice AI</span></h2><p></p></div><p><span>Since launching in February 2025, Tolan has grown to more than 200,000 monthly active users. Its 4.8-star rating and more than 100,000 App Store reviews highlight how well the system maintains consistency across long, shifting conversations. One reviewer noted, “They remember things we talked about two days ago and they bring it back into the conversation that we’re having today.”</span></p><p><span>These signals map directly to the underlying architecture: low-latency model calls, turn-by-turn context reconstruction, and modular memory and persona systems. Together, they allow Tolan to track topic changes, preserve tone, and keep responses grounded without relying on large, fragile prompts.</span></p><p><span>Looking ahead,&nbsp; Tolan plans to deepen its investments in steerability and memory refinement, focusing its efforts on tighter compression, improved retrieval logic, and expanded persona tuning. The long-term goal is to expand what a voice interface can be: not just responsive, but context-aware and conversationally dynamic.</span></p><p><span>“The next frontier,” says Quinten, “is building voice agents that aren’t just responsive, but truly multimodal, able to integrate voice, vision, and context into a single, steerable system.”</span></p></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/419ed2PplLerw020k1Usi0/881913b327f73f9590867392f0ce9c30/oai_Tolan_SEO.png?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/index/introducing-chatgpt-health",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/introducing-chatgpt-health",
    "title": "Introducing ChatGPT Health ",
    "publishedAt": "Wed, 07 Jan 2026 00:00:00 GMT",
    "fetchedAt": "2026-01-25T19:08:07.122Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div><p><span>We’re introducing ChatGPT Health, a dedicated experience that securely brings your health information and ChatGPT’s intelligence together, to help you feel more informed, prepared, and confident navigating your health.</span></p><p><span>Health is already one of the most common ways people use ChatGPT, with hundreds of millions of people asking health and wellness questions each week. ChatGPT Health builds on the strong privacy, security, and data controls across ChatGPT with additional, layered protections designed specifically for health— including purpose-built encryption and isolation to keep health conversations protected and compartmentalized. You can securely connect medical records and wellness apps to ground conversations in your own health information, so responses are more relevant and useful to you. Designed in close collaboration with physicians, ChatGPT Health helps people take a more active role in understanding and managing their health and wellness—while supporting, not replacing, care from clinicians.</span></p><div id=\"a-dedicated-health-experience\"><p></p><h2><span>A dedicated health experience</span></h2><p></p></div><p><span>Today, health information is often scattered across portals, apps, wearables, PDFs, and medical notes—so it's hard to see the full picture, and people are left to navigate a complex healthcare system on their own. People have shared countless stories of turning to ChatGPT to help make sense of it all. In fact, health is one of the most common ways people use ChatGPT today: based on our de-identified analysis of conversations, over 230 million people globally ask health and wellness related questions on ChatGPT every</span><b><span> </span></b><span>week.</span></p><p><span>ChatGPT Health builds on this so responses are informed by your health information and context. You can now securely connect medical records and wellness apps—like Apple Health, Function, and MyFitnessPal—so ChatGPT can help you understand recent test results, prepare for appointments with your doctor, get advice on how to approach your diet and workout routine, or understand the tradeoffs of different insurance options based on your healthcare patterns.</span></p><p><span>Health is designed to support, not replace, medical care. It is not intended for diagnosis or treatment. Instead, it helps you navigate everyday questions and understand patterns over time—not just moments of illness—so you can feel more informed and prepared for important medical conversations. To keep your health information protected and secure, Health operates as a separate space with enhanced privacy to protect sensitive data. Conversations in Health are not used to train our foundation models. If you start a health-related conversation in ChatGPT, we’ll suggest moving into Health for these additional protections.</span></p><p><span>If you’re interested in getting access as it becomes available, you can sign up for the </span><a href=\"https://chatgpt.com/health/waitlist\" target=\"_blank\" referrerpolicy=\"no-referrer-when-downgrade\" rel=\"noopener noreferrer\"><span>waitlist</span>⁠<span>(opens in a new window)</span></a><span>. </span><span>We’re starting by providing access to a small group of early users to learn and continue refining the experience—users with ChatGPT Free, Go, Plus, and Pro plans outside of the European Economic Area, Switzerland, and the United Kingdom are eligible. As we make improvements, we plan to expand access and make Health available to all users on web and iOS in the coming weeks.</span></p><p><span>Medical record integrations and some apps are available in the U.S. only, and connecting Apple Health requires iOS.</span></p><div id=\"designed-with-privacy-and-security-at-the-core\"><p></p><h2><span>Designed with privacy and security at the core</span></h2><p></p></div><p><span>Your health information is deeply personal. That’s why Health is built as a dedicated space with added protections for sensitive health information and easy-to-use controls.</span></p><p><span>Health lives in its own space within ChatGPT, where your conversations, connected apps, and files are stored separately from your other chats. Health has separate memories, ensuring that your health context stays contained within the space. You’ll still see health chats in your chat history so you can easily return to them, but the information itself stays within Health.</span></p><p><span>When helpful, ChatGPT may use context from your non-Health chats—like a recent move or lifestyle change—to make a health conversation more relevant. However, Health information and memories never flow back into your non-Health chats, and conversations outside of Health can’t access files, conversations, or memories created within Health. You can view or delete Health memories at any time within Health or the “Personalization” section of Settings.</span></p><p><span>We recognize that people share personal and sensitive information with ChatGPT. That understanding shapes how we design the security, privacy, and </span><a href=\"https://openai.com/consumer-privacy/\" target=\"_blank\" rel=\"noopener noreferrer\"><span>data controls</span>⁠</a><span> for all of our products—from the start. Even before introducing ChatGPT Health, we built foundational protections across ChatGPT to give you meaningful control over your data, including temporary chats, the ability to delete chats from OpenAI’s systems within 30 days, and training our models not to retain personal information from user chats.</span></p><p><span>Conversations and files across ChatGPT are encrypted by default at rest and in transit as part of our core security architecture. Due to the sensitive nature of health data, Health builds on this foundation with additional, layered protections—including purpose-built encryption and isolation—to keep health conversations protected and compartmentalized. Conversations in Health are not used to train our foundation models.</span></p><p><span>When you choose to connect your health data, such as medical records or wellness apps, your responses are grounded in your own health information. To enable access to trusted U.S. healthcare providers, we partner with b.well, the largest and most secure network of live, connected health data for U.S. consumers. b.well adheres to the highest industry standards in data security and privacy. You can remove access to medical records at any time in the \"Apps\" section of Settings.</span></p><p><span>You can also connect your Apple Health information and other wellness apps, such as Function and MyFitnessPal. Apps may only be connected to your health data with your explicit permission, even if they’re already connected to ChatGPT for conversations outside of Health. All apps available in Health must meet OpenAI’s privacy and security requirements, including collecting only the minimum data needed, and undergo additional security review specific to inclusion in Health. The first time you connect an app, we’ll help you understand what types of data may be collected by the third party. And you’re always in control: disconnect an app at any time and it immediately loses access.</span></p><div id=\"built-with-physicians\"><p></p><h2><span>Built with physicians</span></h2><p></p></div><p><span>ChatGPT Health was developed in close collaboration with physicians around the world to provide clear and useful health information.</span></p><p><span>Over two years, we’ve worked with more than 260 physicians who have practiced in 60 countries and dozens of specialties to understand what makes an answer to a health question helpful or potentially harmful—this group has now provided feedback on model outputs over 600,000 times across 30 areas of focus. This collaboration has shaped not just what Health can do, but how it responds: how urgently to encourage follow-ups with a clinician, how to communicate clearly without oversimplifying, and how to prioritize safety in </span><a href=\"https://openai.com/index/helping-people-when-they-need-it-most/\" target=\"_blank\" rel=\"noopener noreferrer\"><span>moments that matter</span>⁠</a><span>.</span></p><p><span>This physician-led approach is built directly into the model that powers Health, which is evaluated against clinical standards using </span><a href=\"https://openai.com/index/healthbench/\" target=\"_blank\" rel=\"noopener noreferrer\"><span>HealthBench</span>⁠</a><span>, an assessment framework we created with input from our network of practicing physicians. Rather than relying on exam-style questions or generic accuracy checks, HealthBench evaluates responses using physician-written rubrics that reflect how clinicians judge quality in practice—prioritizing safety, clarity, appropriate escalation of care, and respect for individual context.</span></p><p><span>This evaluation-driven approach helps ensure the model performs well on the tasks people actually need help with, including explaining lab results in accessible language, preparing questions for an appointment, interpreting data from wearables and wellness apps, and summarizing care instructions. The result is support that people can trust—always designed to support, not replace, your healthcare providers.</span></p><div id=\"how-to-get-started\"><p></p><h2><span>How to get started</span></h2><p></p></div><p><span>Select ‘Health’ from the sidebar menu in ChatGPT.</span></p><p><span>Bring your medical records and the apps you use to track your health and wellness into Health. You can upload files directly, connect from tools (+) or “Apps” in Settings.</span></p><div><ul><li><i><b><span>New:</span></b></i><b><span> Medical Records </span></b><span>for lab results, visit summaries, and clinical history</span></li><li><i><b><span>New:</span></b></i><b><span> Apple Health</span></b><span> for health and fitness data, including movement, sleep, and activity patterns (must be on iOS to sync)</span></li><li><i><b><span>New:</span></b></i><b><span> Function </span></b><span>for lab test insights, nutrition ideas, and taking action on your health</span></li><li><i><b><span>New:</span></b></i><b><span> MyFitnessPal</span></b><span> for nutrition advice, macros, and recipes</span></li><li><i><b><span>New:</span></b></i><b><span> Weight Watchers</span></b><span> for GLP-1 personalized meal ideas, recipes, and food guidance</span></li><li><b><span>AllTrails</span></b><span> to help you find your next hike&nbsp;</span></li><li><b><span>Instacart </span></b><span>to turn meal plans into shoppable lists&nbsp;</span></li><li><b><span>Peloton</span></b><span> for suggested workout classes or guided meditations</span></li></ul></div><p><span>Health conversations feel just like chatting with ChatGPT—but grounded in the information you’ve connected. You can upload photos and files and use search, deep research, voice mode and dictation. When relevant, ChatGPT can automatically reference your connected information to provide more relevant and personalized responses. For example, you might ask: </span><i><span>“How’s my cholesterol trending?”</span></i><span> or </span><i><span>“Can you summarize my latest bloodwork before my appointment?”</span></i><span> To use a connected app you can start your question with it, select it from tools (+) or ChatGPT may suggest one when helpful. </span></p><p><span>You can add custom instructions in Health to help ChatGPT know what to focus on, to avoid mentioning sensitive topics, or change how responses are framed. These instructions only apply to Health chats, and you can update or remove any time in Health or Settings.</span></p><div id=\"just-the-start\"><p></p><h2><span>Just the start </span></h2><p></p></div><p><span>We’ll continue to expand what you can connect and the insights Health can support—so ChatGPT can help you feel more informed, prepared, and confident as you navigate your health.</span></p></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/2zlj1v5fup8IPQFeD0HI8j/908a1aafec67c13ee67a62163e3c3c35/OAI_ChatGPT_Health_SEO.png?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/index/openai-grove",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/openai-grove",
    "title": "Announcing OpenAI Grove Cohort 2",
    "publishedAt": "Fri, 02 Jan 2026 10:00:00 GMT",
    "fetchedAt": "2026-01-25T19:08:05.899Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div id=\"main\" tabindex=\"-1\"><span aria-live=\"polite\" aria-atomic=\"true\">OpenAI</span><article><div><p>January 2, 2026</p><p>A program for individuals early in their company building journey.</p></div><div><p><i><b><span>Update on January 12, 2026</span></b></i><i><span>: Applications are now closed.</span></i></p><div><p><span>Today, we’re opening the applications for the next cohort of OpenAI Grove, a program for technical talent at the very start of their company-building journey. The Grove is not a startup accelerator or traditional program: it offers pre-idea individuals deeply curious about building in AI a dense talent network, co-building with OpenAI researchers, and resources designed to accelerate your journey. As participants explore early concepts, they will receive counsel from the OpenAI team and community with peers in OpenAI Grove. </span></p><p>\tThis program is the starting point of a long-term network. It will begin with five weeks of content and programming hosted in the OpenAI San Francisco HQ, including in-person workshops, weekly office hours, and mentoring from OpenAI technical leaders. In addition to technical support and community, participants will also have the opportunity to get hands-on with new OpenAI tools and models prior to general availability. Following the program, participants will be able to explore raising capital or pursue another avenue, internally or externally to OpenAI. </p></div><p><span>The Grove cohort will consist of approximately fifteen participants. We recommend individuals from all backgrounds, disciplines, and experience levels apply. To apply, please submit the form below by January 12th, 2026.</span></p><div id=\"faq\"><p></p><h2><span>FAQ</span></h2><p></p></div><div id=\"content_7yYGEfKk0MmnG3dHCN2PAY\" aria-labelledby=\"trigger_7yYGEfKk0MmnG3dHCN2PAY\" aria-hidden=\"false\"><p><span>Applications are due by January 12th, 2026.</span></p></div></div><div><p></p><h2>Keep reading</h2><p></p></div></article></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/b7xI7gXB6Rsli2zQ3ft1B/2f610ccfffccb7b8abd7bb2e750a6ed1/image__1_.png?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/index/one-in-a-million-customers",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/one-in-a-million-customers",
    "title": "One in a million: celebrating the customers shaping AI’s future",
    "publishedAt": "Mon, 22 Dec 2025 00:00:00 GMT",
    "fetchedAt": "2026-01-25T19:08:05.338Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div><p><span>No two customers use AI in exactly the same way.</span></p><p><span>This year was defined by watching people move from experimenting with AI to using it to transform how they work.</span></p><p><span>They rolled out ChatGPT across their organizations to help with writing, coding, research, data analysis, design, and the hundreds of small tasks that add up every day. They built agents to automate workflows that used to take hours. Developers used Codex to move faster and tackle bigger problems. And companies built entirely new products on our API, working across voice, video, images, and other modalities.&nbsp;</span></p><p><span>When we asked customers what AI enabled them to do, 75% told us they were completing tasks they had never been able to do before.&nbsp;</span></p><p><span>We’re grateful to be building with and learning from these teams every day. Below are just some of the ways our customers are pushing what’s possible with OpenAI, and helping make it the fastest growing business platform in history.</span></p></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/1Ut86gAjgUItv6XAgNboIE/8aa9ec22a0139b69f7809f082ed33970/One_Million_Tile_Card_16x9_2x.png?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/index/updating-model-spec-with-teen-protections",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/updating-model-spec-with-teen-protections",
    "title": "Updating our Model Spec with teen protections",
    "publishedAt": "Thu, 18 Dec 2025 11:00:00 GMT",
    "fetchedAt": "2026-01-25T19:08:06.245Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div><p><span>We’re sharing an update to our Model Spec, the written set of rules, values, and behavioral expectations that guides how we want our AI models to behave, especially in difficult or high stakes situations, with </span><a href=\"http://model-spec.openai.com/2025-12-18.html\" target=\"_blank\" referrerpolicy=\"no-referrer-when-downgrade\" rel=\"noopener noreferrer\"><u><span>Under-18 (U18) Principles</span></u>⁠<span>(opens in a new window)</span></a><span>. Model behavior is critical to how people interact with AI, and teens have different developmental needs than adults.</span></p><p><span>The U18 Principles guide how ChatGPT should provide a safe, age-appropriate experience for teens aged 13 to 17. Grounded in developmental science, this approach prioritizes prevention, transparency, and early intervention. In developing these principles, we previewed them with external experts, including the American Psychological Association, as part of our ongoing work to seek input to strengthen our approach.</span></p><p><span>While the principles of the Model Spec continue to apply to both adult and teen users, this update clarifies how it should be applied in teen contexts, especially where safety considerations for minors may be more pronounced.&nbsp;</span></p><p><span>The U18 Principles are anchored in four guiding commitments:</span></p><div><ul><li><b><span>Put teen safety first</span></b><span>, even when it may conflict with other goals</span></li><li><b><span>Promote real-world support</span></b><span> by encouraging offline relationships and trusted resources</span></li><li><b><span>Treat teens like teens</span></b><span>, neither condescending to them nor treating them as adults</span></li><li><b><span>Be transparent</span></b><span> by setting clear expectations</span></li></ul></div><p><span>Consistent with our </span><a href=\"https://openai.com/index/introducing-the-teen-safety-blueprint/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>Teen Safety Blueprint</span></u>⁠</a><span>, these principles have guided our teen safety work to date, including the content protections we apply to users who tell us they are under 18 at sign up, and through parental controls. In these contexts, we’ve implemented safeguards to guide the model to take extra care when discussing higher-risk areas, including self-harm and suicide, romantic or sexualized roleplay, graphic or explicit content, dangerous activities and substances, body image and disordered eating, and requests to keep secrets about unsafe behavior.</span></p><p><span>The American Psychological Association, which reviewed an early draft of the U18 Model Spec and offered important insights for the long term, is clear about the importance of protecting teens:</span></p><p><span>“</span><i><span>APA encourages AI developers to offer developmentally appropriate precautions for youth users of their products and to take a more protective approach for younger users.&nbsp; Children and adolescents might benefit from AI tools if they are balanced with human interactions that science shows are critical for social, psychological, behavioral, and even biological development. Youth experiences with AI should be thoroughly supervised and discussed with trusted adults to encourage critical review of what AI bots offer, and to encourage young people’s development of independent thinking and skills.</span></i><span>”—</span><b><span>Dr. Arthur C. Evans Jr, CEO, American Psychological Association</span></b></p><p><span>This update also clarifies how the assistant should respond when safety concerns arise for teens. This means teens should encounter stronger guardrails, safer alternatives, and encouragement to seek trusted offline support when conversations move into higher-risk territory. Where there is imminent risk, teens are urged to contact emergency services or crisis resources.</span></p><p><span>As with the rest of the Model Spec, the U18 Principles reflect our intended model behavior. We will continue to refine them as we incorporate new research, expert input, and real-world use.</span></p><div id=\"building-on-our-work-to-strengthen-teen-safety\"><p></p><h2><span>Building on our work to strengthen teen safety</span></h2><p></p></div><p><span>Alongside updating the Model Spec, we’ve taken a multi-layered approach to </span><a href=\"https://openai.com/index/building-more-helpful-chatgpt-experiences-for-everyone/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>strengthening teen safety</span></u>⁠</a><span> across ChatGPT, spanning product safeguards, family support, and expert guidance.</span></p><p><span>Since rolling out </span><a href=\"https://help.openai.com/en/articles/12315553-parental-controls-on-chatgpt-faq\" target=\"_blank\" referrerpolicy=\"no-referrer-when-downgrade\" rel=\"noopener noreferrer\"><u><span>parental controls</span></u>⁠<span>(opens in a new window)</span></a><span>, we’ve extended protections across new products including group chats, the ChatGPT Atlas browser, and the Sora app. These updates help parents tailor their teen’s ChatGPT experience as we introduce new products and features.</span></p><div id=\"working-with-experts\"><p></p><h2><span>Working with experts</span></h2><p></p></div><p><span>Our work in teen safety is guided by close engagement with experts across disciplines and expertise. In October, we established an </span><a href=\"https://openai.com/index/expert-council-on-well-being-and-ai/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>Expert Council on Well-Being and AI</span></u>⁠</a><span> to help advise and define what healthy interactions with AI should look like for all ages. That work has informed guidance on parental controls and parent notifications. We also incorporate clinical expertise through our </span><a href=\"https://openai.com/index/strengthening-chatgpt-responses-in-sensitive-conversations/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>Global Physician Network</span></u>⁠</a><span> to inform safety research and evaluate model behavior, including improving how ChatGPT recognizes distress and guides people toward professional care when appropriate. We built on these foundations with </span><a href=\"https://openai.com/index/introducing-gpt-5-2/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>GPT‑5.2</span></u>⁠</a><span>, and we’ve also expanded access to real-world support by surfacing localized helplines in ChatGPT and Sora through our partnership with </span><a href=\"https://www.throughlinecare.com/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>ThroughLine</span></u>⁠<span>(opens in a new window)</span></a><span>.</span></p><div id=\"whats-next\"><p></p><h2><span>What’s next</span></h2><p></p></div><p><span>We’re in the early stages of rolling out an </span><a href=\"https://help.openai.com/en/articles/12652064-age-prediction-in-chatgpt\" target=\"_blank\" referrerpolicy=\"no-referrer-when-downgrade\" rel=\"noopener noreferrer\"><u><span>age prediction model</span></u>⁠<span>(opens in a new window)</span></a><span> on ChatGPT consumer plans. This will help us automatically apply teen safeguards when we believe an account belongs to a minor. If we are not confident about someone’s age or have incomplete information, we’ll default to an&nbsp;U18 experience and give adults ways to verify their age.</span></p><p><span>Strengthening teen safety is ongoing work and we’ll continue to improve parental controls and model capabilities, expand resources for parents, work with organizations, researchers, and expert partners including the Well-Being Council and Global Physician Network.&nbsp;</span></p><p><span>We’re committed to making strong teen protections and improving them over time to better support teens and families.</span></p></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/29DblE1L7aBD56HebDbpq2/315cd43e2cf966b4bd9f14852319aa34/u18_Blog_Art_Card_Open_Graph.png?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/index/introducing-gpt-5-2-codex",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/introducing-gpt-5-2-codex",
    "title": "Introducing GPT-5.2-Codex",
    "publishedAt": "Thu, 18 Dec 2025 00:00:00 GMT",
    "fetchedAt": "2026-01-25T19:08:06.922Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div><p><span>Today we’re releasing GPT‑5.2-Codex, the most advanced agentic coding model yet for complex, real-world software engineering. GPT‑5.2-Codex is a version of </span><a href=\"https://openai.com/index/introducing-gpt-5-2/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>GPT‑5.2</span></u>⁠</a><span> further optimized for agentic coding in Codex, including improvements on long-horizon work through context compaction, stronger performance on large code changes like refactors and migrations, improved performance in Windows environments, and significantly stronger cybersecurity capabilities.</span></p><p><span>As our models continue to advance along the intelligence frontier, we’ve observed that these improvements also translate to capability jumps in specialized domains such as </span><a href=\"https://openai.com/index/strengthening-cyber-resilience/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>cybersecurity</span></u>⁠</a><span>. For example, just last week, a security researcher using GPT‑5.1-Codex-Max with Codex CLI found and responsibly </span><a href=\"https://react.dev/blog/2025/12/11/denial-of-service-and-source-code-exposure-in-react-server-components\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>disclosed</span></u>⁠<span>(opens in a new window)</span></a><span> a vulnerability in React that could lead to source code exposure.</span></p><p><span>GPT‑5.2-Codex has stronger cybersecurity capabilities than any model we’ve released so far. These advances can help strengthen cybersecurity at scale, but they also raise new dual-use risks that require careful deployment. While GPT‑5.2-Codex does not reach a ‘High’ level of cyber capability under our Preparedness Framework, we’re designing our </span><a href=\"https://openai.com/index/strengthening-cyber-resilience/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>deployment approach</span></u>⁠</a><span> with future capability growth in mind.</span></p><p><span>We're releasing GPT‑5.2-Codex today in all Codex surfaces for paid ChatGPT users, and working towards safely enabling access to GPT‑5.2-Codex for API users in the coming weeks. In parallel, we’re piloting invite-only trusted access to upcoming capabilities and more permissive models for vetted professionals and organizations focused on defensive cybersecurity work. We believe that this approach to deployment will balance accessibility with safety.</span></p><div id=\"pushing-the-frontier-on-real-world-software-engineering\"><p></p><h2><span>Pushing the frontier on real-world software engineering</span></h2><p></p></div><p><span>GPT‑5.2-Codex builds on </span><a href=\"https://openai.com/index/introducing-gpt-5-2/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>GPT‑5.2’s strengths</span></u>⁠</a><span> in professional knowledge work and </span><a href=\"https://openai.com/index/gpt-5-1-codex-max/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>GPT‑5.1-Codex-Max</span></u>⁠</a><span>’s frontier agentic coding and terminal-using capabilities. GPT‑5.2-Codex is now better at long-context understanding, reliable tool calling, improved factuality, and native compaction, making it a more dependable partner for long running coding tasks, while remaining token-efficient in its reasoning.</span></p><p><span>GPT‑5.2-Codex achieves state-of-the-art performance on SWE-Bench Pro and Terminal-Bench 2.0, benchmarks designed to test agentic performance on a wide variety of tasks in realistic terminal environments. It is also much more effective and reliable at agentic coding in native Windows environments, building on capabilities introduced in GPT‑5.1-Codex-Max.</span></p><p><span>With these improvements, Codex is more capable at working in large repositories over extended sessions with full context intact. It can more reliably complete complex tasks like large refactors, code migrations, and feature builds — continuing to iterate without losing track, even when plans change or attempts fail.</span></p><p><span>Stronger vision performance enables GPT‑5.2-Codex to more accurately interpret screenshots, technical diagrams, charts, and UI surfaces shared during coding sessions.</span></p><p><span>Codex can take design mocks and quickly translate them to functional prototypes, and you can pair with Codex to take these prototypes to production.</span></p><div data-multi-columns=\"true\"><!--$--><div><!--$--><div><p></p><h5>Design mock</h5><p></p></div><!--/$--><!--$--><div><p><img alt=\"Design mock used to generate a web prototype with Codex-5.2\" data-nosnippet=\"true\" loading=\"lazy\" width=\"1536\" height=\"1024\" decoding=\"async\" data-nimg=\"1\" sizes=\"(min-width: 1728px) 1728px, 100vw\" srcset=\"https://images.ctfassets.net/kftzwdyauwt9/3zqTyemGGUiGdqzwcSHfqT/7dcff34a7b6f51ce1ed20be8a4ffcbf4/image__5_.png?w=640&amp;q=90&amp;fm=webp 640w, https://images.ctfassets.net/kftzwdyauwt9/3zqTyemGGUiGdqzwcSHfqT/7dcff34a7b6f51ce1ed20be8a4ffcbf4/image__5_.png?w=750&amp;q=90&amp;fm=webp 750w, https://images.ctfassets.net/kftzwdyauwt9/3zqTyemGGUiGdqzwcSHfqT/7dcff34a7b6f51ce1ed20be8a4ffcbf4/image__5_.png?w=828&amp;q=90&amp;fm=webp 828w, https://images.ctfassets.net/kftzwdyauwt9/3zqTyemGGUiGdqzwcSHfqT/7dcff34a7b6f51ce1ed20be8a4ffcbf4/image__5_.png?w=1080&amp;q=90&amp;fm=webp 1080w, https://images.ctfassets.net/kftzwdyauwt9/3zqTyemGGUiGdqzwcSHfqT/7dcff34a7b6f51ce1ed20be8a4ffcbf4/image__5_.png?w=1200&amp;q=90&amp;fm=webp 1200w, https://images.ctfassets.net/kftzwdyauwt9/3zqTyemGGUiGdqzwcSHfqT/7dcff34a7b6f51ce1ed20be8a4ffcbf4/image__5_.png?w=1920&amp;q=90&amp;fm=webp 1920w, https://images.ctfassets.net/kftzwdyauwt9/3zqTyemGGUiGdqzwcSHfqT/7dcff34a7b6f51ce1ed20be8a4ffcbf4/image__5_.png?w=2048&amp;q=90&amp;fm=webp 2048w, https://images.ctfassets.net/kftzwdyauwt9/3zqTyemGGUiGdqzwcSHfqT/7dcff34a7b6f51ce1ed20be8a4ffcbf4/image__5_.png?w=3840&amp;q=90&amp;fm=webp 3840w\" src=\"https://images.ctfassets.net/kftzwdyauwt9/3zqTyemGGUiGdqzwcSHfqT/7dcff34a7b6f51ce1ed20be8a4ffcbf4/image__5_.png?w=3840&amp;q=90&amp;fm=webp\" style=\"max-width: 100%; height: auto; border-radius: 1rem; margin: 2rem 0px;\"></p></div><!--/$--></div><!--/$--><!--$--><div><p></p><h5>Prototype generated by GPT-5.2-Codex</h5><p></p></div><!--/$--></div><div id=\"advancing-the-cyber-frontier\"><p></p><h2><span>Advancing the cyber frontier</span></h2><p></p></div><p><span>When charting performance on one of our core cybersecurity evaluations over time, we see a sharp jump in capability starting with GPT‑5-Codex, another large jump with GPT‑5.1-Codex-Max and now a third jump with GPT‑5.2-Codex. We expect that upcoming AI models will continue on this trajectory. In preparation, we are planning and evaluating as though each new model could reach ‘High’ levels of cybersecurity capability, as measured by our </span><a href=\"https://cdn.openai.com/pdf/18a02b5d-6b67-4cec-ab64-68cdfbddebcd/preparedness-framework-v2.pdf\" target=\"_blank\" referrerpolicy=\"no-referrer-when-downgrade\" rel=\"noopener noreferrer\"><span>Preparedness Framework⁠</span>⁠<span>(opens in a new window)</span></a><span>. While GPT‑5.2-Codex has not yet reached ‘High’ level of cyber capability, we are preparing for future models that cross that threshold. Due to the increased cyber capabilities, we have added additional </span><span>safeguards in the model</span><span> and in the product, which are outlined in the </span><a href=\"https://openai.com/index/gpt-5-2-codex-system-card\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>system card</span></u>⁠</a><span>.</span></p><div id=\"real-world-cyber-capabilities\"><p></p><h2><span>Real-world cyber capabilities</span></h2><p></p></div><p><span>Modern society runs on software, and its reliability depends on strong cybersecurity—keeping critical systems in banking, healthcare, communications, and essential services online, protecting sensitive data, and ensuring people can trust the software they rely on every day. Vulnerabilities can exist long before anyone knows about them, and finding, validating, and fixing them often depends on a community of engineers and independent security researchers equipped with the right tools.</span></p><p><span>On December 11, 2025, the React team published three security vulnerabilities affecting apps built with React Server Components. What made this disclosure notable was not only the vulnerabilities themselves, but how they were uncovered.</span></p><p><span>Andrew MacPherson, a principal security engineer at Privy (a Stripe company), was using GPT‑5.1-Codex-Max with Codex CLI and other coding agents to reproduce and study a different critical React vulnerability disclosed the week prior, known as </span><a href=\"https://react.dev/blog/2025/12/03/critical-security-vulnerability-in-react-server-components\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>React2Shell</span></u>⁠<span>(opens in a new window)</span></a><span> (</span><a href=\"https://nvd.nist.gov/vuln/detail/CVE-2025-55182\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>CVE-2025-55182</span></u>⁠<span>(opens in a new window)</span></a><span>). His goal was to evaluate how well the model could assist with real-world vulnerability research.</span></p><p><span>He initially attempted several zero-shot analyses, prompting the model to examine the patch and identify the vulnerability it addressed. When that did not yield results, he shifted to a higher-volume, iterative prompting approach. When those approaches did not succeed, he guided Codex through standard defensive security workflows—setting up a local test environment, reasoning through potential attack surfaces, and using fuzzing to probe the system with malformed inputs. While attempting to reproduce the original React2Shell issue, Codex surfaced unexpected behaviors that warranted deeper investigation. Over the course of a single week, this process led to the discovery of previously unknown vulnerabilities, which were responsibly disclosed to the React team.</span></p><p><span>This demonstrates how advanced AI systems can materially accelerate defensive security work in widely used, real-world software. At the same time, capabilities that help defenders move faster can also be misused by bad actors.</span></p><p><span>As agentic systems become more capable in cybersecurity-relevant tasks, we are making it a core priority to ensure these advances are deployed responsibly—pairing every gain in capability with stronger safeguards, tighter access controls, and ongoing collaboration with the security community.</span></p><div id=\"empowering-cyberdefense-through-trusted-access\"><p></p><h2><span>Empowering cyberdefense through trusted access</span></h2><p></p></div><p><span>Security teams can run into restrictions when attempting to emulate threat actors, analyze malware to support remediation, or stress test critical infrastructure. We are developing a trusted access pilot to remove that friction for qualifying users and organizations and enable trusted defenders to use frontier AI cyber capabilities to accelerate cyberdefense.</span></p><p><span>Initially the pilot program will be invite-only for vetted security professionals with a track record of responsible vulnerability disclosure and organizations with a clear professional cybersecurity use case. Qualifying participants will get access to our most capable models for defensive use-cases to enable legitimate dual-use work.</span></p><p><span>If you’re a security professional or part of an organization doing ethical security work like vulnerability research or authorized red-teaming, we invite you to express interest in joining and share feedback on what you’d like to see from the program </span><a href=\"https://docs.google.com/forms/d/e/1FAIpQLSea_ptovrS3xZeZ9FoZFkKtEJFWGxNrZb1c52GW4BVjB2KVNA/viewform\" target=\"_blank\" rel=\"noopener noreferrer\"><span>here</span>⁠<span>(opens in a new window)</span></a><span>. </span></p><div id=\"conclusion\"><p></p><h2><span>Conclusion</span></h2><p></p></div><p><span>GPT‑5.2-Codex represents a step forward in how advanced AI can support real-world software engineering and specialized domains like cybersecurity—helping developers and defenders tackle complex, long-horizon work, and strengthening the tools available for responsible security research.</span></p><p><span>By rolling GPT‑5.2-Codex out gradually, pairing deployment with safeguards, and working closely with the security community, we’re aiming to maximize defensive impact while reducing the risk of misuse. What we learn from this release will directly inform how we expand access over time as the software and cyber frontiers continue to advance.</span></p></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/6LIpGEEENB5lAfUNbRi0ey/8f42edb6e74d7d0b6f2541d409ba8553/OAI_GPT-5.2-Codex_ArtCard_16x9..png?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/index/openai-academy-for-news-organizations",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/openai-academy-for-news-organizations",
    "title": "Introducing OpenAI Academy for News Organizations",
    "publishedAt": "Wed, 17 Dec 2025 06:00:00 GMT",
    "fetchedAt": "2026-01-25T19:08:06.558Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div id=\"main\" tabindex=\"-1\"><span aria-live=\"polite\" aria-atomic=\"true\">OpenAI</span><article><div><p>Working with the American Journalism Project and The Lenfest Institute to launch a new learning hub for journalists and publishers using AI.</p></div><div><p><span>At OpenAI, we believe journalism is essential to a healthy democracy. People depend on reliable local and national reporting to understand their communities and the world around them, and we’re committed to being a strong partner to news organizations—supporting their work and convening the right people to move the industry forward.</span></p><p><span>We shared this initiative yesterday at the </span><a href=\"https://brown.columbia.edu/ai-summit/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>AI and Journalism Summit</span></u>⁠<span>(opens in a new window)</span></a><span>, which we co-hosted with the Brown Institute for Media Innovation and Hearst, which brought together leaders from the newsroom, academic, and technology community. The OpenAI Academy for News Organizations goes live today with hands-on training, playbooks, and real-world examples that help teams save time and focus on high-impact journalism – from reporting and fact-gathering, to the business and operational work that keeps news organizations strong.</span></p><p><span>At launch, the OpenAI Academy for News Organizations includes:</span></p><div><ul><li><b><span>On-demand training</span></b><span>, including </span><i><span>AI Essentials for Journalists</span></i><span>, which introduces core AI concepts and newsroom-relevant use cases, along with sessions for more technical and product-focused teams exploring advanced tools and custom solutions to their business needs.&nbsp;</span></li><li><b><span>Practical use cases</span></b><span> focusing on investigative and background research, translation and multilingual reporting, data analysis, and production efficiency.&nbsp;</span></li><li><b><span>Open-source projects and shared resources</span></b><span> to make it easier for other news organizations to adapt for their own needs.&nbsp;</span></li><li><b><span>Guidance on responsible uses, </span></b><span>including tips and examples for developing internal policies and governance frameworks.&nbsp;</span></li></ul></div><p><span>The OpenAI Academy for News Organizations builds on years of collaboration with the journalism community, including our ongoing work with American Journalism Project and The Lenfest Institute to support local news organizations as they responsibly adopt AI to assist in critical newsroom research and investigative work, accelerate product development, and explore new ways of using AI to improve business sustainability. Those efforts, alongside partnerships with publishers and industry groups around the world, helped inform the new Academy’s emphasis on practical guidance, transparency, and shared learning grounded in real newsroom needs.</span></p><p><span>AI is already reshaping how newsrooms work, and the Academy is intended to provide immediate value. We recognize that adopting new technology raises important questions for journalists and publishers, including concerns about trust, accuracy, and jobs. The Academy is built with those realities in mind.&nbsp;</span></p><p><span>We’ve invested for years in supporting a healthy news ecosystem while helping more than 800 million weekly ChatGPT users access timely, high-quality information from trusted news outlets. Today, that work includes partnerships with organizations such as News Corp, Axios, the Financial Times, Condé Nast, and Hearst as well as collaborations with groups like AJP, The Lenfest Institute, the World Association of News Publishers (WAN-IFRA), and the International News Media Association (INMA) that focus on shared learning and capacity building across the industry. Together, these partners provide content in more than 20 languages globally.&nbsp;</span></p><p><span>In the year ahead, we plan to work with additional news organizations and industry partners to expand the Academy with new courses, case studies, and live programming. Through this effort, we’ll provide tools to help journalists everywhere do their work even better and support news organizations as they build for the future.</span></p></div><section id=\"citations\" data-testid=\"citations\"><ul><li><a href=\"https://openai.com/news/?tags=community\" target=\"_blank\" rel=\"noopener noreferrer\">Community</a></li><li><a href=\"https://openai.com/news/?tags=2025\" target=\"_blank\" rel=\"noopener noreferrer\">2025</a></li></ul></section></article></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/6oeS6e2sVMNK2Z2LOa6DaE/7b0bdd8b8b918f54afcb7e0601e6ba3f/Frame_2__1_.png?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/index/accelerating-biological-research-in-the-wet-lab",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/accelerating-biological-research-in-the-wet-lab",
    "title": "Measuring AI’s capability to accelerate biological research",
    "publishedAt": "Tue, 16 Dec 2025 08:00:00 GMT",
    "fetchedAt": "2026-01-25T19:08:06.443Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div><p><span>Accelerating scientific progress is one of the most valuable ways AI can benefit humanity. With GPT‑5, we’re beginning to see </span><a href=\"https://openai.com/index/accelerating-science-gpt-5/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>early signs</span></u>⁠</a><span> of this—not only in helping researchers move faster through the scientific literature, but also in supporting new forms of scientific reasoning, such as surfacing unexpected connections, proposing proof strategies, or suggesting plausible mechanisms that experts can evaluate and test.</span></p><p><span>Progress to date has been most visible in fields like mathematics, theoretical physics, and theoretical computer science, where ideas can be rigorously checked without physical experiments. Biology is different: most advances depend on experimental execution, iteration, and empirical validation in the laboratory.</span></p><p><span>To help understand how frontier models behave in these settings, we worked with Red Queen Bio, a biosecurity start-up, to build an evaluation framework that tests how a model proposes, analyzes, and iterates on ideas in the wet lab. We set up a simple molecular biology experimental system and had GPT‑5 optimize a molecular cloning protocol for efficiency.</span></p><p><span>Over multiple rounds of experimentation, GPT‑5 introduced a novel mechanism that improved cloning efficiency by 79x. Cloning is a fundamental molecular biology tool. The efficiency of cloning methods is critical for creating large, complex libraries central to </span><a href=\"https://www.nature.com/articles/s41592-025-02740-0\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>protein engineering</span></u>⁠<span>(opens in a new window)</span></a><span>, </span><a href=\"https://www.nature.com/articles/s41467-025-67256-9\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>genetic screens</span></u>⁠<span>(opens in a new window)</span></a><span>, and </span><a href=\"https://www.nature.com/articles/s41467-019-13189-z\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>organismal strain engineering</span></u>⁠<span>(opens in a new window)</span></a><span>. This project offers a glimpse of how AI could work side-by-side with biologists to speed up research. Improving experimental methods will help human researchers move faster, reduce costs, and translate discoveries into real-world impact.</span></p><p><span>Because advances in biological reasoning carry biosecurity implications, we conducted this work in a tightly controlled setting—using a benign experimental system, limiting the scope of the task, and evaluating model behavior to inform our biosecurity risk assessments and the development of model- and system-level safeguards, as outlined in our </span><a href=\"https://cdn.openai.com/pdf/18a02b5d-6b67-4cec-ab64-68cdfbddebcd/preparedness-framework-v2.pdf\" target=\"_blank\" referrerpolicy=\"no-referrer-when-downgrade\" rel=\"noopener noreferrer\"><u><span>Preparedness Framework</span></u>⁠<span>(opens in a new window)</span></a><span>.</span></p><div id=\"experimental-results\"><p></p><h2><span>Experimental results</span></h2><p></p></div><p><span>In this set-up, GPT‑5 autonomously reasoned about the cloning protocol, proposed modifications, and incorporated data from new experiments to suggest more improvements. The only human intervention was having scientists carry out the modified protocol and upload experimental data.</span></p><p><span>Over the course of multiple rounds, GPT‑5 optimized the cloning procedure to improve the efficiency by over 79x—meaning that for a fixed amount of input DNA, we recovered 79x more sequence-verified clones than the baseline protocol. Most notably, it introduced two enzymes that constitute a novel mechanism: the recombinase RecA from </span><i><span>E. coli</span></i><span>, and phage T4 gene 32 single-stranded DNA–binding protein (gp32). Working in tandem, gp32 smooths and detangles the loose DNA ends, and RecA then guides each strand to its correct match.</span></p><p><span>While early, these results are encouraging. The improvements are specific to our particular cloning set up used in our model system, and still require human scientists to set up and run the protocols. Even so, these experiments show that AI systems can meaningfully assist real laboratory work and may accelerate human scientists in the future.</span></p><p><span>Notably, the AI-lab loop was run with fixed prompting and no human intervention. This scaffolding helped reveal the model’s capacity to propose genuinely novel protocol changes independent of human guidance, but it also locked the system into exploration and limited its ability to maximize the performance of newly discovered ideas. A better dynamic balance between exploration and exploitation would likely yield larger gains, as both the enzymatic and transformation improvements have substantial room for refinement. We expect advances in planning and task-horizon reasoning to improve the ability of simple fixed prompts to support both discovery and subsequent optimization.</span></p><div id=\"an-evolutionary-framework-for-optimizing-real-world-protocols\"><p></p><h2><span>An evolutionary framework for optimizing real-world protocols</span></h2><p></p></div><p><span>The </span><a href=\"https://www.nature.com/articles/nmeth.1318\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>Gibson assembly</span></u>⁠<span>(opens in a new window)</span></a><span> reaction has been a primary cloning method since its invention in 2009, with widespread adoption across molecular biology. Gibson assembly lets molecular biologists “glue” pieces of DNA together by briefly melting their ends so matching sequences can be sealed into a single molecule. One major appeal of Gibson assembly is its simplicity: everything happens in a single tube at one temperature. Those constraints naturally leave room for improvement. In addition, the following properties make it well-suited to evaluating AI models’ abilities to improve wet lab techniques:</span></p><div><ul><li><span>Well-defined with controlled components, unlike a cell-based system</span></li><li><span>Has a clear optimization function: transformable circularized DNA made from a fixed amount of linear DNA inputs</span></li><li><span>Relatively fast experimental cycles (1-2 days)</span></li><li><span>High-dimensional design space that requires mechanistic reasoning to improve: optimal buffers, reagents, and temperatures are all interdependent</span></li></ul></div><div><p><span>We used </span><a href=\"https://www.neb.com/en-us/applications/cloning-and-synthetic-biology/dna-assembly-and-cloning/nebuilder-hifi-dna-assembly?srsltid=AfmBOoo1sNIc0ELdZ6rZXK8ERV18f4x8nNd7WTyKXyCWClhMmGCPxRFM\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>HiFi assembly</span></u>⁠<span>(opens in a new window)</span></a><span>, a proprietary enzyme system developed by New England Biolabs and based on Gibson assembly, as an optimization starting point. We explored whether an AI could innovate and learn from experimental feedback once the single-step and isothermal constraints were removed, and thereby identify protocol improvements in this scenario.</span></p><p>Specifically, we performed a two-piece cloning reaction using a gene for green fluorescent protein (GFP) and the widely used pUC19 plasmid, a standard DNA “vehicle” used to carry genes into bacteria so they can be copied. The goal was to increase the number of successful colonies.</p></div><p><span>We optimized the cloning reaction by introducing an evolutionary framework for iterating on proposals, enabling the model to learn “online” from its past experiments. In each round, GPT‑5 proposed a batch of 8-10 different reactions, with reactions pushed to later rounds if they required custom reagents the laboratory did not have readily on hand. Human scientists then carried out the reactions and measured the colony counts relative to the baseline HiFi Gibson assembly in an initial screen. The best performing data from the previous round were then fed into the next round. Importantly, the prompting was standardized with no human input beyond clarifying questions, allowing us to attribute novel mechanistic insights directly to the AI rather than human guidance.&nbsp;</span></p><p><span>We retested the top eight reactions from the full optimization series using a wider range of DNA dilutions, and found that many showed smaller effects than in the initial screen; ultimately, the strongest validated candidate was a reaction from round-5 that reproduced its original performance. Many high performers fell into the ligase-polish family, which appears particularly sensitive to small variations in competent-cell state and/or post-reaction DNA handling. Because these reactions used a short HiFi step, we hypothesize that many products likely enter </span><i><span>E. coli </span></i><span>with only one junction sealed and the other held by annealing, leaving downstream rescue to cellular repair pathways. This creates high variance and a ‘jackpot’ dynamic: even if most of the time variants of this reaction don’t outperform, a single strong outlier can carry the family into subsequent rounds.&nbsp;</span></p><p><span>While we focused on optimizing the cloning reaction over rounds due to its mechanistic complexity, we in parallel optimized the transformation procedure using a single “one-shot” round where the model proposed many independent changes, and we took the top performing reaction.</span></p><p><span>Using standardized prompts with no human input, GPT5 improved end-to-end cloning efficiency 79-fold, confirmed across experimental replicates.</span></p><p><span>Notably, the model proposed a new enzymatic procedure, which the model called RecA-Assisted Pair-and-Finish HiFi Assembly (RAPF-HiFi), that adds two new proteins to the reaction: the recombinase RecA from </span><i><span>E. coli</span></i><span>, and the phage T4 gene 32 single-stranded DNA–binding protein (gp32). Further, the model made deliberate modifications to the incubation temperature and time, and the timing of enzymatic additions: it proposed adding RecA and gp32 after an initial 50°C HiFi reaction, letting these proteins work at 37°C, and then going back to 50°C to complete the assembly. Together, these new modifications boosted efficiency over 2.5-fold. It should be noted that this represents the initial performance without iterative optimization of reaction conditions and timing.</span></p><p><span>On the transformation side, the most effective modification proved unexpectedly simple: pelleting the cells (spinning them down in a centrifuge so they collect at the bottom of the tube), removing half of the supplied volume, and resuspending the cells before adding DNA, all at 4°C. While high-efficiency chemically competent cells are typically considered fragile, the cells tolerated concentration well and the increased molecular collisions boosted transformation efficiency substantially (&gt;30-fold on final validation).&nbsp;</span></p><div id=\"a-novel-improvement-to-homology-based-cloning\"><p></p><h2><span>A novel improvement to homology-based cloning</span></h2><p></p></div><div><p><span>T5 exonuclease creates 3′ overhangs that gp32 stabilizes by suppressing secondary structure. RecA then invades from the 3′ ends, displacing gp32 and promoting homology search and annealing. Heating to 50 °C removes both proteins, enabling polymerase gap fill and ligation.</span></p></div><p><span>Gibson assembly works by giving pieces of DNA matching “sticky” ends so that they can find each other and join. The reaction uses two different enzymes (a polymerase and a ligase) to seal the joined pieces. In RAPF-HiFi, two proteins were introduced to make the matching step work better. The first, gp32, acts like a comb that smooths and untangles the loose DNA ends. The second, RecA, acts like a guide that searches for the correct partner for each strand and pulls the matching pieces together. Higher temperature causes both helpers to fall off the DNA, allowing the normal Gibson enzymes to complete the reaction.</span></p><p><span>In summary, we hypothesize that the improved performance is mediated via the following mechanism:</span></p><div><ul><li><span>Gp32 coats non-annealed single-stranded DNA (ssDNA) tails, removing secondary structure</span></li><li><span>RecA, normally inhibited by structure, invades from the 3’ and displaces the gp32 filament</span></li><li><span>RecA mediates a </span><a href=\"https://www.pnas.org/doi/10.1073/pnas.82.2.297\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>ssDNA:ssDNA homology search</span></u>⁠<span>(opens in a new window)</span></a><span>, driving annealing</span></li><li><span>A return to 50°C displaces both the recA and the gp32 filaments, allowing polymerase and ligase to complete the reaction.</span></li></ul></div><p><span>To test whether the novel enzymes were functional, and to rule out that the performance improvement is driven solely by changes in thermal steps or buffers, we tested the performance of RAPF-HiFi without RecA, and without both RecA and gp32. The performance of both reactions was reduced relative to RAPF-HiFi, suggesting that both proteins are necessary for the mechanism of action of RAPF-HiFi.</span></p><p><span>The development RAPF-HiFi suggests that GPT‑5 is capable of complex, multi-dimensional reasoning:</span></p><div><ul><li><a href=\"https://www.pnas.org/doi/10.1073/pnas.151242898\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>RecA is inhibited by DNA structure</span></u>⁠<span>(opens in a new window)</span></a><span>, and it’s notable that the model introduced two synergistic modifications at once: add RecA, and complemented it with gp32 to remove DNA secondary structure.</span></li><li><span>The natural partner to </span><i><span>E. coli </span></i><span>RecA is </span><i><span>E. coli </span></i><span>single-stranded binding protein (SSB). SSB performs a similar role to gp32 during genome replication, recombination, and repair. However, </span><i><span>E. coli </span></i><span>SSB does not spontaneously fall off the DNA fast enough for RecA filament growth, with the </span><a href=\"https://www.sciencedirect.com/science/article/pii/S1097276503001886\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>RecFOR complex promoting RecA nucleation at SSB filament in vivo</span></u>⁠<span>(opens in a new window)</span></a><span>. SSB binds as a stable tetramer with </span><a href=\"https://pubs.acs.org/doi/10.1021/bi020122z\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>extremely slow off-rates</span></u>⁠<span>(opens in a new window)</span></a><span>. By contrast, gp32 filament is </span><a href=\"https://www.sciencedirect.com/science/article/pii/S0022283624001396\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>more dynamic</span></u>⁠<span>(opens in a new window)</span></a><span>, allowing for RecA displacement.&nbsp;</span></li></ul></div><p><span>To our knowledge, RecA and gp32 have not been functionally co-used in molecular biology methods. As with many novel molecular biology techniques, the underlying biochemical activities were already studied, but their use as a practical, generalizable method constitutes the advance.</span></p><p><span>For example, the interaction of RecA and gp32 has been studied in mechanistic in vitro reconstitution assays: in studies of D loop formation, </span><a href=\"https://www.pnas.org/doi/10.1073/pnas.77.5.2606?url_ver=Z39.88-2003&amp;rfr_id=ori%3Arid%3Acrossref.org&amp;rfr_dat=cr_pub++0pubmed\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>gp32 was shown</span></u>⁠<span>(opens in a new window)</span></a><span> to be capable of enhancing RecA activity. Gp32 has been used in conjunction with its natural T4 recombinase partner UvsX and recombinase loading factor uvsY in </span><a href=\"https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.0040204\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>recombinase polymerase amplification (RPA</span></u>⁠<span>(opens in a new window)</span></a><span>). Although an </span><a href=\"https://patents.google.com/patent/US20090029421A1/en\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>RPA patent specification states</span></u>⁠<span>(opens in a new window)</span></a><span> that effective RPA reactions have been demonstrated using E. coli RecA in a heterologous system with a compromised (i.e., engineered, non–wild-type) gp32 protein, this assertion appears only as a tangent in some patent disclosures and, to our knowledge, has not been supported by published data or adopted as a robust RecA-based RPA system. One cloning method called </span><a href=\"https://academic.oup.com/nar/article/40/8/e55/2411705\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>SLiCE</span></u>⁠<span>(opens in a new window)</span></a><span> uses a whole cell extract from </span><i><span>E. coli</span></i><span> containing the λ Red recombination system, where Red beta may perform dual roles as both a DNA-binding protein and recombinase (though we explicitly prohibited the use of cell extracts in our prompt). In a different application, </span><a href=\"https://www.pnas.org/doi/10.1073/pnas.95.5.2152\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>Ferrin &amp; Camerini-Otero</span></u>⁠<span>(opens in a new window)</span></a><span> used RecA alone to selectively capture DNA molecules based on matching sequences. Separately, g</span><a href=\"https://academic.oup.com/nar/article/18/4/1079/1112638\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>p32 has been used as an additive</span></u>⁠<span>(opens in a new window)</span></a><span> in a DNA amplification process called PCR to reduce secondary structure. </span><a href=\"https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0265391\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>NABSA amplification was shown</span></u>⁠<span>(opens in a new window)</span></a><span> to be enhanced by both RecA and gp32, though each could enhance the reaction separately and no synergy was identified. More broadly, reported improvements to the basic Gibson-style DNA assembly reactions have been scarce, with the most notable example being a heat-stable DNA-binding protein (ET SSB) that </span><a href=\"https://www.biorxiv.org/content/10.1101/2020.06.14.150979v1\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>improves assembly efficiency by approximately 2.5-fold</span></u>⁠<span>(opens in a new window)</span></a><span>.&nbsp;</span></p><p><span>For most applications, we do not expect RAPF-HiFi to compete with the simplicity and robustness of HiFi/Gibson cloning. However, the emergence of a mechanistically distinct assembly pathway is noteworthy: GPT‑5 arrived at a solution that incorporates an unfamiliar combination of recombination proteins and reaction dynamics. The underlying mechanism may prove modular, providing components that can be repurposed or recombined in other molecular workflows. We are also continuing to explore improvements to RAPF-HiFi. Reaction temperatures and step durations can be tuned to balance RecA and gp32 activity against exonuclease over-digestion, and the amounts of both proteins remain to be optimized. GPT‑5 has also proposed a hyperactive RecA variant, which we are currently purifying.</span></p><p><span>With respect to the transformation protocol, the successful optimization conditions spanned a range of additives and thermal perturbations intended to enhance the heat-shock efficiency of commercial </span><a href=\"https://www.neb.com/en-us/products/c3019-neb-10-beta-competent-e-coli-high-efficiency?srsltid=AfmBOorcs_qhj9EZFQ4g-gGg2ZDAOkN4GF8JZijwvEEn3JIJFcYt_N3y\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>10-beta competent cells</span></u>⁠<span>(opens in a new window)</span></a><span>. Of the 13 AI-generated one-shot transformations tested, the most effective modification, Transformation 7 (T7), pelleted the cells, removing half of the supplied volume, and resuspending the cells before adding DNA, all at 4°C. High-efficiency chemically competent cells are typically considered fragile, and such handling steps are generally avoided. Nonetheless, the cells tolerated concentration well. The combined effects of increased DNA exposure per cell and less inhibitory buffer leading to a sharper heat-shock yielded a substantial increase in transformation efficiency (&gt;30-fold).&nbsp;</span></p><p><span>This transformation protocol is novel, although a conceptually </span><a href=\"https://portlandpress.com/bioscirep/article/33/6/e00086/55976/A-comparison-and-optimization-of-methods-and\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>similar approach</span></u>⁠<span>(opens in a new window)</span></a><span> where the cells are concentrated at an earlier step has been reported. Notably, the method developed here by GPT‑5 is compatible with off-the-shelf chemically competent cells, eliminating the need for in-house cell preparation, while exceeding the similar approach’s reported efficiency&nbsp;gains on comparable cell strains.</span></p><div id=\"robotic-system\"><p></p><h2><span>Robotic system</span></h2><p></p></div><p><span>To increase the throughput of this model experimental system, Robot on Rails and Red Queen Bio collaborated to build a robotic system that takes in a natural language cloning protocol and executes it in the wet lab.</span></p><p><span>The system combines three components: 1) a human-to-robot LLM that converts plain English into the robot’s actions; 2) a vision system that identifies and localizes labware in real time; and 3) a robotic path planner that determines how to carry out each action safely and accurately. The result is a flexible, generalized lab robot that was further optimized for variants of the Gibson cloning protocol.</span></p><div><p><span>We tested whether the autonomous robot could execute a complete cloning experiment by running two protocols simultaneously: the standard HiFi method and R8, the top-performing AI-modified protocol from the first optimization round. </span></p><p>We compared the robot’s work to human-performed experiments at each step. The robot successfully handled the transformation process, which required diverse physical operations: transferring and mixing liquids, moving sample tubes, applying controlled heat to cells, and spreading cells onto growth plates. When compared directly with human-performed transformations, the robot generated similar quality data with equivalent improvements over baseline, showing early potential for automating and accelerating biological experiment optimization.</p></div><p><span>While the fold-changes between the robot and human experiments were similar, absolute colony counts from the robot were approximately ten-fold lower than manual execution, indicating areas for improvement such as liquid handling precision, temperature control calibration, and replicating the nuances of manual cell handling techniques.</span></p><div id=\"the-future\"><p></p><h2><span>The future</span></h2><p></p></div><p><span>We believe that these experiments offer a snapshot of what future AI-accelerated science will look like: models continually learning and interacting with the real world. Although our experiments excluded human intervention to purely measure model capabilities, we’re particularly excited about </span><a href=\"https://openai.com/science/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>AI helping human scientists</span></u>⁠</a><span> design experiments and contribute to research breakthroughs.</span></p><p><span><br>As we work to accelerate scientific progress safely and responsibly, we also seek to evaluate and reduce risks, particularly those related to biosecurity. These evaluations results show that models can reason in the wet lab to improve protocols, and may have implications for biosecurity as described in our </span><a href=\"https://cdn.openai.com/pdf/18a02b5d-6b67-4cec-ab64-68cdfbddebcd/preparedness-framework-v2.pdf\" target=\"_blank\" referrerpolicy=\"no-referrer-when-downgrade\" rel=\"noopener noreferrer\"><u><span>Preparedness Framework</span></u>⁠<span>(opens in a new window)</span></a><span>. We are </span><a href=\"https://openai.com/index/preparing-for-future-ai-capabilities-in-biology/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>committed to building</span></u>⁠</a><span> necessary and nuanced safeguards at a model and system level to reduce these risks, as well as develop evaluations to track current levels.</span></p></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/5YLMwQ4xkbvsQaVhC5SmIW/c0e7a138494ec4d27ed4d48258411c45/oai_forscience_wetlab_16x9.png?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  },
  {
    "id": "https://openai.com/index/shipping-sora-for-android-with-codex",
    "sourceType": "rss",
    "sourceName": "OpenAI Blog",
    "url": "https://openai.com/index/shipping-sora-for-android-with-codex",
    "title": "How We Used Codex to Ship Sora for Android in 28 Days",
    "publishedAt": "Fri, 12 Dec 2025 00:00:00 GMT",
    "fetchedAt": "2026-01-25T19:08:05.502Z",
    "summary": "",
    "fullText": "<div id=\"readability-page-1\" class=\"page\"><div><p><span>In November, we launched the Sora Android app to the world, giving anyone with an Android device the ability to turn a short prompt into a vivid video. On launch day, the app reached #1 in the Play Store. Android users generated more than a million videos in the first 24 hours.</span></p><p><span>Behind the launch is a story: the initial version of Sora’s production Android app was built in 28 days, thanks to the same agent that’s available to any team or developer: Codex.</span></p><p><span>From October 8 to November 5, 2025, a lean engineering team working alongside Codex and consuming roughly 5 billion tokens, shipped Sora for Android from prototype to global launch. Despite its scale, the app has a crash-free rate of 99.9 percent and an architecture we’re proud of. If you’re wondering whether we used a secret model, we used an early version of the GPT‑5.1-Codex model – the same version that any developer or business can use today via CLI, IDE extension, or web app. </span></p><div><p>Prompt: figure skater performs a triple axle with a cat on her head</p></div><div id=\"embracing-brooks-law-staying-nimble-to-move-fast\"><p></p><h4><span>Embracing Brooks’ Law: Staying nimble to move fast</span></h4><p></p></div><p><span>When Sora launched on iOS, usage exploded. People immediately began generating a stream of videos. On Android, by contrast, we had only a small internal prototype and a mounting number of pre-registered users on Google Play.</span></p><p><span>A common response to a high stakes, time-pressured launch is to pile on resources and add process. A production app of this scope and quality would typically involve many engineers working for months, slowed down by coordination.&nbsp;</span></p><p><span>American computer architect Fred Brooks famously warned that “adding more people to a late software project makes it later.” In other words, when trying to ship a complex project quickly, adding more engineers can often slow down efficiency by adding to communication overhead, task fragmentation, and integration costs. We leaned into this insight instead of ignoring it; we assembled a strong team of four engineers – all equipped with Codex to drastically increase each engineer’s impact.&nbsp;</span></p><p><span>Working this way, we shipped an internal build of Sora for Android to employees in 18 days and launched publicly 10 days later. We maintained a high bar on Android engineering practices, invested in maintainability, and held the app to the same reliability bar we would expect from a more traditional project. (We also continue to use Codex extensively today to evolve and bring new features to the app).</span></p><div id=\"onboarding-a-new-senior-engineer\"><p></p><h4><span>Onboarding a new senior engineer</span></h4><p></p></div><p><span>To make sense of how we worked with Codex, it helps to know where it shines and where it needs direction. Treating it like a newly hired senior engineer was a good approach. Codex’s ability meant we could spend more time directing and reviewing code than writing it ourselves.</span></p><p><b><span>Where Codex needs guidance</span></b></p><div><ol><li><span>Codex isn’t yet great at inferring what it hasn’t been told (e.g., your preferred architecture patterns, product strategy, real user behavior, and internal norms or shortcuts).</span></li><li><span>Similarly, Codex couldn’t see the app actually run: It couldn’t open Sora on a device, notice that a scroll felt off, or sense that a flow was confusing. Only our team could cover these experiential tasks.</span></li><li><span>Each instance requires onboarding. Sharing context with clear goals, constraints, and guidance on “how we do things” was essential to making Codex execute well.</span></li><li><span>In the same vein, Codex struggled with deep architectural judgment: Left on its own, it might introduce an extra view model where we really wanted to extend an existing one or push logic into the UI layer that clearly belonged in a repository. Its instinct is to get something working, not to prioritize long‑term cleanliness.</span></li></ol></div><p><span>We found it useful to have Codex create and maintain a generous amount of AGENT.md files throughout the codebase. This made it easy to apply the same guidance and best practices across sessions. For example, to ensure Codex wrote code in our style guidelines, we added the following to our top-level AGENTS.md:</span></p><p><b><span>Where Codex excels</span></b></p><div><ol><li><span>Reading and understanding large codebases rapidly: Codex knows essentially all major programming languages, which makes it easier to leverage the same concepts across many platforms without complex abstractions.</span></li><li><span>Testing coverage: Codex is (uniquely) enthusiastic about writing unit tests to cover a broad variety of cases. Not every test was deep, but having breadth of coverage was helpful in preventing regressions.&nbsp;</span></li><li><span>Applying feedback: In a similar vein, Codex is good at reacting to feedback. When CI failed, we could paste log output into a prompt and ask Codex to propose fixes.</span></li><li><span>Massively parallel, disposable execution: Most won’t push the limits of the number of sessions they could actually run at any one time. It’s highly feasible to test multiple ideas in parallel and view code as disposable.</span></li><li><span>Offering new perspective: In design discussions, we used Codex as a generative tool to explore potential failure points and discover new ways to solve a problem. For example, while we designed video player memory optimizations, Codex sifted through multiple SDKs to propose approaches we wouldn’t have had time to parse. The insights from Codex’s research proved invaluable in minimizing memory footprint in the final app.</span></li><li><span>Enabling higher‑leverage work: In practice, we ended up spending more time reviewing and directing code than writing it ourselves. That said, Codex is very good at code review, too, often catching bugs before they’re merged, improving reliability.</span></li></ol></div><p><span>Once we acknowledged these characteristics, our working model became more straightforward. We leaned on Codex to do a huge amount of heavy lifting inside well‑understood patterns and well‑bounded scopes, while our team focused on architecture, user experience, systemic changes, and final quality.</span></p><div id=\"laying-the-foundation-by-hand\"><p></p><h4><span>Laying the foundation by hand</span></h4><p></p></div><p><span>Even the best new, senior hire doesn’t have the right vantage point for making long-term trade-offs right away. To leverage Codex and ensure its work was robust and maintainable, it was key that we oversaw the app’s systems design and key trade-offs ourselves. These included shaping the app’s architecture, modularization, dependency injection, and navigation; we also implemented authentication and base networking flows.&nbsp;</span></p><p><span>From this foundation, we wrote a few representative features end‑to‑end. We used the rules we wanted the entire codebase to follow and documented project‑wide patterns as we went. By pointing Codex to representative features, it was able to work more independently within our standards. For a project that we estimate was 85% written by Codex, a carefully planned foundation avoided costly backtracking and refactoring. It was one of the most important decisions we made.&nbsp;</span></p><p><span>The idea was not to make “something that works” as quickly as possible, rather to make “something that gets how we want things to work.” There are many “correct” ways to write code. We didn’t need to tell Codex exactly what to do; we needed to show Codex what’s “correct” on our team. Once we had established our starting point and how we liked to build, Codex was ready to start.</span></p><p><span>To see what would happen, we did try prompting: “Build the Sora Android app based on the iOS code. Go,” but quickly aborted that path. While what Codex created technically worked, the product experience was sub-par. And without a clear understanding of endpoints, data, and user flows, Codex’s single-shot code was unreliable (Even without using an agent, it’s risky to merge thousands of lines of code.)&nbsp;</span></p><p><span>We hypothesized Codex would thrive in a sandbox of well-written examples; and we were right. Asking Codex to “build this settings screen” with almost no context was unreliable. Asking Codex to “build this settings screen using the same architecture and patterns as this other screen you just saw” worked far better. Humans made the structural decisions and set the invariants; Codex then filled in large amounts of code inside that structure.</span></p><div id=\"planning-with-codex-before-coding\"><p></p><h4><span>Planning with Codex before coding</span></h4><p></p></div><p><span>Our next step in maximizing Codex’s potential was figuring out how to enable Codex to work for long periods of time (recently, </span><a href=\"https://openai.com/index/gpt-5-1-codex-max/\" target=\"_blank\" rel=\"noopener noreferrer\"><u><span>more than 24 hours</span></u>⁠</a><span>), unsupervised.</span></p><p><span>Early on in using Codex, we jumped to prompts like, “Here is the feature. Here are some files. Please build it.” That sometimes worked, but mostly produced code that technically compiled, while straying from our architecture and goals.</span></p><p><span>So we changed the workflow. For any non‑trivial change, we first asked Codex to help us understand how the system and code work. For example, we’d ask it to read a set of related files and summarize how that feature works; for example, how data flows from the API through the repository layer, the view model, and into the UI. Then we would correct or refine its understanding. (For example, we’d point out that a particular abstraction really belongs in a different layer or that a given class exists only for offline mode and should not be extended.)</span></p><p><span>Similarly to how you might engage a new, highly capable teammate, we worked with Codex to create a solid implementation plan. That plan often looked like a miniature design document directing which files should change, what new states should be introduced, and how logic should flow. Only then did we ask Codex to start applying the plan, one step at a time. One helpful tip: for very long tasks, where we hit the limit of our context window, we’d ask Codex to save its plan to a file, allowing us to apply the same direction across instances.</span></p><p><span>This extra planning loop turned out to be worth the time. It allowed us to let Codex run “unsupervised” for long stretches, because we knew its plans. It made code review easier, because we could check the implementation against our plan rather than reading a diff without context. And when something went wrong, we could debug the plan first and the code second.&nbsp;</span></p><p><span>The dynamic felt similar to the way a good design document gives a tech lead confidence in a project. We weren’t just generating code: we were producing code that supported a shared roadmap.</span></p><div id=\"distributed-engineering\"><p></p><h4><span>Distributed engineering</span></h4><p></p></div><p><span>At the peak of the project, we were often running multiple Codex sessions in parallel. One was working on playback, another on search, another on error handling, and sometimes another on tests or refactors. It felt less like using a tool and more like managing a team.</span></p><p><span>Each session would periodically report back to us with progress. One might say, “I’m done planning out this module; here’s what I propose,” while another would offer a large diff for a new feature. Each required attention, feedback, and review. It was uncannily similar to being a tech lead with several new engineers, all making progress, all needing guidance.</span></p><p><span>The result was a collaborative flow. Codex’s raw coding capability freed us from a lot of manual typing. We had more time to think about architecture, read pull requests carefully, and test out the app.&nbsp;</span></p><p><span>At the same time, that extra speed meant we always had something waiting in our review queue. Codex didn’t get blocked by context switching, but we did. Our bottleneck in development shifted from writing code to making decisions, giving feedback, and integrating changes.</span></p><p><span>This is where Brooks’s insights land in a new way. You can’t simply add Codex sessions and expect linear speedups any more than you can keep adding engineers to a project and expect the schedule to shrink linearly. Each additional “pair of hands,” even virtual ones, adds coordination overhead. We had become the conductor of an orchestra versus simply faster solo players.</span></p><div id=\"codex-as-a-cross-platform-superpower\"><p></p><h4><span>Codex as a cross‑platform superpower</span></h4><p></p></div><p><span>We started our project with a huge stepping stone: Sora had already shipped on iOS. We frequently pointed Codex at the iOS and backend codebases to help it understand key requirements and constraints. Throughout the project we joked that we had reinvented the idea of a cross‑platform framework. Forget React Native or Flutter; </span><i><span>the future of cross‑platform is just Codex.</span></i></p><p><span>Beneath the quip are two principles:.</span></p><div><ol><li><span>Logic is portable. Whether the code is written in Swift or Kotlin, the underlying application logic – data models, network calls, validation rules, business logic – are the same. Codex is very good at reading a Swift implementation and producing an equivalent in Kotlin that preserves semantics.</span></li><li><span>Concrete examples provide powerful context. A fresh Codex session that can see “here is exactly how this works on iOS” and “here is the Android architecture” is far more effective than one that’s only working from natural language descriptions.</span></li></ol></div><p><span>Putting these principles to work, we made the iOS, backend and Android repos available in the same environment. We gave Codex prompts like:</span></p><p><span>“Read these models and endpoints in the iOS code and then propose a plan to implement the equivalent behavior on Android using our existing API client and model classes.”</span></p><p><span>One small but useful trick was to detail in&nbsp; </span><code><span>~/.codex/AGENTS.md</span></code><span> where local repos lived and what they contained. That made it easier for Codex to discover and navigate relevant code.</span></p><p><span>We were effectively doing cross-platform development through translation instead of shared abstraction. Because Codex handled most of the translation, we avoided doubling implementation costs.</span></p><p><span>The broader lesson is that for Codex, context is everything. Codex did its best work when it understood how the feature already worked in iOS, paired with an understanding of how our Android app was structured. When Codex lacked that context, it wasn’t “refusing to cooperate”; it was guessing. The more we treated it like a new teammate and invested in giving it the right inputs, the better it performed.</span></p><div id=\"the-software-engineering-of-tomorrow-today\"><p></p><h4><span>The software engineering of tomorrow, today</span></h4><p></p></div><p><span>By the end of our four‑week sprint, using Codex stopped feeling like an experiment and became our default development loop. We used it to understand existing code, plan changes, and implement features. We reviewed its output the same way we’d review a teammate’s. It was simply how we shipped software.</span></p><p><span>It became clear that AI‑assisted development does not reduce the need for rigor; it increases it. As capable as Codex is, its objective is to get from A to B, now. This is why AI-assisted coding doesn’t work without humans. Software engineers can understand and apply the real-world constraints of systems, the best ways to architect software, and how to build with future development and product plans in mind. The super powers of tomorrow’s software engineer will be deep systems understanding and the ability to work collaboratively with AI over long time horizons.&nbsp;</span></p><p><span>The most interesting parts of software engineering are building compelling products, designing scalable systems, writing complex algorithms, and experimenting with data, patterns, and code. However, the realities of software engineering of the past and present often lean more mundane: centering buttons, wiring endpoints, and writing boilerplate. Now, Codex makes it possible to focus on the most meaningful parts of software engineering and the reasons we love our craft.</span></p><p><span>Once Codex is set up in a context-rich environment where it understands your goals and how you like to build, any team can multiply its capabilities. Our launch retro isn’t a one‑size‑fits‑all recipe, and we're not claiming to have solved AI‑assisted development. But we hope our experience makes it easier to find the best ways to empower Codex to empower you.&nbsp;</span></p><p><span>When Codex launched in a research preview seven months ago, software engineering looked very different. Through Sora, we got to explore the next chapter of engineering. As our models and harness keep improving, AI will become an increasingly indispensable part of building.&nbsp;</span></p><p><span>What will you make with your own team of Codex?</span></p></div></div>",
    "imageUrl": "https://images.ctfassets.net/kftzwdyauwt9/48FQHADjrPcGgwronRQxLp/1bce28770f356319023015f3c38f8b4c/OpenAI_SoraAndroid_16x9.png?w=1600&h=900&fit=fill",
    "topics": [],
    "entities": []
  }
]